{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":7399829,"sourceType":"datasetVersion","datasetId":4302683}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#from huggingface_hub import notebook_login\n\n#notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:39:55.330091Z","iopub.execute_input":"2024-01-26T10:39:55.331083Z","iopub.status.idle":"2024-01-26T10:39:55.336641Z","shell.execute_reply.started":"2024-01-26T10:39:55.331029Z","shell.execute_reply":"2024-01-26T10:39:55.335550Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%pip install -qq -U datasets transformers pyarrow torchinfo\n%pip install -qq --upgrade transformers ftfy accelerate regex tqdm\n%pip install git+https://github.com/openai/CLIP.git\n%pip install --q -U pytorch-lightning lightning-bolts\n%pip install --upgrade -q wandb\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:39:55.344892Z","iopub.execute_input":"2024-01-26T10:39:55.345704Z","iopub.status.idle":"2024-01-26T10:41:27.594393Z","shell.execute_reply.started":"2024-01-26T10:39:55.345668Z","shell.execute_reply":"2024-01-26T10:41:27.593132Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.12.3 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.10 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.0 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nCollecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-5kbrkdi0\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-5kbrkdi0\n  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (6.1.3)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.15.1)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.24.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\nBuilding wheels for collected packages: clip\n  Building wheel for clip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=bb54a80345443ef6cc5b50a3bd281ac181cd3b12702612f9912d67e2639e5f59\n  Stored in directory: /tmp/pip-ephem-wheel-cache-kc4p019t/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\nSuccessfully built clip\nInstalling collected packages: clip\nSuccessfully installed clip-1.0\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**All the imports**","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport torch\nimport pickle\nimport json\nimport torchinfo\nimport torch.nn as nn\nimport numpy as np\nimport pytorch_lightning as pl\nfrom PIL import Image\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nfrom pathlib import Path\n#from GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\nfrom typing import Union, List\nimport torch.multiprocessing as mp \nfrom torch.cuda.amp import autocast\nfrom matplotlib import pyplot as plt\nfrom pytorch_lightning import LightningModule, Trainer\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\nfrom pytorch_lightning.loggers import WandbLogger\n#from pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks.progress import TQDMProgressBar\nfrom pytorch_lightning.callbacks import Callback\nimport torchmetrics\nimport wandb\n#mp.set_start_method('spawn')","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:41:27.596429Z","iopub.execute_input":"2024-01-26T10:41:27.596729Z","iopub.status.idle":"2024-01-26T10:41:35.761461Z","shell.execute_reply.started":"2024-01-26T10:41:27.596702Z","shell.execute_reply":"2024-01-26T10:41:35.760666Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Define Hyperparameters**","metadata":{}},{"cell_type":"code","source":"raw_images_path = '/kaggle/input/coco-2017-dataset/coco2017/train2017'\ntrain_dataset_path = '/kaggle/input/coco2017-clip-image-embeddings/coco_embeddings_clip_vision_1x768'\ncaptions_path = '/kaggle/input/coco-2017-dataset/coco2017/annotations/captions_train2017.json'\ncaptions_key = 'annotations'\nbatch_size = 1\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nval_split_size = 0.1\nprojection_layer_in_channels = 24\nprojection_layer_out_channels = 2560\nprojection_hidden_size = 64\nmax_training_steps = 100000\nseq_len = 32\nlog_dir = '/kaggle/working/'\nexp_name = 'phi2_proj_layer'\ncheck_point_save_dir = '/kaggle/working/phi2_projection_checkpoints/'\nos.makedirs(check_point_save_dir,exist_ok = True)\nsave_freq = 1000\nval_check_interval = 1000\nlr = 1e-4\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:41:35.762483Z","iopub.execute_input":"2024-01-26T10:41:35.762935Z","iopub.status.idle":"2024-01-26T10:41:35.787404Z","shell.execute_reply.started":"2024-01-26T10:41:35.762910Z","shell.execute_reply":"2024-01-26T10:41:35.786562Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\n# I have saved my API token with \"wandb_api\" as Label. \n# If you use some other Label make sure to change the same below. \n#wandb login --relogin\nwandb.login()\nwandb_logger = WandbLogger(save_dir=log_dir, name='mm_phi_stage1')\ntext_table = wandb.Table(columns=[\"training_step\", \"loss\", \"text\"])\nval_data_log = []","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:41:35.789307Z","iopub.execute_input":"2024-01-26T10:41:35.789592Z","iopub.status.idle":"2024-01-26T10:42:18.406652Z","shell.execute_reply.started":"2024-01-26T10:41:35.789567Z","shell.execute_reply":"2024-01-26T10:42:18.405797Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgyani123\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240126_104147-xxi91sxr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/gyani123/lightning_logs/runs/xxi91sxr' target=\"_blank\">mm_phi_stage1</a></strong> to <a href='https://wandb.ai/gyani123/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/gyani123/lightning_logs' target=\"_blank\">https://wandb.ai/gyani123/lightning_logs</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/gyani123/lightning_logs/runs/xxi91sxr' target=\"_blank\">https://wandb.ai/gyani123/lightning_logs/runs/xxi91sxr</a>"},"metadata":{}}]},{"cell_type":"markdown","source":"**All definitions**","metadata":{}},{"cell_type":"code","source":"class IdentityMap(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x, *args, **kwargs):\n        return x\n\n    @property\n    def config(self):\n        return {\"mm_projector_type\": 'identity'}\n\n\nclass SimpleResBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.pre_norm = nn.LayerNorm(in_channels)\n\n        self.proj = nn.Sequential(\n            nn.Linear(in_channels, out_channels),\n            nn.GELU(),\n            nn.Linear(out_channels, out_channels)\n        )\n    def forward(self, x):\n        x = self.pre_norm(x)\n        return x + self.proj(x)\n\n\nclass SimpleLinearBlock(nn.Module):\n    def __init__(self, in_size, out_size, hidden_size = 50, add_residual_connection=True):\n        super().__init__()\n        self.pre_norm = nn.LayerNorm(in_size)\n        self.proj = nn.Sequential(nn.Linear(in_size, hidden_size),\n                                  nn.GELU(),\n                                  nn.Linear(hidden_size, out_size))\n        self.add_residual_connection = add_residual_connection\n        \n    def forward(self,x):\n        return self.proj(self.pre_norm(x))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.407957Z","iopub.execute_input":"2024-01-26T10:42:18.408294Z","iopub.status.idle":"2024-01-26T10:42:18.420172Z","shell.execute_reply.started":"2024-01-26T10:42:18.408266Z","shell.execute_reply":"2024-01-26T10:42:18.419236Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def model_summary(model, input_size):\n    torchinfo.summary(model, \n                      input_size = input_size, \n                      batch_dim=0, \n                      col_names=(\"kernel_size\",\n                                 \"input_size\",\n                                 \"output_size\",\n                                 \"num_params\",\n                                 \"mult_adds\"),\n                       verbose=1,) \n\n    \ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\ndef chunked_cross_entropy(\n    logits: Union[torch.Tensor, List[torch.Tensor]], targets: torch.Tensor, chunk_size: int = 128, ignore_index = -1\n) -> torch.Tensor:\n    # with large max_sequence_lengths, the beginning of `backward` allocates a large memory chunk which can dominate\n    # the memory usage in fine-tuning settings with low number of parameters.\n    # as a workaround hack, the cross entropy computation is chunked to force it to deallocate on the go, reducing\n    # the memory spike's magnitude\n\n    # lm_head was chunked (we are fine-tuning)\n    if isinstance(logits, list):\n        # don't want to chunk cross entropy\n        if chunk_size == 0:\n            logits = torch.cat(logits, dim=1)\n            logits = logits.reshape(-1, logits.size(-1))\n            targets = targets.reshape(-1)\n            return torch.nn.functional.cross_entropy(logits, targets, ignore_index=ignore_index)\n\n        # chunk cross entropy\n        logit_chunks = [logit_chunk.reshape(-1, logit_chunk.size(-1)) for logit_chunk in logits]\n        target_chunks = [target_chunk.reshape(-1) for target_chunk in targets.split(logits[0].size(1), dim=1)]\n        loss_chunks = [\n            torch.nn.functional.cross_entropy(logit_chunk, target_chunk, ignore_index=ignore_index, reduction=\"none\")\n            for logit_chunk, target_chunk in zip(logit_chunks, target_chunks)\n        ]\n        return torch.cat(loss_chunks).mean()\n\n    # no chunking at all\n    logits = logits.reshape(-1, logits.size(-1))\n    targets = targets.reshape(-1)\n    if chunk_size == 0:\n        return torch.nn.functional.cross_entropy(logits, targets, ignore_index=ignore_index)\n\n    # lm_head wasn't chunked, chunk cross entropy\n    logit_chunks = logits.split(chunk_size)\n    target_chunks = targets.split(chunk_size)\n    loss_chunks = [\n        torch.nn.functional.cross_entropy(logit_chunk, target_chunk, ignore_index=ignore_index, reduction=\"none\")\n        for logit_chunk, target_chunk in zip(logit_chunks, target_chunks)\n    ]\n    return torch.cat(loss_chunks).mean()","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.421601Z","iopub.execute_input":"2024-01-26T10:42:18.421912Z","iopub.status.idle":"2024-01-26T10:42:18.438417Z","shell.execute_reply.started":"2024-01-26T10:42:18.421876Z","shell.execute_reply":"2024-01-26T10:42:18.437558Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#projection_layer_in_channels = 24\n#projection_layer_out_channels = 2560\n#test_model = SimpleLinearBlock(projection_layer_in_channels,projection_layer_out_channels, hidden_size=64)\n#model_summary(test_model, (1,32,24))","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.439756Z","iopub.execute_input":"2024-01-26T10:42:18.440070Z","iopub.status.idle":"2024-01-26T10:42:18.454396Z","shell.execute_reply.started":"2024-01-26T10:42:18.440015Z","shell.execute_reply":"2024-01-26T10:42:18.453528Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Pytorch Model definition**\n","metadata":{}},{"cell_type":"code","source":"class MultiModalGPT(nn.Module):\n    \"\"\"\n    Pytorch Lightning module for Transformer\n\n    \"\"\"\n    def __init__(self,\n                 llm_model,\n                 tokenizer,\n                 projection_layer_in_channels,\n                 projection_layer_out_channels,\n                 hidden_size = 32,\n                 ):\n        super(MultiModalGPT, self).__init__()\n        self.tokenizer = tokenizer\n        self.projection_layer = SimpleLinearBlock(projection_layer_in_channels,projection_layer_out_channels, hidden_size=hidden_size)\n        self.llm_model = llm_model\n        \n        # freeze the llm\n        for param in self.llm_model.parameters():\n            param.requires_grad = False\n    \n    \n    def forward(self, x, max_length=1):\n        #print(f\"beginning of projection: {x.shape}\")\n        x = self.projection_layer(x)\n        #print(f\"end of projection: {x.shape}\")\n        with torch.no_grad():  \n            x = self.llm_model(inputs_embeds = x, return_dict=False)\n        #print(f\"end of llm: logits: {x[0].shape}\")\n        return x\n    \n       \n    def forward(self, batch):\n        #print(f\"beginning of projection: {x.shape}\")\n        x = batch['image_embeddings']\n        targets = batch['tokenized_caption']\n        x = self.projection_layer(x)\n        #print(f\"end of projection: {x.shape}\")\n        #x = self.llm_model(inputs_embeds = x, return_dict=False)\n        outputs_dict = self.llm_model(inputs_embeds = x,\n                                     labels = targets,\n                                     return_dict = True) \n        #print(f\"end of llm: logits: {x[0].shape}\")\n        return outputs_dict\n    \n    def generate(self, x):\n        proj_outs = self.projection_layer(x)\n        with torch.no_grad():\n            output_tokens = self.llm_model.generate(**proj_outs, max_length=200)\n            generated_text = self.tokenizer.batch_decode(output_tokens)[0]\n        return generated_text","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.455978Z","iopub.execute_input":"2024-01-26T10:42:18.456534Z","iopub.status.idle":"2024-01-26T10:42:18.469437Z","shell.execute_reply.started":"2024-01-26T10:42:18.456485Z","shell.execute_reply":"2024-01-26T10:42:18.468266Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Pytorch Lightning Model definition**","metadata":{}},{"cell_type":"code","source":"class LitMultiModalGPT(LightningModule):\n    \"\"\"\n    Pytorch Lightning module for Transformer\n\n    \"\"\"\n    def __init__(self,\n                 projection_layer_in_channels,\n                 projection_layer_out_channels,\n                 hidden_size = 32,\n                 num_validation_examples=2,\n                 num_training_steps=100000):\n        super().__init__()\n        self.num_validation_examples = num_validation_examples\n        self.num_training_steps = num_training_steps\n        self.scheduler = None\n        self.scheduler_dict = {}\n        self.optimizer = None\n        self.this_step_train_loss = None\n        self.predicted_list = []\n        self.expected_list = []\n        self.save_hyperparameters(ignore=['loss_criterion', 'epoch'])\n        self.projection_layer = SimpleLinearBlock(projection_layer_in_channels,projection_layer_out_channels, hidden_size=hidden_size)\n        self.llm_model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n        self.train_loss_values = []\n        self.val_loss_values = []\n        self.COMMENT_TOKEN_ID = 23893\n        self.EOS_TOKEN_ID = 50256\n\n     \n        # freeze the llm\n        for param in self.llm_model.parameters():\n            #print(param.dtype)\n            param.requires_grad = False\n    \n    \n\n    def set_optimizer(self, optimizer):\n        self.optimizer = optimizer\n\n    \n    def set_scheduler_dict(self, scheduler, freq='step'):\n        self.scheduler = scheduler\n        self.scheduler_dict = {\n            \"scheduler\": self.scheduler,\n            \"interval\": freq,\n        }\n\n    def configure_optimizers(self):\n        if self.scheduler_dict:\n            return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler_dict}\n        return {\"optimizer\": self.optimizer}\n         \n   \n    def forward(self, batch):\n        x = batch['image_embeddings']\n        targets = batch['tokenized_caption']\n        x = self.projection_layer(x)\n        outputs_dict = self.llm_model(inputs_embeds = x,\n                                     labels = targets,\n                                     return_dict = True) \n        return outputs_dict\n    \n    def proj_output(self, image_embeds):\n        return self.projection_layer(image_embeds)\n    \n    \n    def generate(self, x):\n        proj_outs = self.projection_layer(x)\n        with torch.no_grad():\n            pred_logits, outputs = self.llm_model(inputs_embeds = proj_outs, return_dict=False)\n            output_tokens = torch.argmax(pred_logits, axis=-1)  \n            generated_text = self.tokenizer.batch_decode(output_tokens, skip_special_tokens=True)[0]\n        return generated_text\n    \n    \n    def evaluate(self,batch, stage):\n        if stage:\n            predicted = self.generate(batch['image_embeddings'])\n            #self.predicted_list.append(predicted)\n            #self.expected_list.append(batch['caption'])\n            # print the source, target, and the model output\n            #print(\"*****************************************\")\n            input_text = f\"{f'label: ' :>12}{batch['caption'][0]}\"\n            pred_text = f\"{f'predicted: ' :>12}{predicted}\"\n            #print(\"*****************************************\\n\")\n            # log a W&B Table that has a text caption, an image and audio\n            columns = [\"step\", \"caption\", \"prediction\"]\n\n            # data should be a list of lists\n            val_data_log.append([self.global_step,input_text , pred_text])\n            # log the Table\n            wandb_logger.log_table(key=\"val_samples\", columns=columns, data=val_data_log)\n        return predicted\n\n    def training_step(self, batch):\n        targets = batch['tokenized_caption']  # (B, seq_len)\n        #print(targets.shape)\n        max_size = len(targets)\n        pos = 0\n        loss = 0\n        with autocast(True):\n            llm_inputs_embeds = self.proj_output(batch['image_embeddings'])# (B, 32, 2560)\n            #print(llm_inputs_embeds.dtype)\n            #print(llm_inputs_embeds)\n            next_embeds = self.llm_model.model.embed_tokens(torch.tensor(self.COMMENT_TOKEN_ID, dtype=torch.int64).to(llm_inputs_embeds.device)).unsqueeze(0).unsqueeze(0) # \n            #print(next_embeds.dtype)\n            while pos < max_size:\n                inputs = torch.cat([llm_inputs_embeds, next_embeds], dim=1) # (B, 33, 2560)\n                #print(inputs.dtype)\n                pred_logits, _ = self.llm_model.forward(inputs_embeds = inputs, return_dict=False) # (B, 33, 512000)\n                pred_next_token_logits = pred_logits[:, -1, :]  # (B, 512000)\n                #print(pred_next_token_logits)\n                predicted_token = torch.argmax(pred_logits, axis=-1) # (B, 1)\n                gt_token = targets[0,pos].contiguous().view(-1) # (B,1)\n                #print(f\"label:{gt_token} predicted:{predicted_token}\")\n                this_loss = torch.nn.functional.cross_entropy(pred_next_token_logits, gt_token, ignore_index = self.EOS_TOKEN_ID, label_smoothing=0.1)\n                loss+=this_loss\n                #print(loss)\n                #if pos < 5:\n                    #next_token = self.llm_model.model.embed_tokens(targets[pos]) # (1, 512000)\n                    #print(next_token.shape)\n                    #print(next_embeds.shape)\n                next_embeds = torch.cat([next_embeds, self.llm_model.model.embed_tokens(targets[pos]).unsqueeze(0)],axis=1) # ()\n                #else:\n                #    next_embeds = torch.cat([next_embeds, self.llm_model.model.embed_tokens(predicted_token).unsqueeze(0)],axis=1)\n                pos+=1\n            loss = loss/max_size\n        del inputs\n        del next_embeds\n        del pred_next_token_logits\n        del pred_logits\n        gc.collect()\n        torch.cuda.empty_cache()\n        #self.llm_model.to(\"cpu\")\n        self.log(\"train_loss\", loss.item(), prog_bar=True)\n        self.this_step_train_loss = loss.item()\n        self.train_loss_values.append(self.this_step_train_loss)\n        return loss\n\n    \n    def validation_step(self, batch, batch_idx):\n        if batch_idx < self.num_validation_examples:\n            predicted = self.evaluate(batch, \"val\")\n            #if batch_idx % 10000 == 0:\n            #    raw_img_path = batch['raw_image_path'][0]\n            #    print(raw_img_path)\n            #    image = Image.open(raw_img_path)\n            #    plt.imshow(image)\n            #    plt.show()\n            #    #print(\"*****************************************\")\n            #    #print(f\"{f'Input: ' :>12}{batch['caption']}\")\n            #    #print(f\"{f'predicted: ' :>12}{predicted}\")\n            #    #print(\"*****************************************\\n\")\n\n\n\n    def test_step(self, batch, batch_idx):\n        self.evaluate(batch, \"test\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.471036Z","iopub.execute_input":"2024-01-26T10:42:18.471667Z","iopub.status.idle":"2024-01-26T10:42:18.504963Z","shell.execute_reply.started":"2024-01-26T10:42:18.471635Z","shell.execute_reply":"2024-01-26T10:42:18.504105Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#batch = next(iter(train_dataloader))\n#input_embeds = multimodal_gpt_model.projection_layer(batch['image_embeddings'])\n#print(input_embeds.shape)\n#token_embeds = multimodal_gpt_model.llm_model.model.embed_tokens(torch.tensor(multimodal_gpt_model.EOS_TOKEN_ID, dtype=torch.int64)).unsqueeze(0).unsqueeze(0)\n#print(token_embeds.shape)\n#inputs = torch.cat([input_embeds, token_embeds], dim=1)\n#print(inputs.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.509361Z","iopub.execute_input":"2024-01-26T10:42:18.509689Z","iopub.status.idle":"2024-01-26T10:42:18.519713Z","shell.execute_reply.started":"2024-01-26T10:42:18.509665Z","shell.execute_reply":"2024-01-26T10:42:18.518888Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Define Trainer**","metadata":{}},{"cell_type":"code","source":"class PeriodicCheckpoint(ModelCheckpoint):\n    def __init__(self, checkpoint_save_dir, save_freq, verbose: bool = False, every_n_train_steps=0, every_n_epochs=0):\n        super().__init__()\n        self.verbose = verbose\n        self.save_dir = checkpoint_save_dir\n        self.save_freq = save_freq\n\n    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n        if batch_idx % self.save_freq == 0:\n            # save the model at the end of every epoch\n            model_filename = os.path.join(self.save_dir, f\"ckpt_{trainer.global_step}.pt\")\n            # first remove \n            # Save only the state_dict of projection layer\n            torch.save(trainer.model.projection_layer.state_dict(), model_filename)\n    \n    def on_validation_end(self, trainer):\n        pass\n\nclass PrintAccuracyAndLoss(Callback):\n    def __init__(self):\n        super().__init__()\n\n    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n        train_loss = trainer.callback_metrics['train_loss']\n        trainer.model.log(\"train_step_loss\", train_loss)\n        if batch_idx % 500 == 0:\n            print(f\"Step: {trainer.global_step}: train_loss={train_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.520894Z","iopub.execute_input":"2024-01-26T10:42:18.521209Z","iopub.status.idle":"2024-01-26T10:42:18.532120Z","shell.execute_reply.started":"2024-01-26T10:42:18.521181Z","shell.execute_reply":"2024-01-26T10:42:18.531169Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":" def train_multimodal_gpt_model(model, train_dataloader, val_dataloader, ckpt_path=None, max_training_steps=2):\n    trainer = Trainer(\n        enable_checkpointing=True,\n        max_steps=max_training_steps,\n        accelerator=\"auto\", #\"auto\" if torch.cuda.is_available() else \"cpu\",\n        devices = 1, \n        logger=wandb_logger,\n        callbacks=[LearningRateMonitor(logging_interval=\"step\"),\n                   TQDMProgressBar(refresh_rate=10),\n                   PeriodicCheckpoint(check_point_save_dir, save_freq, verbose=True),\n                   PrintAccuracyAndLoss()],\n        num_sanity_val_steps=0,\n        val_check_interval = val_check_interval,\n        precision=\"16\"\n    )\n    \n    trainer.fit(model, train_dataloader, val_dataloader, ckpt_path=ckpt_path)\n    return trainer","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.533476Z","iopub.execute_input":"2024-01-26T10:42:18.533822Z","iopub.status.idle":"2024-01-26T10:42:18.546432Z","shell.execute_reply.started":"2024-01-26T10:42:18.533790Z","shell.execute_reply":"2024-01-26T10:42:18.545412Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Data loader**","metadata":{}},{"cell_type":"code","source":"def get_absolute_paths(directory_path, max_files = None):\n    absolute_paths = []\n    image_ids = []\n\n    # Check if the given path is a valid directory\n    if os.path.isdir(directory_path):\n        # Iterate over all files in the directory\n        for root, _, files in os.walk(directory_path):\n            for file in tqdm(files):\n                # extract image ID\n                image_ids.append(Path(file).stem)\n                # Construct the absolute path for each file\n                absolute_path = os.path.abspath(os.path.join(root, file))\n                absolute_paths.append(absolute_path)\n                if max_files is not None and len(absolute_paths) > max_files:\n                    break\n    return absolute_paths, image_ids\n\n\ndef parse_captions_file(captions_path, captions_key):\n    \"\"\"\n    Read a JSON file and return its contents as a dictionary.\n\n    Parameters:\n    - file_path (str): The path to the JSON file.\n\n    Returns:\n    - dict: The contents of the JSON file as a dictionary.\n    \"\"\"\n    try:\n        with open(captions_path, 'r') as file:\n            data = json.load(file)\n        captions = {}\n        annotations = data[captions_key]\n        for annotation in annotations:\n            captions[annotation['image_id']] = annotation['caption']\n        return captions\n    except FileNotFoundError:\n        print(f\"Error: File not found - {captions_path}\")\n    except json.JSONDecodeError:\n        print(f\"Error: Unable to decode JSON in file - {captions_path}\")\n\n        \ndef load_pickle_file(file_path):\n    with open(file_path, 'rb') as fh:\n        data = pickle.load(fh)\n    keys = list(data.keys()) \n    assert len(keys) == 1\n    return data[keys[0]]\n\n\nclass PickleDataset(Dataset):\n\n    def __init__(self, \n                 raw_images_path,\n                 embeddings_path,\n                 image_ids,\n                 captions_path,\n                 captions_key,\n                 tokenizer, \n                 seq_len=768):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.ds = None\n        self.raw_images_path = raw_images_path\n        self.captions_key = captions_key\n        self.embeddings_path = embeddings_path\n        self.image_ids = image_ids\n        self.bos_token = self.tokenizer.bos_token\n        self.eos_token = self.tokenizer.eos_token\n        self.seq_len = seq_len\n        self.captions = parse_captions_file(captions_path, captions_key)\n        \n\n    def __len__(self):\n        return len(self.image_ids)\n\n\n    def __getitem__(self, idx):\n\n        # get image embeddings\n        img_embds = load_pickle_file(self.embeddings_path[idx])\n        img_embds = torch.tensor(np.squeeze(img_embds))\n        img_embds = img_embds.view(32,24)\n        #print(img_embds.shape)\n        this_img_id = self.image_ids[idx]\n        #print(this_img_id)\n        this_img_f_name = \"{:012d}\".format(int(this_img_id))+'.jpg'\n        \n        # get caption\n        caption = self.captions[int(this_img_id)]\n        tokenized_caption = self.tokenize_caption(caption)\n        \n        return {\n            \"image_embeddings\": img_embds,\n            \"raw_image_path\": os.path.join(self.raw_images_path, this_img_f_name),\n            \"caption\": caption,\n            \"tokenized_caption\": tokenized_caption\n        }\n    \n    def tokenize_caption(self, caption):\n        tokens = self.tokenizer(caption)\n        tokenizer_output = self.tokenizer(caption, return_tensors=\"pt\", return_attention_mask=False)\n        caption_encoded = tokenizer_output['input_ids'].squeeze()\n        if len(caption_encoded) > self.seq_len:\n            caption_encoded = caption_encoded[:self.seq_len-2]\n        num_padding_tokens = self.seq_len - len(caption_encoded) - 1\n        # Add <s> and </s> token\n        tokenized_caption = torch.cat(\n            [\n                caption_encoded.squeeze(),\n                torch.tensor([self.tokenizer.eos_token_id]*num_padding_tokens,dtype=torch.int64),\n            ],dim=0)\n        #print(f\"caption length: {len(caption_encoded)} number of padding tokens: {num_padding_tokens} total size: {len(tokenized_caption)}\")\n        return tokenized_caption\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.547806Z","iopub.execute_input":"2024-01-26T10:42:18.548134Z","iopub.status.idle":"2024-01-26T10:42:18.568627Z","shell.execute_reply.started":"2024-01-26T10:42:18.548103Z","shell.execute_reply":"2024-01-26T10:42:18.567680Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Define train dataset and train dataloader**","metadata":{}},{"cell_type":"code","source":"files_list, images_ids_list = get_absolute_paths(train_dataset_path)\nfiles_list = np.array(files_list)\nimages_ids_list = np.array(images_ids_list)\nrand_indices = np.arange(len(files_list))\nnp.random.shuffle(rand_indices)\n\nval_split = int(len(files_list)*val_split_size)\n\nval_filepaths, train_filepaths = files_list[rand_indices[:100]], files_list[rand_indices[100:]] \nval_image_ids, train_image_ids = images_ids_list[rand_indices[:100]], images_ids_list[rand_indices[100:]]\n\nprint(f\"Train dataset size: {len(train_filepaths)}\")\nprint(f\"Valid dataset size: {len(val_filepaths)}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:42:18.569931Z","iopub.execute_input":"2024-01-26T10:42:18.570296Z","iopub.status.idle":"2024-01-26T10:44:30.264215Z","shell.execute_reply.started":"2024-01-26T10:42:18.570264Z","shell.execute_reply":"2024-01-26T10:44:30.262946Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 118285/118285 [00:01<00:00, 70416.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train dataset size: 118185\nValid dataset size: 100\n","output_type":"stream"}]},{"cell_type":"code","source":"phi_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\ntrain_ds = PickleDataset(raw_images_path, train_filepaths, train_image_ids, captions_path, captions_key, phi_tokenizer, seq_len = seq_len)\nval_ds = PickleDataset(raw_images_path, val_filepaths, val_image_ids, captions_path, captions_key, phi_tokenizer, seq_len = seq_len)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:44:30.265459Z","iopub.execute_input":"2024-01-26T10:44:30.265786Z","iopub.status.idle":"2024-01-26T10:44:36.609218Z","shell.execute_reply.started":"2024-01-26T10:44:30.265757Z","shell.execute_reply":"2024-01-26T10:44:36.608107Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87afe43e20354215a60c9c878ae55c3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39bd0a3ad314452d9ddb58b823404984"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"930ef73720ef433ba33e1dbb1a7e6d2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10486d69ebb427db8c418c19fc16967"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c79a754e40a449ebc475e58aeb9112f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05096fcf05264f54898c4d9edffd520e"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataloader = DataLoader(dataset = train_ds,\n                              batch_size = batch_size,\n                              num_workers = 1,\n                              collate_fn = None,\n                              shuffle = True)\nval_dataloader = DataLoader(dataset = val_ds,\n                            batch_size = 1,\n                            num_workers = 1,\n                            collate_fn = None,\n                            shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:44:36.610408Z","iopub.execute_input":"2024-01-26T10:44:36.610696Z","iopub.status.idle":"2024-01-26T10:44:36.617113Z","shell.execute_reply.started":"2024-01-26T10:44:36.610671Z","shell.execute_reply":"2024-01-26T10:44:36.616229Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#batch = next(iter(train_dataloader))\n#print(batch['tokenized_caption'].dtype)\n#inputs_embeds = batch['image_embeddings']\n#print(inputs_embeds.dtype)\n#inputs_embeds2 = multimodal_gpt_model.projection_layer(inputs_embeds)\n#print(inputs_embeds2.dtype)\n#with torch.autocast(device_type=\"cpu\"):\n#    llm_output = multimodal_gpt_model.llm_model(phi_tokenizer(\"hello my name is Jyani\", return_tensors=\"pt\", return_attention_mask=False), return_dict=False)\n#                                            labels = batch['tokenized_caption'],\n#                                            return_dict=True)\n#print(llm_output)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:44:36.618256Z","iopub.execute_input":"2024-01-26T10:44:36.619135Z","iopub.status.idle":"2024-01-26T10:44:36.634883Z","shell.execute_reply.started":"2024-01-26T10:44:36.619108Z","shell.execute_reply":"2024-01-26T10:44:36.633974Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#del multimodal_gpt_model\n#del trainer\ngc.collect()\ntorch.cuda.empty_cache()\ngc.collect()\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:44:36.636066Z","iopub.execute_input":"2024-01-26T10:44:36.636450Z","iopub.status.idle":"2024-01-26T10:44:37.078974Z","shell.execute_reply.started":"2024-01-26T10:44:36.636389Z","shell.execute_reply":"2024-01-26T10:44:37.077911Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Define model and optimizer**","metadata":{}},{"cell_type":"code","source":"multimodal_gpt_model = LitMultiModalGPT(projection_layer_in_channels,\n                                        projection_layer_out_channels,\n                                        hidden_size = projection_hidden_size)\noptimizer = torch.optim.Adam(multimodal_gpt_model.parameters(), lr=1.0e-4, eps=1e-9)\nmultimodal_gpt_model.set_optimizer(optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:44:37.081196Z","iopub.execute_input":"2024-01-26T10:44:37.081486Z","iopub.status.idle":"2024-01-26T10:45:49.588694Z","shell.execute_reply.started":"2024-01-26T10:44:37.081460Z","shell.execute_reply":"2024-01-26T10:45:49.587439Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/866 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2cbced9dd694d278b8ed71f07706c13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi.py:   0%|          | 0.00/9.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48fda420535343c89c169739b1b3b093"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n- configuration_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi.py:   0%|          | 0.00/62.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04210d579b134e5f9085aa14ed4c882a"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n- modeling_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b0e56ab1d3e475abaccf14d34a5a5d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c047292c5fb747f39fff878e8508b3a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1cc6992b17e4b2a8d82942850845e04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ddc541734c4064b283d5b5afc541d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23eadf4626f648748f189d14a46312cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1f9c2e9afe24be29b5e4910ca9b186c"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Train the model**","metadata":{}},{"cell_type":"code","source":"trainer = train_multimodal_gpt_model(multimodal_gpt_model, train_dataloader, val_dataloader, max_training_steps=max_training_steps)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T10:45:49.590377Z","iopub.execute_input":"2024-01-26T10:45:49.590753Z","iopub.status.idle":"2024-01-26T11:01:24.689338Z","shell.execute_reply.started":"2024-01-26T10:45:49.590719Z","shell.execute_reply":"2024-01-26T11:01:24.686597Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n  rank_zero_warn(\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6226a4e14e4e4f70821510c1b9fe4d43"}},"metadata":{}},{"name":"stdout","text":"Step: 1: train_loss=11.4562\nStep: 101: train_loss=7.5139\nStep: 201: train_loss=7.3516\nStep: 301: train_loss=3.9412\nStep: 401: train_loss=4.2764\nStep: 501: train_loss=8.2188\nStep: 601: train_loss=1.9753\nStep: 701: train_loss=1.8514\nStep: 801: train_loss=15.3109\nStep: 901: train_loss=3.5267\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Step: 1001: train_loss=6.4216\nStep: 1101: train_loss=2.2084\nStep: 1201: train_loss=2.2036\nStep: 1301: train_loss=3.5126\nStep: 1401: train_loss=1.8362\nStep: 1501: train_loss=2.6328\nStep: 1601: train_loss=1.7975\nStep: 1701: train_loss=2.2002\nStep: 1801: train_loss=2.0463\nStep: 1901: train_loss=2.0099\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_multimodal_gpt_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmultimodal_gpt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_training_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_training_steps\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36mtrain_multimodal_gpt_model\u001b[0;34m(model, train_dataloader, val_dataloader, ckpt_path, max_training_steps)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_multimodal_gpt_model\u001b[39m(model, train_dataloader, val_dataloader, ckpt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_training_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      2\u001b[0m    trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      3\u001b[0m        enable_checkpointing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m        max_steps\u001b[38;5;241m=\u001b[39mmax_training_steps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m        precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m16\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m    )\n\u001b[0;32m---> 17\u001b[0m    \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1214\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1214\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:267\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(dataloader, batch_to_device\u001b[38;5;241m=\u001b[39mbatch_to_device)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36mTrainingEpochLoop.on_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_check_val:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# update plateau LR scheduler after metrics are logged\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:308\u001b[0m, in \u001b[0;36mTrainingEpochLoop._run_validation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loop\u001b[38;5;241m.\u001b[39m_reload_evaluation_dataloaders()\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:206\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:198\u001b[0m, in \u001b[0;36mEvaluationLoop.on_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mlog_eval_end_metrics(all_logged_outputs)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_evaluation_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# enable train mode again\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_evaluation_model_train()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:262\u001b[0m, in \u001b[0;36mEvaluationLoop._on_evaluation_end\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs ``on_{validation/test}_end`` hook.\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(hook_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook(hook_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1394\u001b[0m, in \u001b[0;36mTrainer._call_callback_hooks\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m   1393\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1394\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m   1397\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1398\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:312\u001b[0m, in \u001b[0;36mModelCheckpoint.on_validation_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    310\u001b[0m monitor_candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_monitor_candidates(trainer)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_every_n_epochs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (trainer\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_every_n_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_topk_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_last_checkpoint(trainer, monitor_candidates)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:363\u001b[0m, in \u001b[0;36mModelCheckpoint._save_topk_checkpoint\u001b[0;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_monitor_checkpoint(trainer, monitor_candidates)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_none_monitor_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:669\u001b[0m, in \u001b[0;36mModelCheckpoint._save_none_monitor_checkpoint\u001b[0;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# set the best model path before saving because it will be part of the state.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m previous, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model_path, filepath\n\u001b[0;32m--> 669\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_top_k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m previous \u001b[38;5;129;01mand\u001b[39;00m previous \u001b[38;5;241m!=\u001b[39m filepath:\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_checkpoint(trainer, previous)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:366\u001b[0m, in \u001b[0;36mModelCheckpoint._save_checkpoint\u001b[0;34m(self, trainer, filepath)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, filepath: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_global_step_saved \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mglobal_step\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;66;03m# notify loggers\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1939\u001b[0m, in \u001b[0;36mTrainer.save_checkpoint\u001b[0;34m(self, filepath, weights_only, storage_options)\u001b[0m\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving a checkpoint is only possible if a model is attached to the Trainer. Did you call\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `Trainer.save_checkpoint()` before calling `Trainer.\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mfit,validate,test,predict}`?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1938\u001b[0m     )\n\u001b[0;32m-> 1939\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:511\u001b[0m, in \u001b[0;36mCheckpointConnector.save_checkpoint\u001b[0;34m(self, filepath, weights_only, storage_options)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    storage_options: parameter for how to save to storage, passed to ``CheckpointIO`` plugin\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    510\u001b[0m _checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdump_checkpoint(weights_only)\n\u001b[0;32m--> 511\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:466\u001b[0m, in \u001b[0;36mStrategy.save_checkpoint\u001b[0;34m(self, checkpoint, filepath, storage_options)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m    storage_options: parameter for how to save to storage, passed to ``CheckpointIO`` plugin\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_global_zero:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning_fabric/plugins/io/torch_io.py:54\u001b[0m, in \u001b[0;36mTorchCheckpointIO.save_checkpoint\u001b[0;34m(self, checkpoint, path, storage_options)\u001b[0m\n\u001b[1;32m     51\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# write the checkpoint dictionary on the file\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[43m_atomic_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# todo: is this try catch necessary still?\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# https://github.com/Lightning-AI/lightning/pull/431\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# TODO(fabric): Fabric doesn't support hyperparameters in the checkpoint, so this should be refactored\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyper_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:72\u001b[0m, in \u001b[0;36m_atomic_save\u001b[0;34m(checkpoint, filepath)\u001b[0m\n\u001b[1;32m     70\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(checkpoint, bytesbuffer)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fsspec\u001b[38;5;241m.\u001b[39mopen(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytesbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fsspec/implementations/local.py:369\u001b[0m, in \u001b[0;36mLocalFileOpener.write\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"],"ename":"OSError","evalue":"[Errno 28] No space left on device","output_type":"error"},{"name":"stderr","text":"--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n","output_type":"stream"}]},{"cell_type":"code","source":"wandb_logger.log({})","metadata":{"execution":{"iopub.status.busy":"2024-01-26T11:01:24.690687Z","iopub.status.idle":"2024-01-26T11:01:24.691078Z","shell.execute_reply.started":"2024-01-26T11:01:24.690898Z","shell.execute_reply":"2024-01-26T11:01:24.690917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -alh /kaggle/working/phi2_proj_layer/version_0/checkpoints","metadata":{"execution":{"iopub.status.busy":"2024-01-26T11:01:24.692730Z","iopub.status.idle":"2024-01-26T11:01:24.693179Z","shell.execute_reply.started":"2024-01-26T11:01:24.692923Z","shell.execute_reply":"2024-01-26T11:01:24.692944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!vi /kaggle/working/phi2_proj_layer/version_0/checkpoints/epoch\\=0-step\\=1000.ckpt","metadata":{"execution":{"iopub.status.busy":"2024-01-26T11:01:24.696403Z","iopub.status.idle":"2024-01-26T11:01:24.696827Z","shell.execute_reply.started":"2024-01-26T11:01:24.696639Z","shell.execute_reply":"2024-01-26T11:01:24.696660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -alh /kaggle/working/phi2_projection_checkpoints","metadata":{"execution":{"iopub.status.busy":"2024-01-26T11:01:24.699796Z","iopub.status.idle":"2024-01-26T11:01:24.702425Z","shell.execute_reply.started":"2024-01-26T11:01:24.702170Z","shell.execute_reply":"2024-01-26T11:01:24.702194Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 708, in handle_request_pause\n    logger.info(\"stopping system metrics thread\")\nMessage: 'stopping system metrics thread'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 709, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 203, in finish\n    logger.info(\"Stopping system monitor\")\nMessage: 'Stopping system monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 179, in _start\n    logger.debug(\"Finished system metrics aggregation loop\")\nMessage: 'Finished system metrics aggregation loop'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 183, in _start\n    logger.debug(\"Publishing last batch of metrics\")\nMessage: 'Publishing last batch of metrics'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 709, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/cpu.py\", line 163, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined cpu monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 709, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/disk.py\", line 210, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined disk monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 709, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/gpu.py\", line 388, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined gpu monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 709, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/memory.py\", line 152, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined memory monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 709, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/network.py\", line 96, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined network monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 328, in _process\n    self._sm.send(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 382, in send\n    logger.debug(f\"send: {record_type}\")\nMessage: 'send: stats'\nArguments: ()\nException in thread OutRawRd-stderr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n--- Logging error ---\n    self._target(*self._args, **self._kwargs)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1243, in _output_raw_reader_thread\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._finish()\n    self._output_raw_flush(stream)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n    self._hm.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1258, in _output_raw_flush\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 869, in finish\n    logger.info(\"shutting down handler\")\nMessage: 'shutting down handler'\nArguments: ()\n    self._output_raw_file.write(data.encode(\"utf-8\"))\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 128, in write\n    super().write(b\"\\n\".join(ret) + b\"\\n\")\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 95, in write\n    self.f.flush()\nOSError: [Errno 28] No space left on device\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n    self._sm.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1572, in finish\n    logger.info(\"shutting down sender\")\nMessage: 'shutting down sender'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 199, in run\n    self.dispatch_events(self.event_queue, self.timeout)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 368, in dispatch_events\n    handler.dispatch(event)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/events.py\", line 454, in dispatch\n    _method_map[event_type](event)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/filesync/dir_watcher.py\", line 288, in _on_file_modified\n    logger.info(f\"file/dir modified: { event.src_path}\")\nMessage: 'file/dir modified: /kaggle/working/wandb/run-20240126_104147-xxi91sxr/files/output.log'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 48, in run\n    self._target(**self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 174, in wandb_internal\n    logger.error(f\"Thread {thread.name}:\", exc_info=exc_info)\nMessage: 'Thread SenderThread:'\nArguments: ()\nThread SenderThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n    self._sm.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1575, in finish\n    self._output_raw_finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1214, in _output_raw_finish\n    self._output_raw_file.close()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 132, in close\n    super().write(self._buff)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 95, in write\n    self.f.flush()\nOSError: [Errno 28] No space left on device\nwandb: ERROR Internal wandb error: file data was not synced\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2024-01-26T11:06:33.830136Z","iopub.execute_input":"2024-01-26T11:06:33.830499Z","iopub.status.idle":"2024-01-26T11:06:35.386209Z","shell.execute_reply.started":"2024-01-26T11:06:33.830469Z","shell.execute_reply":"2024-01-26T11:06:35.385184Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7afa8901bfd0>> (for pre_run_cell):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:443\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:664\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:359\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"},{"name":"stdout","text":"lightning_logs\tphi2_projection_checkpoints  wandb\nError in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7afa8901bfd0>> (for post_run_cell):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:438\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:656\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    655\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 656\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:355\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"}]}]}