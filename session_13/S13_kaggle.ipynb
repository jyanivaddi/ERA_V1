{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_13/s13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"First Connect Google Drive","metadata":{"id":"OZ4DqRTb9Ym8"}},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/gdrive/', force_remount=True)","metadata":{"id":"TDhBByBZ8qi9","outputId":"74ecf808-1a81-4f0d-d197-3614327b21d8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Install packages","metadata":{"id":"cgHQxuQMAJ5o"}},{"cell_type":"code","source":"!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n!git -C ERA_V1 pull\n#!cd ../\n!git clone \"https://github.com/jyanivaddi/dl_hub.git\"\n!git -C dl_hub pull\n!git pull\n#!cd ../\n\n!pip install --quiet \"torchinfo\" \"seaborn\" \"pytorch-lightning\" \"torchmetrics\" \"lightning-bolts\"\n!pip install --quiet \"prettytable\"\n!pip install --quiet \"torch_lr_finder\"\n!pip install --quiet \"grad-cam\"\n!pip install --quiet \"gradio\"","metadata":{"id":"VAOiUa_mAJVQ","outputId":"85e7cb94-0062-4173-f106-05d14f0d42b1","execution":{"iopub.status.busy":"2023-08-15T11:24:45.240841Z","iopub.execute_input":"2023-08-15T11:24:45.241258Z","iopub.status.idle":"2023-08-15T11:25:50.896569Z","shell.execute_reply.started":"2023-08-15T11:24:45.241226Z","shell.execute_reply":"2023-08-15T11:25:50.895113Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"fatal: destination path 'ERA_V1' already exists and is not an empty directory.\nAlready up to date.\nfatal: destination path 'dl_hub' already exists and is not an empty directory.\nremote: Enumerating objects: 25, done.\u001b[K\nremote: Counting objects: 100% (25/25), done.\u001b[K\nremote: Compressing objects: 100% (18/18), done.\u001b[K\nremote: Total 22 (delta 9), reused 9 (delta 2), pack-reused 0\u001b[K\nUnpacking objects: 100% (22/22), 16.89 KiB | 1.69 MiB/s, done.\nFrom https://github.com/jyanivaddi/dl_hub\n   2e5397b..bf8c66a  main       -> origin/main\nUpdating 2e5397b..bf8c66a\nFast-forward\n {models/YOLO_V3 => YOLO_V3}/__init__.py            |  0\n {models/YOLO_V3 => YOLO_V3}/config.py              |  0\n {models/YOLO_V3 => YOLO_V3}/model.py               |  0\n {models/YOLO_V3 => YOLO_V3/yolo_v3_utils}/loss.py  |  0\n .../yolo_v3_utils}/loss_1_1_deleteme.py            |  0\n .../yolo_v3_utils/pascal_voc_dataset.py            | 63 \u001b[32m+++++++++++\u001b[m\u001b[31m-----------\u001b[m\n .../yolo_v3_utils/pascal_voc_dataset_mosaic.py     | 63 \u001b[32m+++++++++++\u001b[m\u001b[31m-----------\u001b[m\n {models/YOLO_V3 => YOLO_V3/yolo_v3_utils}/train.py |  0\n {models/YOLO_V3 => YOLO_V3/yolo_v3_utils}/utils.py |  0\n session_13/S13_kaggle.ipynb                        |  1 \u001b[31m-\u001b[m\n 10 files changed, 62 insertions(+), 65 deletions(-)\n rename {models/YOLO_V3 => YOLO_V3}/__init__.py (100%)\n rename {models/YOLO_V3 => YOLO_V3}/config.py (100%)\n rename {models/YOLO_V3 => YOLO_V3}/model.py (100%)\n rename {models/YOLO_V3 => YOLO_V3/yolo_v3_utils}/loss.py (100%)\n rename {models/YOLO_V3 => YOLO_V3/yolo_v3_utils}/loss_1_1_deleteme.py (100%)\n rename models/YOLO_V3/dataset_org.py => YOLO_V3/yolo_v3_utils/pascal_voc_dataset.py (75%)\n rename models/YOLO_V3/dataset.py => YOLO_V3/yolo_v3_utils/pascal_voc_dataset_mosaic.py (83%)\n rename {models/YOLO_V3 => YOLO_V3/yolo_v3_utils}/train.py (100%)\n rename {models/YOLO_V3 => YOLO_V3/yolo_v3_utils}/utils.py (100%)\n delete mode 100644 session_13/S13_kaggle.ipynb\nfatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append(\"ERA_V1/session_13\")\nsys.path.append(\"dl_hub\")","metadata":{"id":"ivBzl8YFPvJ0","execution":{"iopub.status.busy":"2023-08-15T11:26:21.698652Z","iopub.execute_input":"2023-08-15T11:26:21.699043Z","iopub.status.idle":"2023-08-15T11:26:21.704208Z","shell.execute_reply.started":"2023-08-15T11:26:21.699011Z","shell.execute_reply":"2023-08-15T11:26:21.703030Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!git -C dl_hub pull\n","metadata":{"id":"n41Pe-b1J3mC","outputId":"2d7d2842-8bfc-459a-beb0-11002dcb6484","execution":{"iopub.status.busy":"2023-08-15T11:31:55.435500Z","iopub.execute_input":"2023-08-15T11:31:55.436556Z","iopub.status.idle":"2023-08-15T11:31:56.839658Z","shell.execute_reply.started":"2023-08-15T11:31:55.436518Z","shell.execute_reply":"2023-08-15T11:31:56.838219Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"remote: Enumerating objects: 9, done.\u001b[K\nremote: Counting objects: 100% (9/9), done.\u001b[K\nremote: Compressing objects: 100% (5/5), done.\u001b[K\nremote: Total 5 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (5/5), 778 bytes | 259.00 KiB/s, done.\nFrom https://github.com/jyanivaddi/dl_hub\n   bf8c66a..26b2b7b  main       -> origin/main\nUpdating bf8c66a..26b2b7b\nFast-forward\n YOLO_V3/yolo_v3_utils/utils.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n 1 file changed, 1 insertion(+), 1 deletion(-)\n","output_type":"stream"}]},{"cell_type":"code","source":"import dl_hub.YOLO_V3.config as config\nimport torch\nimport torch.optim as optim\n\nfrom dl_hub.YOLO_V3.model import YOLOv3\nfrom tqdm import tqdm\nfrom dl_hub.YOLO_V3.yolo_v3_utils.utils import (\n    mean_average_precision,\n    cells_to_bboxes,\n    get_evaluation_bboxes,\n    save_checkpoint,\n    load_checkpoint,\n    check_class_accuracy,\n    get_loaders,\n    plot_couple_examples\n)\nfrom dl_hub.YOLO_V3.yolo_v3_utils.loss import YoloLoss\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"x8WpKATx75Hu","execution":{"iopub.status.busy":"2023-08-15T11:32:10.058548Z","iopub.execute_input":"2023-08-15T11:32:10.059219Z","iopub.status.idle":"2023-08-15T11:32:10.065799Z","shell.execute_reply.started":"2023-08-15T11:32:10.059186Z","shell.execute_reply":"2023-08-15T11:32:10.064511Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\ndef train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, scheduler):\n    loop = tqdm(train_loader, leave=True)\n    losses = []\n    for batch_idx, (x, y) in enumerate(loop):\n        x = x.to(config.DEVICE)\n        y0, y1, y2 = (\n            y[0].to(config.DEVICE),\n            y[1].to(config.DEVICE),\n            y[2].to(config.DEVICE),\n        )\n\n        with torch.cuda.amp.autocast():\n            out = model(x)\n            loss = (\n                loss_fn(out[0], y0, scaled_anchors[0])\n                + loss_fn(out[1], y1, scaled_anchors[1])\n                + loss_fn(out[2], y2, scaled_anchors[2])\n            )\n\n        losses.append(loss.item())\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n\n        # update progress bar\n        mean_loss = sum(losses) / len(losses)\n        loop.set_postfix(loss=mean_loss)","metadata":{"id":"w4GDrpX975Hx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\ntorch.cuda.empty_cache()","metadata":{"id":"TDkVV-JtKJUI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\n\nmodel = YOLOv3(num_classes=config.NUM_CLASSES).to(config.DEVICE)\noptimizer = optim.Adam(\n    model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY\n)\nloss_fn = YoloLoss()\nscaler = torch.cuda.amp.GradScaler()\n\ntrain_loader, test_loader, train_eval_loader = get_loaders(\n    train_csv_path=config.DATASET + \"/100examples.csv\", test_csv_path=config.DATASET + \"/8examples.csv\"\n)\n\nif config.LOAD_MODEL:\n    load_checkpoint(\n        config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE\n    )\n","metadata":{"id":"3DtkSQ9b75H0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\n\nfrom torch_lr_finder import LRFinder\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\n\ndef criterion(out, y):\n    y0, y1, y2 = (\n            y[0].to(config.DEVICE),\n            y[1].to(config.DEVICE),\n            y[2].to(config.DEVICE),\n        )\n    loss = (\n                loss_fn(out[0], y0, scaled_anchors[0])\n                + loss_fn(out[1], y1, scaled_anchors[1])\n                + loss_fn(out[2], y2, scaled_anchors[2])\n            )\n    return loss\nlr_finder = LRFinder(model, optimizer, criterion, device=device)\nlr_finder.range_test(train_loader, end_lr=10, num_iter=200, step_mode=\"exp\")\nlr_finder.plot() # to inspect the loss-learning rate graph\nlr_finder.reset() # to reset the model and optimizer to their initial state","metadata":{"id":"3P9vTBy475H1","outputId":"a2711398-2d5b-4cf4-fd64-7837f85c45f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\n\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\n\n\nfrom torch.optim.lr_scheduler import OneCycleLR\nEPOCHS = config.NUM_EPOCHS * 2 // 5\nscheduler = OneCycleLR(\n        optimizer,\n        max_lr=1E-3,\n        steps_per_epoch=len(train_loader),\n        epochs=EPOCHS,\n        pct_start=5/EPOCHS,\n        div_factor=100,\n        three_phase=False,\n        final_div_factor=100,\n        anneal_strategy='linear'\n    )\n\nfor epoch in range(EPOCHS):\n    #plot_couple_examples(model, test_loader, 0.6, 0.5, scaled_anchors)\n    train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, scheduler)\n\n    #if config.SAVE_MODEL:\n    #   save_checkpoint(model, optimizer, filename=f\"checkpoint.pth.tar\")\n\n    print(f\"Currently epoch {epoch}\")\n    print(\"On Train Eval loader:\")\n    print(\"On Train loader:\")\n    check_class_accuracy(model, train_loader, threshold=config.CONF_THRESHOLD)\n\n    if epoch > 0 and epoch % 3 == 0:\n        check_class_accuracy(model, test_loader, threshold=config.CONF_THRESHOLD)\n        pred_boxes, true_boxes = get_evaluation_bboxes(\n            test_loader,\n            model,\n            iou_threshold=config.NMS_IOU_THRESH,\n            anchors=config.ANCHORS,\n            threshold=config.CONF_THRESHOLD,\n        )\n        mapval = mean_average_precision(\n            pred_boxes,\n            true_boxes,\n            iou_threshold=config.MAP_IOU_THRESH,\n            box_format=\"midpoint\",\n            num_classes=config.NUM_CLASSES,\n        )\n        print(f\"MAP: {mapval.item()}\")\n        model.train()","metadata":{"id":"_PQZ3wqP75H4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Pytorch Lightning Definitions**","metadata":{"id":"JG-vYgIZNS7J"}},{"cell_type":"markdown","source":"Define Model","metadata":{"id":"eZwoyfhNoH3A"}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom pytorch_lightning import LightningModule\nfrom torchmetrics.functional import accuracy\n\n\nclass LitYOLOv3(LightningModule):\n    def __init__(self,\n                 loss_criterion,\n                 scaled_anchors,\n                 conf_threshold,\n                 optimizer=None,\n                 scheduler_dict=None,\n                 num_classes=10,\n                 epochs=20):\n        super().__init__()\n\n        self.save_hyperparameters()\n        self.model = YOLOv3(num_classes=num_classes)\n        self.loss_criterion = loss_criterion\n        self.scaled_anchors = scaled_anchors\n        self.conf_threshold = conf_threshold\n        self.optimizer = None\n        self.scheduler_dict = None\n        self.epochs = epochs\n\n    def set_optimizer(self, optimizer):\n        self.optimizer = optimizer\n\n    def set_scheduler_dict(self, scheduler, freq='step'):\n        self.scheduler = scheduler\n        self.scheduler_dict = {\n            \"scheduler\": self.scheduler,\n            \"interval\": freq,\n        }\n\n    def forward(self, x):\n        return self.model.forward(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y0, y1, y2 = (y[0],y[1],y[2])\n\n        out = self(x)\n        loss = (\n                self.loss_criterion(out[0], y0, self.scaled_anchors[0]) +\n                self.loss_criterion(out[1], y1, self.scaled_anchors[1]) +\n                self.loss_criterion(out[2], y2, self.scaled_anchors[2])\n            )\n        self.log(\"train_loss\", loss, prog_bar=True)\n        return loss\n\n    def evaluate(self, batch, stage=None):\n        \"\"\"\n        Evaluate the model on validation dataset.\n        we compute the class accuracy, the no object accuracy, and the object accuracy\n        \"\"\"\n\n        tot_class_preds, correct_class = 0, 0\n        tot_noobj, correct_noobj = 0, 0\n        tot_obj, correct_obj = 0, 0\n        x, y = batch\n        out = self(x)\n\n        for i in range(3):\n            obj = y[i][..., 0] == 1 # in paper this is Iobj_i\n            noobj = y[i][..., 0] == 0  # in paper this is Iobj_i\n            correct_class += torch.sum(\n                torch.argmax(out[i][..., 5:][obj], dim=-1) == y[i][..., 5][obj]\n            )\n            tot_class_preds += torch.sum(obj)\n\n            obj_preds = torch.sigmoid(out[i][..., 0]) > self.conf_threshold\n            correct_obj += torch.sum(obj_preds[obj] == y[i][..., 0][obj])\n            tot_obj += torch.sum(obj)\n            correct_noobj += torch.sum(obj_preds[noobj] == y[i][..., 0][noobj])\n            tot_noobj += torch.sum(noobj)\n\n        if stage:\n            class_acc = (correct_class/(tot_class_preds+1e-16))*100\n            no_obj_acc = (correct_noobj/(tot_noobj+1e-16))*100\n            obj_acc = (correct_obj/(tot_obj+1e-16))*100\n            self.log(f\"{stage}_Class_Accuracy\",class_acc, prog_bar=True)\n            self.log(f\"{stage}_No_Obj_Accuracy\", no_obj_acc, prog_bar=True)\n            self.log(f\"{stage}_Obj_Accuracy\",obj_acc, prog_bar=True)\n\n\n    def validation_step(self, batch, batch_idx):\n        self.evaluate(batch, \"val\")\n\n    def test_step(self, batch, batch_id):\n        self.evaluate(batch, \"test\")\n\n    def configure_optimizers(self):\n        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler_dict}\n\n\n","metadata":{"id":"OEH_n7lFNU5k","execution":{"iopub.status.busy":"2023-08-15T11:32:20.594558Z","iopub.execute_input":"2023-08-15T11:32:20.595112Z","iopub.status.idle":"2023-08-15T11:32:33.956590Z","shell.execute_reply.started":"2023-08-15T11:32:20.595071Z","shell.execute_reply":"2023-08-15T11:32:33.955579Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Define DataModule","metadata":{"id":"fCmFIu5XoEU7"}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom typing import List, Any\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom pytorch_lightning import LightningDataModule, seed_everything\nfrom dl_hub.YOLO_V3.yolo_v3_utils.pascal_voc_dataset import YOLODataset\n#from dl_hub.YOLO_V3.yolo_v3_utils.pascal_voc_dataset_mosaic import YOLODataset\n\n\nclass YOLODataModule(LightningDataModule):\n    def __init__(self,\n                 csv_files,\n                 img_dir,\n                 label_dir,\n                 anchors,\n                 batch_size,\n                 image_size=416,\n                 S=[13, 26, 52],\n                 C=20,\n                 train_transforms = None,\n                 val_transforms = None,\n                 test_transforms = None,\n                 val_split=0.2,\n                 num_workers = 1,\n                 pin_memory = False):\n\n        # Initialize the class. Set up the datadir, image dims, and num classes\n        super().__init__()\n        self.train_csv_path, self.test_csv_path = csv_files\n        self.img_dir = img_dir\n        self.label_dir = label_dir\n        self.anchors = anchors\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.train_transforms = train_transforms\n        self.val_transforms = val_transforms\n        self.test_transforms = test_transforms\n        self.val_split = val_split\n        self.S = S\n        self.C = C\n        self.num_workers = num_workers\n        self.pin_memory = pin_memory\n        self.test_dataset = None\n        self.train_dataset = None\n        self.train_eval_dataset = None\n\n    def get_dataset_train(self):\n        return YOLODataset(self.train_csv_path,\n                           self.img_dir,\n                           self.label_dir,\n                           self.anchors,\n                           image_size=self.image_size,\n                           S=self.S,\n                           C=self.C,\n                           transform=self.train_transforms)\n\n\n    def get_dataset_test(self):\n        return YOLODataset(self.test_csv_path, \n                           self.img_dir,\n                           self.label_dir,\n                           self.anchors,\n                           image_size=self.image_size,\n                           S=self.S,\n                           C=self.C,\n                           transform=self.test_transforms)\n\n    def get_dataset_val(self):\n        return YOLODataset(self.train_csv_path,\n                           self.img_dir,\n                           self.label_dir,\n                           self.anchors,\n                           image_size=self.image_size,\n                           S=self.S,\n                           C=self.C,\n                           transform=self.test_transforms)\n\n\n    def _split_dataset(self, dataset: Dataset, train: bool = True) -> Dataset:\n        \"\"\"Splits the dataset into train and validation set.\"\"\"\n        len_dataset = len(dataset)\n        splits = self._get_splits(len_dataset)\n        dataset_train, dataset_val = random_split(dataset, splits, generator=torch.Generator().manual_seed(42))\n        if train:\n            return dataset_train\n        return dataset_val\n\n    def _get_splits(self, len_dataset: int) -> List[int]:\n        \"\"\"Computes split lengths for train and validation set.\"\"\"\n        if isinstance(self.val_split, int):\n            train_len = len_dataset - self.val_split\n            splits = [train_len, self.val_split]\n        elif isinstance(self.val_split, float):\n            val_len = int(self.val_split * len_dataset)\n            train_len = len_dataset - val_len\n            splits = [train_len, val_len]\n        else:\n            raise ValueError(f\"Unsupported type {type(self.val_split)}\")\n\n        return splits\n\n  \n    def prepare_data(self):\n        # Download the dataset\n        YOLODataset(self.train_csv_path, \n                    self.img_dir, \n                    self.label_dir, \n                    self.anchors,\n                    image_size=self.image_size, \n                    S=self.S,\n                    C=self.C, \n                    transform=self.train_transforms)\n        YOLODataset(self.test_csv_path, \n                    self.img_dir, \n                    self.label_dir, \n                    self.anchors,\n                    image_size=self.image_size, \n                    S=self.S,\n                    C=self.C, \n                    transform=self.test_transforms)\n        return\n\n    def setup(self, stage=None):\n        # Assign train/val datasets\n        if stage == 'fit' or stage is None:\n            dataset_train = self.get_dataset_train()\n            dataset_val = self.get_dataset_val()\n\n            # Split\n            self.train_dataset = self._split_dataset(dataset_train)\n            self.train_eval_dataset = self._split_dataset(dataset_val, train=False)\n\n        if stage == 'test' or stage:\n            self.test_dataset = self.get_dataset_test()\n\n    def train_dataloader(self):\n        train_data_loader = DataLoader(\n            dataset=self.train_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=True,\n            drop_last=False)\n        return train_data_loader\n\n    def val_dataloader(self):\n        val_data_loader = DataLoader(\n            dataset=self.train_eval_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=False,\n            drop_last=False)\n        return val_data_loader\n\n    def test_dataloader(self):\n        if self.test_dataset is None:\n            self.test_dataset = self.get_dataset_test()\n        test_data_loader = DataLoader(\n            dataset=self.test_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=False,\n            drop_last=False)\n        return test_data_loader","metadata":{"id":"lxXXyGjxZlrx","execution":{"iopub.status.busy":"2023-08-15T12:03:34.752110Z","iopub.execute_input":"2023-08-15T12:03:34.752507Z","iopub.status.idle":"2023-08-15T12:03:34.779140Z","shell.execute_reply.started":"2023-08-15T12:03:34.752473Z","shell.execute_reply":"2023-08-15T12:03:34.777840Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Put it all together!","metadata":{"id":"DE4icN1VpaBp"}},{"cell_type":"markdown","source":"Define Data Module","metadata":{"id":"Jo9tGpfAt81G"}},{"cell_type":"code","source":"# Define data module\n#csv_files = [os.path.join(config.DATASET, \"100examples.csv\"),os.path.join(config.DATASET,\"8examples.csv\")]\ncsv_files = [os.path.join(config.DATASET, \"train.csv\"),os.path.join(config.DATASET,\"test.csv\")]\n#config.NUM_EPOCHS = 20\ntrain_transforms=config.train_transforms\ntest_transforms=config.test_transforms\nval_transforms = test_transforms\nIMAGE_SIZE = config.IMAGE_SIZE\nS=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8]\nimg_dir=config.IMG_DIR\nlabel_dir=config.LABEL_DIR\nanchors=config.ANCHORS\nbatch_size = 8\nyolo_dm = YOLODataModule(\n    csv_files,\n    img_dir,\n    label_dir,\n    anchors,\n    batch_size,\n    image_size=IMAGE_SIZE,\n    S=S,\n    C=20,\n    train_transforms = train_transforms,\n    val_transforms = val_transforms,\n    test_transforms = test_transforms,\n    val_split=0.1,\n    num_workers = config.NUM_WORKERS,\n    pin_memory = False)\nyolo_dm.prepare_data()\nyolo_dm.setup()","metadata":{"id":"RN7BkD6YoObb","execution":{"iopub.status.busy":"2023-08-15T12:19:26.696238Z","iopub.execute_input":"2023-08-15T12:19:26.696606Z","iopub.status.idle":"2023-08-15T12:19:26.723372Z","shell.execute_reply.started":"2023-08-15T12:19:26.696575Z","shell.execute_reply":"2023-08-15T12:19:26.722409Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"Define Trainer","metadata":{}},{"cell_type":"code","source":"from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks.progress import TQDMProgressBar\nfrom pathlib import Path\nimport pytorch_lightning as pl\n\n\nclass PeriodicCheckpoint(ModelCheckpoint):\n    def __init__(self, dirpath: str, every: int = 1, verbose:bool = False):\n        super().__init__()\n        self.every = every\n        self.dirpath = dirpath\n        self.verbose=verbose\n\n    def on_train_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule, *args, **kwargs):\n        if self.every >=1 and (trainer.current_epoch +1) % self.every == 0:\n            assert self.dirpath is not None\n            current = Path(self.dirpath) / f\"checkpoint_epoch_{trainer.current_epoch}_step_{pl_module.global_step}.ckpt\"\n            trainer.save_checkpoint(current)\n            \ndef train_pl_model(model, datamodule, ckpt_path=None, epochs = 2):\n    trainer = Trainer(\n        enable_checkpointing=True,\n        max_epochs=epochs,\n        accelerator=\"auto\",\n        devices=1 if torch.cuda.is_available() else None,\n        logger=CSVLogger(save_dir=\"/kaggle/working/logs/\"),\n        callbacks=[LearningRateMonitor(logging_interval=\"step\"), \n                   TQDMProgressBar(refresh_rate=10), \n                   PeriodicCheckpoint(dirpath=\"/kaggle/working/logs/\",every=2, verbose=True)],\n        num_sanity_val_steps=0,\n        precision=16\n    )\n    \n    trainer.fit(model, datamodule.train_dataloader(), datamodule.val_dataloader(),ckpt_path=ckpt_path)\n    trainer.test(model, datamodule.test_dataloader())\n    return trainer","metadata":{"execution":{"iopub.status.busy":"2023-08-15T12:56:04.498364Z","iopub.execute_input":"2023-08-15T12:56:04.498967Z","iopub.status.idle":"2023-08-15T12:56:04.510679Z","shell.execute_reply.started":"2023-08-15T12:56:04.498925Z","shell.execute_reply":"2023-08-15T12:56:04.509700Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"Training From Scratch","metadata":{}},{"cell_type":"code","source":"from torch.optim.lr_scheduler import OneCycleLR\n\n# Define model parameters\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\nloss_criterion = YoloLoss()\nconf_threshold = config.CONF_THRESHOLD\nEPOCHS = config.NUM_EPOCHS * 2 // 5\n\n# Define Model\nyolo_model = LitYOLOv3(loss_criterion, scaled_anchors,conf_threshold, optimizer=None, scheduler_dict=None, num_classes=20, epochs=EPOCHS)\noptimizer = optim.Adam(yolo_model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\ntrain_data_loader = yolo_dm.train_dataloader()\nscheduler = OneCycleLR(\n        optimizer,\n        max_lr=1E-3,\n        steps_per_epoch=len(train_data_loader),\n        epochs=EPOCHS,\n        pct_start=5/EPOCHS,\n        div_factor=100,\n        three_phase=False,\n        final_div_factor=100,\n        anneal_strategy='linear'\n    )\nyolo_model.set_optimizer(optimizer)\nyolo_model.set_scheduler_dict(scheduler,freq='step')\n\n\n# train and eval model\ntrainer = train_pl_model(yolo_model, yolo_dm, epochs = EPOCHS)","metadata":{"id":"VB2YNtDauAeW","execution":{"iopub.status.busy":"2023-08-15T12:56:00.382812Z","iopub.execute_input":"2023-08-15T12:56:00.383283Z","iopub.status.idle":"2023-08-15T12:56:01.345793Z","shell.execute_reply.started":"2023-08-15T12:56:00.383242Z","shell.execute_reply":"2023-08-15T12:56:01.344665Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"Resume Training","metadata":{}},{"cell_type":"code","source":"# Define model parameters\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\nloss_criterion = YoloLoss()\nconf_threshold = config.CONF_THRESHOLD\n\n# Define Model\noptimizer = optim.Adam(yolo_model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\ntrain_data_loader = yolo_dm.train_dataloader()\nEPOCHS = config.NUM_EPOCHS * 2 // 5\nscheduler = OneCycleLR(\n        optimizer,\n        max_lr=1E-3,\n        steps_per_epoch=len(train_data_loader),\n        epochs=EPOCHS,\n        pct_start=5/EPOCHS,\n        div_factor=100,\n        three_phase=False,\n        final_div_factor=100,\n        anneal_strategy='linear'\n    )\nyolo_model = LitYOLOv3(loss_criterion, scaled_anchors,conf_threshold, optimizer=None, scheduler_dict=None, num_classes=20, epochs=20)\nyolo_model.set_optimizer(optimizer)\nyolo_model.set_scheduler_dict(scheduler,freq='step')\n\n# resume training\nckpt_path = \"/kaggle/working/logs/checkpoint_epoch_5_step_72.ckpt\"\ntrainer = train_pl_model(yolo_model, yolo_dm, epochs = EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-08-15T13:19:30.116336Z","iopub.execute_input":"2023-08-15T13:19:30.116747Z","iopub.status.idle":"2023-08-15T13:19:30.582239Z","shell.execute_reply.started":"2023-08-15T13:19:30.116711Z","shell.execute_reply":"2023-08-15T13:19:30.579821Z"},"trusted":true},"execution_count":88,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/IPython/core/\u001b[0m\u001b[1;33minteractiveshell.py\u001b[0m:\u001b[94m3508\u001b[0m in \u001b[92mrun_code\u001b[0m        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3505 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m async_:                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3506 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mawait\u001b[0m \u001b[96meval\u001b[0m(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3507 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3508 \u001b[2m│   │   │   │   │   \u001b[0mexec(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3509 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3510 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Reset our crash handler in place\u001b[0m                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3511 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msys.excepthook = old_excepthook                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m5\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0mscaled_anchors = (                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0mtorch.tensor(config.ANCHORS)                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   \u001b[0m* torch.tensor(config.S).unsqueeze(\u001b[94m1\u001b[0m).unsqueeze(\u001b[94m1\u001b[0m).repeat(\u001b[94m1\u001b[0m, \u001b[94m3\u001b[0m, \u001b[94m2\u001b[0m)                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 5 ).to(config.DEVICE)                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0mloss_criterion = YoloLoss()                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0mconf_threshold = config.CONF_THRESHOLD                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mRuntimeError: \u001b[0mCUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be \nincorrect.\nFor debugging consider passing \u001b[33mCUDA_LAUNCH_BLOCKING\u001b[0m=\u001b[1;36m1\u001b[0m.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/IPython/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">interactiveshell.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3508</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_code</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3505 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> async_:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3506 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">await</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">eval</span>(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3507 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3508 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>exec(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3509 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3510 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Reset our crash handler in place</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3511 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>sys.excepthook = old_excepthook                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>scaled_anchors = (                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>torch.tensor(config.ANCHORS)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>* torch.tensor(config.S).unsqueeze(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>).unsqueeze(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>).repeat(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 5 ).to(config.DEVICE)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>loss_criterion = YoloLoss()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>conf_threshold = config.CONF_THRESHOLD                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be \nincorrect.\nFor debugging consider passing <span style=\"color: #808000; text-decoration-color: #808000\">CUDA_LAUNCH_BLOCKING</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"EPOCHS","metadata":{"execution":{"iopub.status.busy":"2023-08-15T12:10:11.412755Z","iopub.execute_input":"2023-08-15T12:10:11.413203Z","iopub.status.idle":"2023-08-15T12:10:11.420918Z","shell.execute_reply.started":"2023-08-15T12:10:11.413166Z","shell.execute_reply":"2023-08-15T12:10:11.419779Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}]}]}