{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_13/s13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"First Connect Google Drive","metadata":{"id":"OZ4DqRTb9Ym8"}},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/gdrive/', force_remount=True)","metadata":{"id":"TDhBByBZ8qi9","outputId":"74ecf808-1a81-4f0d-d197-3614327b21d8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Install packages","metadata":{"id":"cgHQxuQMAJ5o"}},{"cell_type":"code","source":"!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n!git -C ERA_V1 pull\n#!cd ../\n!git clone \"https://github.com/jyanivaddi/dl_hub.git\"\n!git -C dl_hub pull\n!git pull\n#!cd ../\n\n!pip install --quiet \"torchinfo\" \"seaborn\" \"pytorch-lightning\" \"torchmetrics\" \"lightning-bolts\"\n!pip install --quiet \"prettytable\"\n!pip install --quiet \"torch_lr_finder\"\n!pip install --quiet \"grad-cam\"\n!pip install --quiet \"gradio\"","metadata":{"id":"VAOiUa_mAJVQ","outputId":"85e7cb94-0062-4173-f106-05d14f0d42b1","execution":{"iopub.status.busy":"2023-08-11T05:38:11.071143Z","iopub.execute_input":"2023-08-11T05:38:11.071498Z","iopub.status.idle":"2023-08-11T05:39:17.079028Z","shell.execute_reply.started":"2023-08-11T05:38:11.071464Z","shell.execute_reply":"2023-08-11T05:39:17.077629Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"fatal: destination path 'ERA_V1' already exists and is not an empty directory.\nAlready up to date.\nfatal: destination path 'dl_hub' already exists and is not an empty directory.\nAlready up to date.\nfatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append(\"ERA_V1/session_13\")\nsys.path.append(\"dl_hub\")","metadata":{"id":"ivBzl8YFPvJ0","execution":{"iopub.status.busy":"2023-08-11T05:40:20.967173Z","iopub.execute_input":"2023-08-11T05:40:20.967579Z","iopub.status.idle":"2023-08-11T05:40:20.972902Z","shell.execute_reply.started":"2023-08-11T05:40:20.967546Z","shell.execute_reply":"2023-08-11T05:40:20.971823Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!git -C dl_hub pull\n","metadata":{"id":"n41Pe-b1J3mC","outputId":"2d7d2842-8bfc-459a-beb0-11002dcb6484","execution":{"iopub.status.busy":"2023-08-11T05:40:25.221053Z","iopub.execute_input":"2023-08-11T05:40:25.221430Z","iopub.status.idle":"2023-08-11T05:40:26.431893Z","shell.execute_reply.started":"2023-08-11T05:40:25.221398Z","shell.execute_reply":"2023-08-11T05:40:26.430552Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Already up to date.\n","output_type":"stream"}]},{"cell_type":"code","source":"import dl_hub.models.YOLO_V3.config as config\nimport torch\nimport torch.optim as optim\n\nfrom dl_hub.models.YOLO_V3.model import YOLOv3\nfrom tqdm import tqdm\nfrom dl_hub.models.YOLO_V3.utils import (\n    mean_average_precision,\n    cells_to_bboxes,\n    get_evaluation_bboxes,\n    save_checkpoint,\n    load_checkpoint,\n    check_class_accuracy,\n    get_loaders,\n    plot_couple_examples\n)\nfrom dl_hub.models.YOLO_V3.loss import YoloLoss\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"x8WpKATx75Hu","execution":{"iopub.status.busy":"2023-08-11T05:40:28.606651Z","iopub.execute_input":"2023-08-11T05:40:28.607078Z","iopub.status.idle":"2023-08-11T05:40:31.129047Z","shell.execute_reply.started":"2023-08-11T05:40:28.607042Z","shell.execute_reply":"2023-08-11T05:40:31.127924Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\ndef train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, scheduler):\n    loop = tqdm(train_loader, leave=True)\n    losses = []\n    for batch_idx, (x, y) in enumerate(loop):\n        x = x.to(config.DEVICE)\n        y0, y1, y2 = (\n            y[0].to(config.DEVICE),\n            y[1].to(config.DEVICE),\n            y[2].to(config.DEVICE),\n        )\n\n        with torch.cuda.amp.autocast():\n            out = model(x)\n            loss = (\n                loss_fn(out[0], y0, scaled_anchors[0])\n                + loss_fn(out[1], y1, scaled_anchors[1])\n                + loss_fn(out[2], y2, scaled_anchors[2])\n            )\n\n        losses.append(loss.item())\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n\n        # update progress bar\n        mean_loss = sum(losses) / len(losses)\n        loop.set_postfix(loss=mean_loss)","metadata":{"id":"w4GDrpX975Hx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\ntorch.cuda.empty_cache()","metadata":{"id":"TDkVV-JtKJUI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\n\nmodel = YOLOv3(num_classes=config.NUM_CLASSES).to(config.DEVICE)\noptimizer = optim.Adam(\n    model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY\n)\nloss_fn = YoloLoss()\nscaler = torch.cuda.amp.GradScaler()\n\ntrain_loader, test_loader, train_eval_loader = get_loaders(\n    train_csv_path=config.DATASET + \"/100examples.csv\", test_csv_path=config.DATASET + \"/8examples.csv\"\n)\n\nif config.LOAD_MODEL:\n    load_checkpoint(\n        config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE\n    )\n","metadata":{"id":"3DtkSQ9b75H0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\n\nfrom torch_lr_finder import LRFinder\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\n\ndef criterion(out, y):\n    y0, y1, y2 = (\n            y[0].to(config.DEVICE),\n            y[1].to(config.DEVICE),\n            y[2].to(config.DEVICE),\n        )\n    loss = (\n                loss_fn(out[0], y0, scaled_anchors[0])\n                + loss_fn(out[1], y1, scaled_anchors[1])\n                + loss_fn(out[2], y2, scaled_anchors[2])\n            )\n    return loss\nlr_finder = LRFinder(model, optimizer, criterion, device=device)\nlr_finder.range_test(train_loader, end_lr=10, num_iter=200, step_mode=\"exp\")\nlr_finder.plot() # to inspect the loss-learning rate graph\nlr_finder.reset() # to reset the model and optimizer to their initial state","metadata":{"id":"3P9vTBy475H1","outputId":"a2711398-2d5b-4cf4-fd64-7837f85c45f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NO NEED TO RUN THIS....FOR REFERENCE ONLY\n\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\n\n\nfrom torch.optim.lr_scheduler import OneCycleLR\nEPOCHS = config.NUM_EPOCHS * 2 // 5\nscheduler = OneCycleLR(\n        optimizer,\n        max_lr=1E-3,\n        steps_per_epoch=len(train_loader),\n        epochs=EPOCHS,\n        pct_start=5/EPOCHS,\n        div_factor=100,\n        three_phase=False,\n        final_div_factor=100,\n        anneal_strategy='linear'\n    )\n\nfor epoch in range(EPOCHS):\n    #plot_couple_examples(model, test_loader, 0.6, 0.5, scaled_anchors)\n    train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, scheduler)\n\n    #if config.SAVE_MODEL:\n    #   save_checkpoint(model, optimizer, filename=f\"checkpoint.pth.tar\")\n\n    print(f\"Currently epoch {epoch}\")\n    print(\"On Train Eval loader:\")\n    print(\"On Train loader:\")\n    check_class_accuracy(model, train_loader, threshold=config.CONF_THRESHOLD)\n\n    if epoch > 0 and epoch % 3 == 0:\n        check_class_accuracy(model, test_loader, threshold=config.CONF_THRESHOLD)\n        pred_boxes, true_boxes = get_evaluation_bboxes(\n            test_loader,\n            model,\n            iou_threshold=config.NMS_IOU_THRESH,\n            anchors=config.ANCHORS,\n            threshold=config.CONF_THRESHOLD,\n        )\n        mapval = mean_average_precision(\n            pred_boxes,\n            true_boxes,\n            iou_threshold=config.MAP_IOU_THRESH,\n            box_format=\"midpoint\",\n            num_classes=config.NUM_CLASSES,\n        )\n        print(f\"MAP: {mapval.item()}\")\n        model.train()","metadata":{"id":"_PQZ3wqP75H4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Pytorch Lightning Definitions**","metadata":{"id":"JG-vYgIZNS7J"}},{"cell_type":"markdown","source":"Define Model","metadata":{"id":"eZwoyfhNoH3A"}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom pytorch_lightning import LightningModule\nfrom torchmetrics.functional import accuracy\n\n\nclass LitYOLOv3(LightningModule):\n    def __init__(self,\n                 loss_criterion,\n                 scaled_anchors,\n                 conf_threshold,\n                 optimizer=None,\n                 scheduler_dict=None,\n                 num_classes=10,\n                 epochs=20):\n        super().__init__()\n\n        self.save_hyperparameters()\n        self.model = YOLOv3(num_classes=num_classes)\n        self.loss_criterion = loss_criterion\n        self.scaled_anchors = scaled_anchors\n        self.conf_threshold = conf_threshold\n        self.optimizer = None\n        self.scheduler_dict = None\n        self.epochs = epochs\n\n    def set_optimizer(self, optimizer):\n        self.optimizer = optimizer\n\n    def set_scheduler_dict(self, scheduler, freq='step'):\n        self.scheduler = scheduler\n        self.scheduler_dict = {\n            \"scheduler\": self.scheduler,\n            \"interval\": freq,\n        }\n\n    def forward(self, x):\n        return self.model.forward(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y0, y1, y2 = (y[0],y[1],y[2])\n\n        out = self(x)\n        loss = (\n                self.loss_criterion(out[0], y0, self.scaled_anchors[0]) +\n                self.loss_criterion(out[1], y1, self.scaled_anchors[1]) +\n                self.loss_criterion(out[2], y2, self.scaled_anchors[2])\n            )\n        self.log(\"train_loss\", loss, prog_bar=True)\n        return loss\n\n    def evaluate(self, batch, stage=None):\n        \"\"\"\n        Evaluate the model on validation dataset.\n        we compute the class accuracy, the no object accuracy, and the object accuracy\n        \"\"\"\n\n        tot_class_preds, correct_class = 0, 0\n        tot_noobj, correct_noobj = 0, 0\n        tot_obj, correct_obj = 0, 0\n        x, y = batch\n        out = self(x)\n\n        for i in range(3):\n            obj = y[i][..., 0] == 1 # in paper this is Iobj_i\n            noobj = y[i][..., 0] == 0  # in paper this is Iobj_i\n            correct_class += torch.sum(\n                torch.argmax(out[i][..., 5:][obj], dim=-1) == y[i][..., 5][obj]\n            )\n            tot_class_preds += torch.sum(obj)\n\n            obj_preds = torch.sigmoid(out[i][..., 0]) > self.conf_threshold\n            correct_obj += torch.sum(obj_preds[obj] == y[i][..., 0][obj])\n            tot_obj += torch.sum(obj)\n            correct_noobj += torch.sum(obj_preds[noobj] == y[i][..., 0][noobj])\n            tot_noobj += torch.sum(noobj)\n\n        if stage:\n            class_acc = (correct_class/(tot_class_preds+1e-16))*100\n            no_obj_acc = (correct_noobj/(tot_noobj+1e-16))*100\n            obj_acc = (correct_obj/(tot_obj+1e-16))*100\n            self.log(f\"{stage}_Class_Accuracy\",class_acc, prog_bar=True)\n            self.log(f\"{stage}_No_Obj_Accuracy\", no_obj_acc, prog_bar=True)\n            self.log(f\"{stage}_Obj_Accuracy\",obj_acc, prog_bar=True)\n\n\n    def validation_step(self, batch, batch_idx):\n        self.evaluate(batch, \"val\")\n\n    def test_step(self, batch, batch_id):\n        self.evaluate(batch, \"test\")\n\n    def configure_optimizers(self):\n        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler_dict}\n\n\n","metadata":{"id":"OEH_n7lFNU5k","execution":{"iopub.status.busy":"2023-08-11T06:10:23.638583Z","iopub.execute_input":"2023-08-11T06:10:23.639452Z","iopub.status.idle":"2023-08-11T06:10:23.663497Z","shell.execute_reply.started":"2023-08-11T06:10:23.639411Z","shell.execute_reply":"2023-08-11T06:10:23.662334Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Define DataModule","metadata":{"id":"fCmFIu5XoEU7"}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom typing import List, Any\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom pytorch_lightning import LightningDataModule, seed_everything\nfrom dl_hub.models.YOLO_V3.dataset_org import YOLODataset\n\n\n\nclass YOLODataModule(LightningDataModule):\n    def __init__(self,\n                 csv_files,\n                 img_dir,\n                 label_dir,\n                 anchors,\n                 batch_size,\n                 image_size=416,\n                 S=[13, 26, 52],\n                 C=20,\n                 train_transforms = None,\n                 val_transforms = None,\n                 test_transforms = None,\n                 val_split=0.2,\n                 num_workers = 1,\n                 pin_memory = False):\n\n        # Initialize the class. Set up the datadir, image dims, and num classes\n        super().__init__()\n        self.train_csv_path, self.test_csv_path = csv_files\n        self.img_dir = img_dir\n        self.label_dir = label_dir\n        self.anchors = anchors\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.train_transforms = train_transforms\n        self.val_transforms = val_transforms\n        self.test_transforms = test_transforms\n        self.val_split = val_split\n        self.S = S\n        self.C = C\n        self.num_workers = num_workers\n        self.pin_memory = pin_memory\n\n    def get_dataset_train(self):\n        return YOLODataset(self.train_csv_path,\n                           self.img_dir,\n                           self.label_dir,\n                           self.anchors,\n                           image_size=self.image_size,\n                           S=self.S,\n                           C=self.C,\n                           transform=self.train_transforms)\n\n\n    def get_dataset_test(self):\n        return YOLODataset(self.test_csv_path, \n                           self.img_dir,\n                           self.label_dir,\n                           self.anchors,\n                           image_size=self.image_size,\n                           S=self.S,\n                           C=self.C,\n                           transform=self.test_transforms)\n\n    def get_dataset_val(self):\n        return YOLODataset(self.train_csv_path,\n                           self.img_dir,\n                           self.label_dir,\n                           self.anchors,\n                           image_size=self.image_size,\n                           S=self.S,\n                           C=self.C,\n                           transform=self.test_transforms)\n\n\n    def _split_dataset(self, dataset: Dataset, train: bool = True) -> Dataset:\n        \"\"\"Splits the dataset into train and validation set.\"\"\"\n        len_dataset = len(dataset)\n        splits = self._get_splits(len_dataset)\n        dataset_train, dataset_val = random_split(dataset, splits, generator=torch.Generator().manual_seed(42))\n        if train:\n            return dataset_train\n        return dataset_val\n\n    def _get_splits(self, len_dataset: int) -> List[int]:\n        \"\"\"Computes split lengths for train and validation set.\"\"\"\n        if isinstance(self.val_split, int):\n            train_len = len_dataset - self.val_split\n            splits = [train_len, self.val_split]\n        elif isinstance(self.val_split, float):\n            val_len = int(self.val_split * len_dataset)\n            train_len = len_dataset - val_len\n            splits = [train_len, val_len]\n        else:\n            raise ValueError(f\"Unsupported type {type(self.val_split)}\")\n\n        return splits\n\n  \n    def prepare_data(self):\n        # Download the dataset\n        YOLODataset(self.train_csv_path, \n                    self.img_dir, \n                    self.label_dir, \n                    self.anchors,\n                    image_size=self.image_size, \n                    S=self.S,\n                    C=self.C, \n                    transform=self.train_transforms)\n        YOLODataset(self.test_csv_path, \n                    self.img_dir, \n                    self.label_dir, \n                    self.anchors,\n                    image_size=self.image_size, \n                    S=self.S,\n                    C=self.C, \n                    transform=self.test_transforms)\n        return\n\n    def setup(self, stage=None):\n        # Assign train/val datasets\n        if stage == 'fit' or stage is None:\n            dataset_train = self.get_dataset_train()\n            dataset_val = self.get_dataset_val()\n\n            # Split\n            self.train_dataset = self._split_dataset(dataset_train)\n            self.train_eval_dataset = self._split_dataset(dataset_val, train=False)\n\n        if stage == 'test' or stage:\n            self.test_dataset = self.get_dataset_test()\n\n    def train_dataloader(self):\n        train_data_loader = DataLoader(\n            dataset=self.train_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=True,\n            drop_last=False)\n        return train_data_loader\n\n    def val_dataloader(self):\n        val_data_loader = DataLoader(\n            dataset=self.train_eval_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=False,\n            drop_last=False)\n        return val_data_loader\n\n    def test_dataloader(self):\n        test_data_loader = DataLoader(\n            dataset=self.test_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory,\n            shuffle=False,\n            drop_last=False)\n        return test_data_loader","metadata":{"id":"lxXXyGjxZlrx","execution":{"iopub.status.busy":"2023-08-11T05:40:44.983080Z","iopub.execute_input":"2023-08-11T05:40:44.983461Z","iopub.status.idle":"2023-08-11T05:40:45.010553Z","shell.execute_reply.started":"2023-08-11T05:40:44.983427Z","shell.execute_reply":"2023-08-11T05:40:45.009340Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Put it all together!","metadata":{"id":"DE4icN1VpaBp"}},{"cell_type":"markdown","source":"Define Data Module","metadata":{"id":"Jo9tGpfAt81G"}},{"cell_type":"code","source":"# Define data module\ncsv_files = [os.path.join(config.DATASET, \"train.csv\"),os.path.join(config.DATASET,\"test.csv\")]\ntrain_transforms=config.train_transforms\ntest_transforms=config.test_transforms\nval_transforms = test_transforms\nIMAGE_SIZE = config.IMAGE_SIZE\nS=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8]\nimg_dir=config.IMG_DIR\nlabel_dir=config.LABEL_DIR\nanchors=config.ANCHORS\nbatch_size = 8\nyolo_dm = YOLODataModule(\n    csv_files,\n    img_dir,\n    label_dir,\n    anchors,\n    batch_size,\n    image_size=IMAGE_SIZE,\n    S=S,\n    C=20,\n    train_transforms = train_transforms,\n    val_transforms = val_transforms,\n    test_transforms = test_transforms,\n    val_split=0.1,\n    num_workers = config.NUM_WORKERS,\n    pin_memory = False)\nyolo_dm.prepare_data()\nyolo_dm.setup()","metadata":{"id":"RN7BkD6YoObb","execution":{"iopub.status.busy":"2023-08-11T05:58:02.197111Z","iopub.execute_input":"2023-08-11T05:58:02.197491Z","iopub.status.idle":"2023-08-11T05:58:02.278850Z","shell.execute_reply.started":"2023-08-11T05:58:02.197461Z","shell.execute_reply":"2023-08-11T05:58:02.277861Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import OneCycleLR\n\n# Define model\nscaled_anchors = (\n    torch.tensor(config.ANCHORS)\n    * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n).to(config.DEVICE)\nloss_criterion = YoloLoss()\nconf_threshold = config.CONF_THRESHOLD\nyolo_model = LitYOLOv3(loss_criterion, scaled_anchors,conf_threshold, optimizer=None, scheduler_dict=None, num_classes=20, epochs=20)\noptimizer = optim.Adam(yolo_model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\ntrain_data_loader = yolo_dm.train_dataloader()\nEPOCHS = config.NUM_EPOCHS * 2 // 5\nscheduler = OneCycleLR(\n        optimizer,\n        max_lr=1E-3,\n        steps_per_epoch=len(train_data_loader),\n        epochs=EPOCHS,\n        pct_start=5/EPOCHS,\n        div_factor=100,\n        three_phase=False,\n        final_div_factor=100,\n        anneal_strategy='linear'\n    )\nyolo_model.set_optimizer(optimizer)\nyolo_model.set_scheduler_dict(scheduler,freq='step')","metadata":{"id":"VB2YNtDauAeW","execution":{"iopub.status.busy":"2023-08-11T06:10:33.465610Z","iopub.execute_input":"2023-08-11T06:10:33.466022Z","iopub.status.idle":"2023-08-11T06:10:34.181639Z","shell.execute_reply.started":"2023-08-11T06:10:33.465980Z","shell.execute_reply":"2023-08-11T06:10:34.180595Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from pytorch_lightning.callbacks import LearningRateMonitor, Callback\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks.progress import TQDMProgressBar\n\ndef save_checkpoint(model, optimizer, epoch, filename):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n        \"epoch\": epoch\n    }\n    torch.save(checkpoint, filename)\n\n\nclass SaveCallback(Callback):\n    def on_validation_epoch_end(self, trainer, model):\n        print(model.current_epoch)\n        if int(model.current_epoch) % 5 == 0:\n            curr_lr = model.scheduler.get_lr()\n            save_checkpoint(model, model.optimizer, model.current_epoch, filename=f\"checkpoint_{model.current_epoch}_{curr_lr}.pth.tar\")\n        print(f\"Model saved at the end of epoch number: {model.current_epoch}!\")\n\ndef train_pl_model(model, datamodule, epochs = 2):\n    trainer = Trainer(\n        max_epochs=epochs,\n        accelerator=\"auto\",\n        devices=1 if torch.cuda.is_available() else None,\n        logger=CSVLogger(save_dir=\"logs/\"),\n        callbacks=[LearningRateMonitor(logging_interval=\"step\"), TQDMProgressBar(refresh_rate=10), SaveCallback()],\n        num_sanity_val_steps=0,\n        precision=16\n    )\n    \n    trainer.fit(model, datamodule.train_dataloader(), datamodule.val_dataloader())\n    trainer.test(model, datamodule.test_dataloader())\n    return trainer","metadata":{"execution":{"iopub.status.busy":"2023-08-11T06:27:00.080813Z","iopub.execute_input":"2023-08-11T06:27:00.081512Z","iopub.status.idle":"2023-08-11T06:27:00.094946Z","shell.execute_reply.started":"2023-08-11T06:27:00.081471Z","shell.execute_reply":"2023-08-11T06:27:00.093925Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\n# Print Model Summary\n#model_summary(resnet_model, input_size = (3,32,32))\n# train and eval model\ntrainer = train_pl_model(yolo_model, yolo_dm, epochs = EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T06:27:07.000440Z","iopub.execute_input":"2023-08-11T06:27:07.000817Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bc44a3f1dc04cb3bec176f921d9d7ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"0\n=> Saving checkpoint\nModel saved at the end of epoch number: 0!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"1\nModel saved at the end of epoch number: 1!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"2\nModel saved at the end of epoch number: 2!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"3\nModel saved at the end of epoch number: 3!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"4\nModel saved at the end of epoch number: 4!\n","output_type":"stream"}]}]}