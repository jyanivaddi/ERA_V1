{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_20/S20_StableDiffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbqeso8Ztr9e",
        "outputId": "0745442c-87d9-4bb5-82d3-5b8b5e5f3957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ERA_V1' already exists and is not an empty directory.\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n",
        "!git -C ERA_V1 pull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/ERA_V1/session_20')"
      ],
      "metadata": {
        "id": "GmstN3L8uSiX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a4UiRjHCdos0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ade80d-e732-49f9-db11-065b6d8e8641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement colorsys (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for colorsys\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -qq -U datasets transformers pyarrow==9.0.0\n",
        "%pip install -qq --upgrade transformers==4.25.1 diffusers ftfy accelerate\n",
        "%pip install -qq colorsys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "d579eab4370d43e7ae1c38c363121d12",
            "4c7593066e144c4f9ece06042b2b269a",
            "e11f8d8d6f67432289eadd267bda46e5",
            "ced61498e7e9481a80423626de24e738",
            "d5017ffc722746a298914d12eff1ed99",
            "8ecb664487814155907340d582e90c02",
            "24ebed8a68a541c3a8c97997bb7f05e7",
            "fc1465597f8e468bbf7b19d5246ac528",
            "b4e84f4d99b148d190cfd8dfdeddcf3c",
            "99c62d5fee0846fa99bf100626ee7926",
            "c863baa407bb4537998d2a222bffcd80",
            "b8e036bca2234698990104b0ca5d1317",
            "61fbd33cd81f40ae9929a79bac677df9",
            "da5dd5d5d075468daa979ead268312da",
            "596bd7e8d6f4490faa4f4ea79ae10f4e",
            "356072e83ef14c8fb98ce8fe5d5e5938",
            "24e76d1be16e4e9a9e3b8b4eb7f2aefa"
          ]
        },
        "id": "HbJEbaWFdY_j",
        "outputId": "413d0d99-76af-472a-ddb8-e9b005d2ec4c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d579eab4370d43e7ae1c38c363121d12"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "61PK2B6YeCQ5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!sudo apt -qq install git-lfs\n",
        "!git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sizyFWdNgGw5"
      },
      "outputs": [],
      "source": [
        "from base64 import b64encode\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from diffusers import AutoencoderKL, LMSDiscreteScheduler, UNet2DConditionModel\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch import autocast\n",
        "from torchvision import transforms as tfms\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import CLIPTextModel, CLIPTokenizer, logging\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "torch.manual_seed(1)\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7WLtlxGOmP76"
      },
      "outputs": [],
      "source": [
        "# Load the autoencoder\n",
        "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder='vae')\n",
        "\n",
        "# Load tokenizer and text encoder to tokenize and encode the text\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Unet model for generating latents\n",
        "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder='unet')\n",
        "\n",
        "# Noise scheduler\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "\n",
        "\n",
        "# Move everything to GPU\n",
        "vae = vae.to(torch_device)\n",
        "text_encoder = text_encoder.to(torch_device)\n",
        "unet = unet.to(torch_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UWNmhJtatNq"
      },
      "source": [
        "**Generate Clip embeddings for input text embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "12LARdS8asL3"
      },
      "outputs": [],
      "source": [
        "# Prep Scheduler\n",
        "def set_timesteps(scheduler, num_inference_steps):\n",
        "    scheduler.set_timesteps(num_inference_steps)\n",
        "    scheduler.timesteps = scheduler.timesteps.to(torch.float32) # minor fix to ensure MPS compatibility, fixed in diffusers PR 3925\n",
        "\n",
        "def get_output_embeds(input_embeddings):\n",
        "    # CLIP's text model uses causal mask, so we prepare it here:\n",
        "    bsz, seq_len = input_embeddings.shape[:2]\n",
        "    causal_attention_mask = text_encoder.text_model._build_causal_attention_mask(bsz, seq_len, dtype=input_embeddings.dtype)\n",
        "\n",
        "    # Getting the output embeddings involves calling the model with passing output_hidden_states=True\n",
        "    # so that it doesn't just return the pooled final predictions:\n",
        "    encoder_outputs = text_encoder.text_model.encoder(\n",
        "        inputs_embeds=input_embeddings,\n",
        "        attention_mask=None, # We aren't using an attention mask so that can be None\n",
        "        causal_attention_mask=causal_attention_mask.to(torch_device),\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=True, # We want the output embs not the final output\n",
        "        return_dict=None,\n",
        "    )\n",
        "\n",
        "    # We're interested in the output hidden state only\n",
        "    output = encoder_outputs[0]\n",
        "\n",
        "    # There is a final layer norm we need to pass these through\n",
        "    output = text_encoder.text_model.final_layer_norm(output)\n",
        "\n",
        "    # And now they're ready!\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIb3-tobaUfq"
      },
      "source": [
        "**Generate with input embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create custom embeddings**"
      ],
      "metadata": {
        "id": "I2jxawH9wEyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "style_files = ['/content/ERA_V1/session_20/learned_embeds_style_0.bin',\n",
        "               '/content/ERA_V1/session_20/learned_embeds_style_10.bin',\n",
        "               '/content/ERA_V1/session_20/learned_embeds_style_2.bin',\n",
        "               '/content/ERA_V1/session_20/learned_embeds_style_5.bin',\n",
        "               '/content/ERA_V1/session_20/learned_embeds_style_8.bin']\n",
        "\n",
        "def get_style_embeddings(style_file):\n",
        "    style_embed = torch.load(style_file)\n",
        "    style_name = list(style_embed.keys())[0]\n",
        "    return style_embed[style_name]\n",
        "\n",
        "def get_EOS_pos_in_prompt(prompt):\n",
        "    return len(prompt.split())+1"
      ],
      "metadata": {
        "id": "dOHKIpzNwMob"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Custom Loss**"
      ],
      "metadata": {
        "id": "QhQMUBzUkw8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb2hsv_torch(rgb: torch.Tensor) -> torch.Tensor:\n",
        "    cmax, cmax_idx = torch.max(rgb, dim=1, keepdim=True)\n",
        "    cmin = torch.min(rgb, dim=1, keepdim=True)[0]\n",
        "    delta = cmax - cmin\n",
        "    hsv_h = torch.empty_like(rgb[:, 0:1, :, :])\n",
        "    cmax_idx[delta == 0] = 3\n",
        "    hsv_h[cmax_idx == 0] = (((rgb[:, 1:2] - rgb[:, 2:3]) / delta) % 6)[cmax_idx == 0]\n",
        "    hsv_h[cmax_idx == 1] = (((rgb[:, 2:3] - rgb[:, 0:1]) / delta) + 2)[cmax_idx == 1]\n",
        "    hsv_h[cmax_idx == 2] = (((rgb[:, 0:1] - rgb[:, 1:2]) / delta) + 4)[cmax_idx == 2]\n",
        "    hsv_h[cmax_idx == 3] = 0.\n",
        "    hsv_h /= 6.\n",
        "    hsv_s = torch.where(cmax == 0, torch.tensor(0.).type_as(rgb), delta / cmax)\n",
        "    hsv_v = cmax\n",
        "    return torch.cat([hsv_h, hsv_s, hsv_v], dim=1)\n",
        "\n",
        "def hsv_loss(gen_image):\n",
        "    gen_image_hsv = rgb2hsv_torch(gen_image.clone())\n",
        "    loss = torch.abs(gen_image_hsv[:,2] - 0.9).mean() # [:,2] -> all images in batch, only the blue channel\n",
        "    return loss\n",
        "\n",
        "def blue_loss(images):\n",
        "    # How far are the blue channel values to 0.9:\n",
        "    error = torch.abs(images[:,2] - 0.9).mean() # [:,2] -> all images in batch, only the blue channel\n",
        "    return error\n",
        "\n",
        "def hsv_loss22(gen_image):\n",
        "    # read the input RGB image as BGR format\n",
        "    bgr_img = cv2.cvtColor(gen_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Convert the BGR image to HSV Image\n",
        "    hsv_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
        "    print(hsv_img.shape)\n",
        "    tensor_transform = ToTensor()\n",
        "    hsv_tensor = tensor_transform(hsv_img).permute(1,0,2).requires_grad_()\n",
        "    print(hsv_tensor.shape)\n",
        "\n",
        "    # Convert to numpy array\n",
        "    #hsv_img_np = torch.tensor(np.array(hsv_img)).requires_grad_()\n",
        "    error = torch.abs(hsv_tensor[:,2] - 0.9).mean() # [:,2] -> all images in batch, only the blue channel\n",
        "    return error"
      ],
      "metadata": {
        "id": "uYOD_Ok3kzK-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the custom embeddings**"
      ],
      "metadata": {
        "id": "vzB0J21uxbIz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xipfQ77aaY-a"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "def pil_to_latent(input_im):\n",
        "    # Single image -> single latent in a batch (so size 1, 4, 64, 64)\n",
        "    with torch.no_grad():\n",
        "        latent = vae.encode(tfms.ToTensor()(input_im).unsqueeze(0).to(torch_device)*2-1) # Note scaling\n",
        "    return 0.18215 * latent.latent_dist.sample()\n",
        "\n",
        "def latents_to_pil(latents):\n",
        "    # bath of latents -> list of images\n",
        "    latents = (1 / 0.18215) * latents\n",
        "    with torch.no_grad():\n",
        "        image = vae.decode(latents).sample\n",
        "    image = (image / 2 + 0.5).clamp(0, 1)\n",
        "    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
        "    images = (image * 255).round().astype(\"uint8\")\n",
        "    pil_images = [Image.fromarray(image) for image in images]\n",
        "    return pil_images\n",
        "\n",
        "\n",
        "\n",
        "def additional_guidance(latents, scheduler, noise_pred, t, sigma, custom_loss_fn, custom_loss_scale):\n",
        "    #### ADDITIONAL GUIDANCE ###\n",
        "    # Requires grad on the latents\n",
        "    latents = latents.detach().requires_grad_()\n",
        "\n",
        "    # Get the predicted x0:\n",
        "    latents_x0 = latents - sigma * noise_pred\n",
        "    print(f\"latents: {latents.shape}, noise_pred:{noise_pred.shape}\")\n",
        "    #latents_x0 = scheduler.step(noise_pred, t, latents).pred_original_sample\n",
        "\n",
        "    # Decode to image space\n",
        "    denoised_images = vae.decode((1 / 0.18215) * latents_x0).sample / 2 + 0.5 # range (0, 1)\n",
        "    #denoised_images = np.asarray(denoised_images.detach().cpu())\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = custom_loss_fn(denoised_images) * custom_loss_scale\n",
        "    #print(loss)\n",
        "\n",
        "    # Get gradient\n",
        "    cond_grad = torch.autograd.grad(loss, latents)[0]\n",
        "    #print(cond_grad)\n",
        "\n",
        "    # Modify the latents based on this gradient\n",
        "    latents = latents.detach() - cond_grad * sigma**2\n",
        "    return latents, loss\n",
        "\n",
        "\n",
        "def generate_with_embs(text_embeddings, max_length, random_seed, custom_loss_fn = None, custom_loss_scale=1.0):\n",
        "    height = 64                        # default height of Stable Diffusion\n",
        "    width = 64                         # default width of Stable Diffusion\n",
        "    num_inference_steps = 30            # Number of denoising steps\n",
        "    guidance_scale = 7.5                # Scale for classifier-free guidance\n",
        "    generator = torch.manual_seed(random_seed)   # Seed generator to create the inital latent noise\n",
        "    batch_size = 1\n",
        "\n",
        "    uncond_input = tokenizer(\n",
        "      [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\n",
        "    text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "\n",
        "    # Prep Scheduler\n",
        "    set_timesteps(scheduler, num_inference_steps)\n",
        "\n",
        "    # Prep latents\n",
        "    latents = torch.randn(\n",
        "    (batch_size, unet.in_channels, height // 8, width // 8),\n",
        "    generator=generator,\n",
        "    )\n",
        "    latents = latents.to(torch_device)\n",
        "    latents = latents * scheduler.init_noise_sigma\n",
        "\n",
        "    # Loop\n",
        "    for i, t in tqdm(enumerate(scheduler.timesteps), total=len(scheduler.timesteps)):\n",
        "        # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
        "        latent_model_input = torch.cat([latents] * 2)\n",
        "        sigma = scheduler.sigmas[i]\n",
        "        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
        "\n",
        "        # predict the noise residual\n",
        "        with torch.no_grad():\n",
        "            noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings)[\"sample\"]\n",
        "\n",
        "        # perform guidance\n",
        "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "        if custom_loss_fn is not None:\n",
        "            if i%5 == 0:\n",
        "                latents, custom_loss = additional_guidance(latents, scheduler, noise_pred, t, sigma, custom_loss_fn, custom_loss_scale)\n",
        "                print(i, 'loss:', custom_loss.item())\n",
        "\n",
        "        # compute the previous noisy sample x_t -> x_t-1\n",
        "        latents = scheduler.step(noise_pred, t, latents).prev_sample\n",
        "\n",
        "    return latents_to_pil(latents)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image_with_custom_style(prompt, style_num=None, random_seed=41, custom_loss_fn = None, custom_loss_scale=1.0):\n",
        "    eos_pos = get_EOS_pos_in_prompt(prompt)\n",
        "\n",
        "    style_token_embedding = None\n",
        "    if style_num:\n",
        "        style_token_embedding = get_style_embeddings(style_files[style_num])\n",
        "\n",
        "    # tokenize\n",
        "    text_input = tokenizer(prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
        "    max_length = text_input.input_ids.shape[-1]\n",
        "    input_ids = text_input.input_ids.to(torch_device)\n",
        "\n",
        "    # get token embeddings\n",
        "    token_emb_layer = text_encoder.text_model.embeddings.token_embedding\n",
        "    token_embeddings = token_emb_layer(input_ids)\n",
        "\n",
        "    # Append style token towards the end of the sentence embeddings\n",
        "    if style_token_embedding is not None:\n",
        "        token_embeddings[-1, eos_pos, :] = style_token_embedding\n",
        "\n",
        "    # combine with pos embs\n",
        "    pos_emb_layer = text_encoder.text_model.embeddings.position_embedding\n",
        "    position_ids = text_encoder.text_model.embeddings.position_ids[:, :77]\n",
        "    position_embeddings = pos_emb_layer(position_ids)\n",
        "    input_embeddings = token_embeddings + position_embeddings\n",
        "\n",
        "    #  Feed through to get final output embs\n",
        "    modified_output_embeddings = get_output_embeds(input_embeddings)\n",
        "\n",
        "    # And generate an image with this:\n",
        "    generated_image = generate_with_embs(modified_output_embeddings, max_length, random_seed, custom_loss_fn, custom_loss_scale)\n",
        "    return generated_image"
      ],
      "metadata": {
        "id": "NQg8sTb19Xhf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images_list):\n",
        "    # Let's visualize the four channels of this latent representation:\n",
        "    fig, axs = plt.subplots(1, len(images_list), figsize=(16, 4))\n",
        "    for c in range(len(images_list)):\n",
        "        axs[c].imshow(images_list[c])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_QZ_-8SC-fKo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "seed_values = [1,2,3,4,5]\n",
        "prompt = \"A dog riding a skateboard\"\n",
        "custom_loss_fn = hsv_loss\n",
        "#custom_loss_fn = blue_loss\n",
        "custom_loss_scale = 100.0\n",
        "num_styles = len(style_files)\n",
        "for cnt in range(num_styles):\n",
        "    this_generated_img = generate_image_with_custom_style(prompt,\n",
        "                                                          style_num = cnt,\n",
        "                                                          random_seed = seed_values[cnt],\n",
        "                                                          custom_loss_fn = custom_loss_fn,\n",
        "                                                          custom_loss_scale = custom_loss_scale)\n",
        "    outputs.append(this_generated_img)\n",
        "show_images(outputs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "1e7521755c844e3aa20942320781c08c",
            "95320323a783449fb6abb9a95a8d3e45",
            "6a1c5510cf904aa8ac7428998abc5ed1",
            "ae27da6e0cb7440585f8fd1f70af8c92",
            "7d41d87d006248c989f872faf4032ae9",
            "e117a275e62049a28a09726df2dba069",
            "9c450195af674dd2810f028ac336c647",
            "e4800fb639d44ccb9a11eb9ae9d00e44",
            "fe8409fd67d34d4ca8a4d73b8352ce0e",
            "12ed8236215f47a59aaeccd09f83ad36",
            "cc9ef5789473499699d3dfbf8f1a652a"
          ]
        },
        "id": "9zZewYKdxfS6",
        "outputId": "f7569621-46e5-43de-c87e-18d9c4f9d2ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-d1fef652031b>:68: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  (batch_size, unet.in_channels, height // 8, width // 8),\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e7521755c844e3aa20942320781c08c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "latents: torch.Size([1, 4, 8, 8]), noise_pred:torch.Size([1, 4, 8, 8])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0a5df98f16be>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_styles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_styles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     this_generated_img = generate_image_with_custom_style(prompt,\n\u001b[0m\u001b[1;32m     10\u001b[0m                                                           \u001b[0mstyle_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                           \u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-61c5b87335ed>\u001b[0m in \u001b[0;36mgenerate_image_with_custom_style\u001b[0;34m(prompt, style_num, random_seed, custom_loss_fn, custom_loss_scale)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# And generate an image with this:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_with_embs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_output_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_loss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgenerated_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-d1fef652031b>\u001b[0m in \u001b[0;36mgenerate_with_embs\u001b[0;34m(text_embeddings, max_length, random_seed, custom_loss_fn, custom_loss_scale)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcustom_loss_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mlatents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_guidance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_loss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-d1fef652031b>\u001b[0m in \u001b[0;36madditional_guidance\u001b[0;34m(latents, scheduler, noise_pred, t, sigma, custom_loss_fn, custom_loss_scale)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Get gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mcond_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m#print(cond_grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.LongTensor [1, 1, 64, 64]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "4HRQuoBZr9Ue"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d579eab4370d43e7ae1c38c363121d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c7593066e144c4f9ece06042b2b269a",
              "IPY_MODEL_e11f8d8d6f67432289eadd267bda46e5",
              "IPY_MODEL_ced61498e7e9481a80423626de24e738",
              "IPY_MODEL_d5017ffc722746a298914d12eff1ed99",
              "IPY_MODEL_8ecb664487814155907340d582e90c02"
            ],
            "layout": "IPY_MODEL_24ebed8a68a541c3a8c97997bb7f05e7"
          }
        },
        "4c7593066e144c4f9ece06042b2b269a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc1465597f8e468bbf7b19d5246ac528",
            "placeholder": "​",
            "style": "IPY_MODEL_b4e84f4d99b148d190cfd8dfdeddcf3c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e11f8d8d6f67432289eadd267bda46e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_99c62d5fee0846fa99bf100626ee7926",
            "placeholder": "​",
            "style": "IPY_MODEL_c863baa407bb4537998d2a222bffcd80",
            "value": ""
          }
        },
        "ced61498e7e9481a80423626de24e738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b8e036bca2234698990104b0ca5d1317",
            "style": "IPY_MODEL_61fbd33cd81f40ae9929a79bac677df9",
            "value": true
          }
        },
        "d5017ffc722746a298914d12eff1ed99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_da5dd5d5d075468daa979ead268312da",
            "style": "IPY_MODEL_596bd7e8d6f4490faa4f4ea79ae10f4e",
            "tooltip": ""
          }
        },
        "8ecb664487814155907340d582e90c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_356072e83ef14c8fb98ce8fe5d5e5938",
            "placeholder": "​",
            "style": "IPY_MODEL_24e76d1be16e4e9a9e3b8b4eb7f2aefa",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "24ebed8a68a541c3a8c97997bb7f05e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "fc1465597f8e468bbf7b19d5246ac528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e84f4d99b148d190cfd8dfdeddcf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99c62d5fee0846fa99bf100626ee7926": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c863baa407bb4537998d2a222bffcd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8e036bca2234698990104b0ca5d1317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61fbd33cd81f40ae9929a79bac677df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da5dd5d5d075468daa979ead268312da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596bd7e8d6f4490faa4f4ea79ae10f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "356072e83ef14c8fb98ce8fe5d5e5938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e76d1be16e4e9a9e3b8b4eb7f2aefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e7521755c844e3aa20942320781c08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95320323a783449fb6abb9a95a8d3e45",
              "IPY_MODEL_6a1c5510cf904aa8ac7428998abc5ed1",
              "IPY_MODEL_ae27da6e0cb7440585f8fd1f70af8c92"
            ],
            "layout": "IPY_MODEL_7d41d87d006248c989f872faf4032ae9"
          }
        },
        "95320323a783449fb6abb9a95a8d3e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e117a275e62049a28a09726df2dba069",
            "placeholder": "​",
            "style": "IPY_MODEL_9c450195af674dd2810f028ac336c647",
            "value": "  0%"
          }
        },
        "6a1c5510cf904aa8ac7428998abc5ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4800fb639d44ccb9a11eb9ae9d00e44",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe8409fd67d34d4ca8a4d73b8352ce0e",
            "value": 0
          }
        },
        "ae27da6e0cb7440585f8fd1f70af8c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12ed8236215f47a59aaeccd09f83ad36",
            "placeholder": "​",
            "style": "IPY_MODEL_cc9ef5789473499699d3dfbf8f1a652a",
            "value": " 0/30 [00:04&lt;?, ?it/s]"
          }
        },
        "7d41d87d006248c989f872faf4032ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e117a275e62049a28a09726df2dba069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c450195af674dd2810f028ac336c647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4800fb639d44ccb9a11eb9ae9d00e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe8409fd67d34d4ca8a4d73b8352ce0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12ed8236215f47a59aaeccd09f83ad36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc9ef5789473499699d3dfbf8f1a652a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}