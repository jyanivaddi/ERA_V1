{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:14:04.217692Z","iopub.execute_input":"2024-01-07T12:14:04.218536Z","iopub.status.idle":"2024-01-07T12:14:04.716427Z","shell.execute_reply.started":"2024-01-07T12:14:04.218501Z","shell.execute_reply":"2024-01-07T12:14:04.715586Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b16024730fa417a8c07a1671985ed77"}},"metadata":{}}]},{"cell_type":"code","source":"%pip install -qq -U datasets transformers pyarrow\n%pip install -qq --upgrade transformers ftfy accelerate regex tqdm\n%pip install git+https://github.com/openai/CLIP.git","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:03:32.710110Z","iopub.execute_input":"2024-01-07T14:03:32.710448Z","iopub.status.idle":"2024-01-07T14:04:57.813630Z","shell.execute_reply.started":"2024-01-07T14:03:32.710422Z","shell.execute_reply":"2024-01-07T14:04:57.812212Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.12.1 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 14.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nCollecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-d6rsrkuz\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-d6rsrkuz\n  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (6.1.3)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.15.1)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.24.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\nBuilding wheels for collected packages: clip\n  Building wheel for clip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=2a2ef7e7785fa688cc88a9a51b525e63c628b7d364b3d0d975dff1be360d0425\n  Stored in directory: /tmp/pip-ephem-wheel-cache-lgvz_pv6/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\nSuccessfully built clip\nInstalling collected packages: clip\nSuccessfully installed clip-1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's import all the libraries we need","metadata":{}},{"cell_type":"code","source":"import clip\nimport os\nimport torch\nimport requests\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.auto import tqdm\nfrom PIL import Image\nfrom datasets import load_dataset\nfrom pathlib import Path\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:18:17.179407Z","iopub.execute_input":"2024-01-07T14:18:17.180381Z","iopub.status.idle":"2024-01-07T14:18:24.900673Z","shell.execute_reply.started":"2024-01-07T14:18:17.180345Z","shell.execute_reply":"2024-01-07T14:18:24.899707Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:27:08.559780Z","iopub.execute_input":"2024-01-07T14:27:08.560171Z","iopub.status.idle":"2024-01-07T14:27:08.564866Z","shell.execute_reply.started":"2024-01-07T14:27:08.560139Z","shell.execute_reply":"2024-01-07T14:27:08.563879Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**Download the CLIP model to encode the image**","metadata":{}},{"cell_type":"code","source":"clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:27:10.986385Z","iopub.execute_input":"2024-01-07T14:27:10.987261Z","iopub.status.idle":"2024-01-07T14:27:17.976809Z","shell.execute_reply.started":"2024-01-07T14:27:10.987226Z","shell.execute_reply":"2024-01-07T14:27:17.975918Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 205MiB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Let's Write a method to encode the image using clip model**","metadata":{}},{"cell_type":"code","source":"def calc_image_emb(img, model, preprocess, device):\n    \"\"\"\n    This method computes the clip embeddings for a given image, after preprocessing it according to the model\n    \"\"\"\n    image = preprocess(img).unsqueeze(0).to(device)\n    with torch.no_grad():\n        image_features = model.encode_image(image)\n    return image_features\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:27:23.254194Z","iopub.execute_input":"2024-01-07T14:27:23.254597Z","iopub.status.idle":"2024-01-07T14:27:23.260450Z","shell.execute_reply.started":"2024-01-07T14:27:23.254563Z","shell.execute_reply":"2024-01-07T14:27:23.259499Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\nurl = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\nimage = Image.open(requests.get(url, stream=True).raw)\nimg_features = calc_image_emb(image, clip_model, clip_preprocess, device)\nprint(img_features)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:27:27.561378Z","iopub.execute_input":"2024-01-07T14:27:27.562232Z","iopub.status.idle":"2024-01-07T14:27:29.743817Z","shell.execute_reply.started":"2024-01-07T14:27:27.562197Z","shell.execute_reply":"2024-01-07T14:27:29.742823Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"tensor([[-1.0590e-01,  1.3782e-01, -2.9712e-01,  1.9852e-02, -6.4331e-02,\n         -1.6895e-01, -1.3501e-01, -2.5692e-03,  4.7412e-01, -1.7517e-01,\n          2.4463e-01, -3.7964e-01,  4.7821e-02, -1.4014e-01, -3.4106e-01,\n         -1.2634e-01, -2.3193e-01, -2.9712e-01,  1.7786e-01,  4.8645e-02,\n         -1.3076e+00, -3.1921e-02,  4.2139e-01, -3.3301e-01, -4.7516e-02,\n          2.9785e-01,  2.3926e-01, -1.8481e-01,  1.5759e-01, -4.7882e-02,\n         -7.7759e-02,  2.5903e-01, -7.2937e-02,  1.7737e-01, -5.7764e-01,\n         -5.2757e-03,  2.7808e-01, -2.8784e-01,  1.9055e-01,  3.2715e-01,\n         -1.0114e-01, -3.4692e-01,  7.4234e-03, -1.4685e-01, -1.8994e-01,\n          2.5225e-04,  5.2002e-01,  1.5112e-01, -9.1370e-02,  1.7554e-01,\n          1.6333e-01,  2.5220e-01,  1.1707e-01, -5.2734e-02,  2.2852e-01,\n          1.8579e-01,  2.5903e-01,  6.0254e-01, -2.5977e-01, -1.6711e-01,\n          4.2505e-01, -1.3953e-01, -6.3782e-02,  3.5596e-01, -7.4036e-02,\n         -2.7002e-01,  2.2437e-01,  1.0947e+00,  1.9690e-01,  7.8735e-02,\n          2.0032e-01, -1.0645e-01,  2.7661e-01,  2.7710e-01,  4.9463e-01,\n         -1.6479e-02,  6.3416e-02, -3.4009e-01, -5.2124e-02, -1.3843e-01,\n         -1.8689e-01, -6.7627e-01, -4.5972e-01, -1.4542e-02, -5.5322e-01,\n          2.6294e-01,  4.3018e-01, -5.3760e-01,  2.9395e-01,  9.3384e-02,\n          1.8030e-01,  2.7847e-02, -7.3438e+00,  3.2593e-01, -2.1533e-01,\n          6.7383e-02,  1.7261e-01, -4.2529e-01, -9.2676e-01,  1.2676e+00,\n         -2.9556e-02,  6.1035e-02, -3.0493e-01, -8.2321e-03,  7.2412e-01,\n          2.5073e-01,  1.2314e+00,  2.6855e-01, -1.8042e-01, -4.7241e-01,\n         -1.5601e-01, -1.0557e+00,  6.3416e-02,  2.0044e-01,  1.8726e-01,\n          5.8960e-02,  8.5266e-02,  1.1603e-01,  1.7615e-01, -1.0651e-01,\n          1.6284e-01, -2.1045e-01, -1.8152e-01,  3.9551e-01, -1.6406e-01,\n         -9.2529e-02, -5.9967e-02,  5.1807e-01, -1.3013e-01,  2.9358e-02,\n         -5.3284e-02,  7.7881e-02, -1.9641e-01,  9.4824e-01, -4.1064e-01,\n         -3.8062e-01,  1.4844e-01, -4.8730e-01, -4.1113e-01, -1.2866e-01,\n          1.5869e-01, -3.7524e-01,  3.5449e-01,  4.1504e-01, -1.5295e-01,\n          2.8516e-01,  3.2129e-01, -5.6104e-01,  8.9111e-02,  2.4695e-01,\n         -4.8340e-01,  1.8762e-01, -3.1030e-01, -2.2681e-01,  2.0294e-02,\n         -5.9540e-02, -3.3521e-01, -4.7534e-01,  1.1847e-01, -4.0112e-01,\n         -2.7008e-02, -2.6294e-01,  1.1261e-01,  2.2266e-01, -6.8903e-05,\n         -3.8452e-01, -5.1855e-01,  5.2832e-01,  1.4587e-01,  3.0444e-01,\n          2.2351e-01,  6.8848e-01,  3.0591e-01, -2.2168e-01, -2.1204e-01,\n          1.8799e-01,  2.2018e-02,  5.5115e-02,  6.8665e-02,  2.5757e-01,\n         -3.7256e-01,  2.3218e-01, -1.2329e-01, -3.6230e-01, -5.8289e-02,\n          1.3196e-01,  1.6785e-01, -3.7915e-01,  3.2886e-01, -1.7712e-01,\n          3.4668e-01, -2.8931e-01, -5.4199e-01, -1.3245e-01, -4.8804e-01,\n         -3.4027e-02, -2.6245e-01, -3.4961e-01, -1.1123e+00, -4.2773e-01,\n          4.3945e-02,  3.6035e-01,  1.3440e-01,  1.8359e-01, -1.0126e-01,\n         -1.2024e-02,  3.2837e-01,  6.7383e-02, -3.0249e-01,  5.6201e-01,\n         -4.1162e-01,  5.1904e-01, -3.5339e-02,  3.3228e-01, -4.2627e-01,\n         -3.5254e-01, -3.0918e-03, -7.1533e-01,  8.2617e-01, -3.9502e-01,\n          3.4657e-03,  1.5515e-01, -1.9946e-01,  1.6101e-01, -5.0537e-02,\n          3.7012e-01,  1.4783e-01, -6.8970e-02,  2.4185e-02, -1.9360e-01,\n         -1.5430e-01,  5.2643e-02, -3.3301e-01,  7.6172e-01,  2.7734e-01,\n         -5.3320e-01, -3.4985e-01,  1.3074e-01,  1.4844e-01, -1.8799e-01,\n          3.5571e-01, -1.8152e-01, -1.2286e-01, -3.0396e-02, -3.2544e-01,\n          6.2939e-01,  1.2402e-01, -4.6448e-02, -1.1011e-01,  7.0898e-01,\n          1.4282e-02,  2.7686e-01, -1.6003e-01, -7.5378e-02,  1.9238e-01,\n          4.7729e-02, -4.1748e-02, -2.7539e-01, -6.4062e-01, -4.4250e-02,\n         -8.5999e-02,  3.3630e-02, -3.5591e-03,  4.5361e-01,  3.2715e-01,\n         -1.0779e-01, -5.3711e-01, -4.2798e-01, -2.8223e-01,  6.1005e-02,\n         -2.4609e-01, -2.0630e-01,  3.2080e-01, -1.3135e-01, -2.2913e-01,\n         -1.8530e-01, -1.6968e-02,  1.7493e-01, -4.4043e-01,  1.0712e-01,\n          3.4033e-01,  2.5586e-01, -3.8525e-01, -6.2469e-02, -2.2595e-01,\n          7.5989e-02,  1.7136e-02, -1.4214e-02,  4.8242e-01, -1.9836e-01,\n         -1.4392e-01,  1.7834e-01,  2.7661e-01,  3.0688e-01,  1.8970e-01,\n          1.9556e-01,  2.6611e-01, -5.7471e-01,  7.2670e-03, -1.5100e-01,\n          2.3193e-01, -1.4185e-01, -1.1835e-01,  4.3286e-01, -9.8083e-02,\n          3.0688e-01, -6.8420e-02,  3.7622e-01,  8.9233e-02, -1.8225e-01,\n         -5.8838e-01,  2.7002e-01,  9.4678e-01, -6.1768e-02, -1.8738e-01,\n          2.5610e-01,  1.5222e-01,  4.8877e-01,  1.8347e-01,  2.5903e-01,\n         -1.9531e-01,  1.6182e+00, -5.8447e-01, -3.6438e-02, -2.4023e-01,\n         -1.3745e-01, -9.4421e-02,  5.6982e-01,  1.9910e-01,  2.7084e-02,\n          1.3138e-02, -1.5527e-01, -1.7200e-01, -1.5063e-01,  3.4210e-02,\n          5.3760e-01,  7.2510e-02,  1.1548e-01, -1.4915e-02, -2.1561e-02,\n         -1.9379e-02, -5.6702e-02,  2.1130e-01,  7.8857e-02,  2.0972e-01,\n         -4.8999e-01, -1.2256e-01,  1.6101e-01, -8.4045e-02,  3.4119e-02,\n          1.1639e-01, -2.2632e-01,  5.5469e-01, -4.0527e-01, -2.0435e-01,\n         -1.0602e-01, -2.6953e-01,  2.6367e-01,  2.0190e-01,  3.7891e-01,\n          1.5454e-01,  1.2415e-01,  6.8378e-04, -1.3208e-01, -4.7021e-01,\n          1.9800e-01,  2.9150e-01, -5.4688e-01,  5.8545e-01, -1.0504e-01,\n          4.7607e-01,  5.0488e-01, -2.1692e-01, -5.9473e-01,  3.2446e-01,\n         -1.5198e-01,  1.8057e+00,  7.2205e-02, -4.2358e-01, -7.4158e-02,\n          6.6956e-02, -5.1904e-01, -1.6760e-01,  4.2603e-01, -1.2769e-01,\n          1.5373e-02, -1.1334e-01, -4.3066e-01,  1.2115e-01, -8.4180e-01,\n         -3.2617e-01, -4.4995e-01,  1.1151e-01, -2.6196e-01,  1.9189e-01,\n          1.2042e-01,  4.5264e-01, -3.2446e-01, -3.6011e-01, -2.7295e-01,\n          3.7231e-02,  2.1045e-01,  4.3335e-01,  2.8735e-01,  9.5032e-02,\n         -3.7720e-02, -2.0264e-01, -4.5850e-01,  6.2402e-01,  3.4180e-02,\n          5.0342e-01,  7.9785e-01, -1.8408e-01,  2.6294e-01,  5.7983e-04,\n         -6.5527e-01, -3.3789e-01, -6.3232e-02, -4.0131e-02, -3.6792e-01,\n         -5.7959e-01,  3.3105e-01,  2.0129e-01,  4.2236e-01,  1.2939e-01,\n          3.1891e-03,  1.1102e-01, -3.7061e-01,  6.6211e-01,  2.8076e-01,\n         -3.2788e-01,  7.9346e-01, -5.1367e-01,  2.6929e-01, -4.9072e-02,\n         -5.8008e-01, -3.9703e-02,  4.2139e-01,  2.9224e-01,  1.2238e-02,\n         -1.1646e-01, -2.6660e-01,  6.8115e-02, -1.1755e-01,  3.4790e-01,\n         -3.4546e-02,  5.1788e-02, -2.9541e-01, -1.9543e-01, -4.1846e-01,\n         -5.6006e-01, -2.5220e-01, -5.3125e-01,  5.3467e-01, -1.2140e-01,\n         -3.0835e-01,  3.7207e-01,  4.4775e-01,  1.3599e-01,  4.5142e-01,\n         -3.2861e-01, -3.9722e-01,  8.4351e-02, -2.9126e-01,  4.1602e-01,\n          1.4282e-01, -2.9810e-01, -2.1924e-01, -1.9348e-01, -4.0918e-01,\n          4.2822e-01, -5.0879e-01, -4.1431e-01, -1.0590e-01, -6.6992e-01,\n         -4.8901e-01, -3.7598e-01, -1.3513e-01, -1.2366e-01, -7.2217e-01,\n         -6.2012e-02, -1.0016e-01,  5.5084e-02,  7.2937e-02,  2.4890e-01,\n          1.5857e-01, -2.0166e-01,  1.1383e-01, -2.5122e-01, -1.5369e-01,\n         -4.2542e-02, -8.5815e-02, -1.8909e-01, -4.1284e-01,  6.2451e-01,\n          1.9031e-01,  8.0566e-02,  3.0664e-01,  1.2122e-01,  1.3574e-01,\n         -1.6675e-01,  5.7031e-01, -3.0713e-01, -1.7285e-01,  7.4158e-02,\n         -2.2876e-01,  1.3525e-01, -4.4946e-01,  1.2708e-01,  8.6523e-01,\n         -1.4694e-02,  2.5586e-01]], device='cuda:0', dtype=torch.float16)\n","output_type":"stream"}]},{"cell_type":"code","source":"cc = img_features.squeeze().tolist()\nprint(len(cc))\nprint(cc[0])","metadata":{"execution":{"iopub.status.busy":"2024-01-07T15:54:40.294606Z","iopub.execute_input":"2024-01-07T15:54:40.294980Z","iopub.status.idle":"2024-01-07T15:54:40.301156Z","shell.execute_reply.started":"2024-01-07T15:54:40.294950Z","shell.execute_reply":"2024-01-07T15:54:40.300167Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"512\n-0.10589599609375\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#dataset = load_dataset(\"json\", data_files=\"llava_instruct_150k.json\")\ndataset = load_dataset(\"liuhaotian/LLaVA-Instruct-150K\", data_files='llava_instruct_150k.json')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T12:22:11.593795Z","iopub.execute_input":"2024-01-07T12:22:11.594185Z","iopub.status.idle":"2024-01-07T12:22:17.147768Z","shell.execute_reply.started":"2024-01-07T12:22:11.594153Z","shell.execute_reply":"2024-01-07T12:22:17.146999Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d720c856ec14fc4aa6af9a279b23c6a"}},"metadata":{}}]},{"cell_type":"code","source":"eg = next(iter(dataset['train']))\nprint(eg)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We need to download COCO2017 images, and compute the CLIP embeddings and store them first**","metadata":{}},{"cell_type":"code","source":"def prepare_coco_image_embeddings(img_path_list):\n    \"\"\"\n    This method computes the CLIP image embeddings for all the images in COCO 2017 dataset\n    \"\"\"\n    f_base = Path(\"/path/to/file.txt\").stem\n    embeddings_dict = {}\n    for f_name in tqdm(img_path_list):\n        img = Image.open(f_name)\n        img_embd = calc_image_emb(image, clip_model, clip_preprocess, device)\n        embeddings_dict[f_name] = img_embd.squeeze().tolist()\n    return embeddings_dict\n\ndef get_absolute_paths(directory_path):\n    absolute_paths = []\n\n    # Check if the given path is a valid directory\n    if os.path.isdir(directory_path):\n        # Iterate over all files in the directory\n        for root, _, files in os.walk(directory_path):\n            for file in files:\n                # Construct the absolute path for each file\n                absolute_path = os.path.abspath(os.path.join(root, file))\n                absolute_paths.append(absolute_path)\n    return absolute_paths\n\ndef prepare_files_list(dataset_path):\n    dirs = ['train2017','val2017','test2017']\n    files_list = []\n    for each_dir in tqdm(dirs):\n        files_list.extend(get_absolute_paths(os.path.join(dataset_path, each_dir)))\n    return files_list","metadata":{"execution":{"iopub.status.busy":"2024-01-07T15:55:32.446422Z","iopub.execute_input":"2024-01-07T15:55:32.446869Z","iopub.status.idle":"2024-01-07T15:55:32.460274Z","shell.execute_reply.started":"2024-01-07T15:55:32.446837Z","shell.execute_reply":"2024-01-07T15:55:32.459178Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"dataset_path = '/kaggle/input/coco-2017-dataset/coco2017'\nfiles_list = prepare_files_list(dataset_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:19:53.556438Z","iopub.execute_input":"2024-01-07T14:19:53.557214Z","iopub.status.idle":"2024-01-07T14:23:53.153858Z","shell.execute_reply.started":"2024-01-07T14:19:53.557186Z","shell.execute_reply":"2024-01-07T14:23:53.152892Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73c3d9783c76492e8b689fa2a9bffc0d"}},"metadata":{}}]},{"cell_type":"code","source":"files_list[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:26:44.644099Z","iopub.execute_input":"2024-01-07T14:26:44.644477Z","iopub.status.idle":"2024-01-07T14:26:44.651649Z","shell.execute_reply.started":"2024-01-07T14:26:44.644448Z","shell.execute_reply":"2024-01-07T14:26:44.650479Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/coco-2017-dataset/coco2017/train2017/000000501175.jpg'"},"metadata":{}}]},{"cell_type":"code","source":"embeddings_dict = prepare_coco_image_embeddings(files_list)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T14:27:36.743440Z","iopub.execute_input":"2024-01-07T14:27:36.743840Z","iopub.status.idle":"2024-01-07T15:44:38.009029Z","shell.execute_reply.started":"2024-01-07T14:27:36.743808Z","shell.execute_reply":"2024-01-07T15:44:38.007978Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/163957 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3be60d6278ed4f35a793a06aff8496c4"}},"metadata":{}}]},{"cell_type":"code","source":"import pickle\npkl_file_path = '/kaggle/working/coco_embeddings.pkl'\njson_file_path = '/kaggle/working/coco_embeddings.json'\nwith open(pkl_file_path,'wb') as fh:\n    pickle.dump(embeddings_dict, fh)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T15:46:53.317582Z","iopub.execute_input":"2024-01-07T15:46:53.317965Z","iopub.status.idle":"2024-01-07T15:47:13.245797Z","shell.execute_reply.started":"2024-01-07T15:46:53.317933Z","shell.execute_reply":"2024-01-07T15:47:13.244651Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import json\n\ndef write_dict_to_json(data_dict, file_path):\n    \"\"\"\n    Write a dictionary to a JSON file.\n\n    Parameters:\n    - dictionary: The dictionary to be written to the file.\n    - file_path: The path to the JSON file.\n    \"\"\"\n    with open(file_path, 'w') as json_file:\n        json.dump(data_dict, json_file, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T15:48:00.964080Z","iopub.execute_input":"2024-01-07T15:48:00.964533Z","iopub.status.idle":"2024-01-07T15:48:00.970252Z","shell.execute_reply.started":"2024-01-07T15:48:00.964485Z","shell.execute_reply":"2024-01-07T15:48:00.969245Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\nembeddings_dict_list = {}\nfor key, value in tqdm(embeddings_dict.items()):\n    embeddings_dict_list[key] =  value.squeeze().tolist()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T15:55:02.715663Z","iopub.execute_input":"2024-01-07T15:55:02.716372Z","iopub.status.idle":"2024-01-07T15:55:12.992275Z","shell.execute_reply.started":"2024-01-07T15:55:02.716337Z","shell.execute_reply":"2024-01-07T15:55:12.991252Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/163957 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"382640b7fea74f028f0cd923c835a3f4"}},"metadata":{}}]},{"cell_type":"code","source":"write_dict_to_json(embeddings_dict_list, json_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T15:56:01.441792Z","iopub.execute_input":"2024-01-07T15:56:01.442693Z","iopub.status.idle":"2024-01-07T15:58:52.476708Z","shell.execute_reply.started":"2024-01-07T15:56:01.442657Z","shell.execute_reply":"2024-01-07T15:58:52.475543Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"**Now we need to include the embeddings to the original json file of LLaVa","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}