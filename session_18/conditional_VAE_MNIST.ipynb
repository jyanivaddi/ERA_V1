{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "86a8c1525d3c4e18b7e195e61587346f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_064de4c530ea42658430a76c790938af",
       "IPY_MODEL_440112670da242ce951de48d4b6b84ef",
       "IPY_MODEL_cf3c5bac7fc8406a98798126102a66ae"
      ],
      "layout": "IPY_MODEL_d1791b4598044a9bb949f0edfb3f440e"
     }
    },
    "064de4c530ea42658430a76c790938af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0533c642c1374c61b707d436cfddd7d3",
      "placeholder": "​",
      "style": "IPY_MODEL_1eca1a35828d45e6a92625be2f052ba0",
      "value": "Epoch 19: 100%"
     }
    },
    "440112670da242ce951de48d4b6b84ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3670248bcaf450c8cb0a5766e98fa4f",
      "max": 1500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d41c1e0d97e4f7a9c944ba632c92ee3",
      "value": 1500
     }
    },
    "cf3c5bac7fc8406a98798126102a66ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c033cc3a16a4dc088b029c22d51ffe8",
      "placeholder": "​",
      "style": "IPY_MODEL_5e6a7e1063a6438ba4c63091048fb6e9",
      "value": " 1500/1500 [00:21&lt;00:00, 70.02it/s, loss=-223, v_num=26]"
     }
    },
    "d1791b4598044a9bb949f0edfb3f440e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "0533c642c1374c61b707d436cfddd7d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1eca1a35828d45e6a92625be2f052ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3670248bcaf450c8cb0a5766e98fa4f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d41c1e0d97e4f7a9c944ba632c92ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c033cc3a16a4dc088b029c22d51ffe8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e6a7e1063a6438ba4c63091048fb6e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_18/conditional_VAE_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#! pip install pytorch-lightning\n",
    "#! pip install pytorch-lightning-bolts==0.2.5rc1\n",
    "#!pip install --quiet \"torchinfo\" \"lightning-bolts\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%capture\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from pl_bolts.models.autoencoders.components import (\n",
    "    resnet18_decoder,\n",
    "    resnet18_encoder,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foTuEb6HMCIG",
    "outputId": "7b09085a-7d02-4cb1-f7b1-b01c7f6bac34"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJfbA6qmFyDo"
   },
   "source": [
    "# Full Implementation\n",
    "So, the full implementation is as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Implement MNIST model training**"
   ],
   "metadata": {
    "id": "nAOXlGYFL0-m"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MNIST_Classifier(nn.Module):\n",
    "    def __init__(self, input_dim = 784, hidden_dim = 512, output_dim=10):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Sequential(nn.Linear(input_dim, hidden_dim, bias=False),\n",
    "                                  nn.Dropout(0.1),\n",
    "                                  nn.ReLU())\n",
    "        self.fc_2 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim, bias=False),\n",
    "                                  nn.Dropout(0.1),\n",
    "                                  nn.ReLU())\n",
    "        self.fc_3 = nn.Sequential(nn.Linear(hidden_dim, output_dim, bias=False),\n",
    "                                  nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "        x = F.relu(self.fc_3(x))\n",
    "        return F.log_softmax(x,dim=1)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsSbdHKfQ-Bz",
    "outputId": "0436b28b-e864-47f2-b0c1-a00b37a48bba"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def model_train(model, device, train_loader, optimizer, train_acc, train_losses):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = torch.flatten(data, start_dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct+= output.argmax(dim=1).eq(target).sum().item()\n",
    "        processed+= len(data)\n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx} Accuracy = {100*correct/processed:0.2f}')\n",
    "\n",
    "    train_acc.append(100*correct/processed)\n",
    "    train_losses.append(train_loss/len(train_loader))\n",
    "    return  loss.item()\n",
    "\n",
    "def load_mnist_data(train_transforms, test_transforms):\n",
    "    train_data = datasets.MNIST('../data', train=True, download=True, transform=train_transforms)\n",
    "    test_data = datasets.MNIST('../data', train=False, download=True, transform=test_transforms)\n",
    "    return train_data, test_data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation([-15.,15.]),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "train_data, test_data = load_mnist_data(train_transforms, test_transforms)\n",
    "torch.manual_seed(1)\n",
    "batch_size = 128\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle = True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = True, **kwargs)\n",
    "model = MNIST_Classifier().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1, verbose=True)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for epoch in range(1,5):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    this_train_loss = model_train(model, device, train_loader, optimizer, train_acc, train_losses)\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), 'classifier_model.pth')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "k8qpTM1tL4Az",
    "outputId": "a55135e9-f2c0-4a82-c9de-9d85468a6e96"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#torch.save(model.state_dict(), 'classifier_model.pth')\n",
    "model = MNIST_Classifier()\n",
    "model.load_state_dict(torch.load('classifier_model.pth'))\n",
    "model.eval()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlBt9ieDORfe",
    "outputId": "98c2c922-8e6f-4a50-98f1-3e3e82894ab9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a3_ABiO0F3jM"
   },
   "source": [
    "class MNIST_Encoder(nn.Module):\n",
    "    def __init__(self, input_dim = 784, hidden_dim = 512, encoding_dim=512):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.fc_3 = nn.Linear(hidden_dim, encoding_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "        x = F.relu(self.fc_3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class MNIST_Decoder(nn.Module):\n",
    "    def __init__(self, output_dim = 784, hidden_dim = 512, latent_dim=256):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(latent_dim, hidden_dim, bias=False)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.fc_3 = nn.Linear(hidden_dim, output_dim, bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = F.relu(self.fc_2(x))\n",
    "        x = F.relu(self.fc_3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConditionalVAE(pl.LightningModule):\n",
    "    def __init__(self, enc_out_dim=512, latent_dim=256, input_height=28, num_classes=10, adversarial_prob=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # encoder, decoder\n",
    "        self.encoder = MNIST_Encoder()\n",
    "        self.decoder = MNIST_Decoder()\n",
    "        self.num_classes = num_classes\n",
    "        self.adversarial_prob = adversarial_prob\n",
    "\n",
    "        # class embeddings\n",
    "        #self.class_embeddings = nn.Sequential(nn.Linear(num_classes, enc_out_dim),\n",
    "        #                                      nn.ReLU())\n",
    "        self.class_embeddings = nn.Embedding(num_classes, enc_out_dim)\n",
    "\n",
    "        # distribution parameters\n",
    "        self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
    "\n",
    "        # for the gaussian likelihood\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "\n",
    "        # mnist classifier\n",
    "        #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #self.mnist_classifier = model.to(device)\n",
    "        #self.mnist_loss_fn = F.nll_loss\n",
    "        #self.classifier_loss = None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def gaussian_likelihood(self, mean, logscale, sample):\n",
    "        scale = torch.exp(logscale)\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "        log_pxz = dist.log_prob(sample)\n",
    "        #print(f\"log_pxz: {log_pxz.shape}\")\n",
    "        return log_pxz.sum(dim=1)\n",
    "\n",
    "    def kl_divergence(self, z, mu, std):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "\n",
    "    def forward(self,x,label):\n",
    "        # encode x to get the mu and variance parameters\n",
    "        #print(x.shape)\n",
    "        x_encoded = self.encoder(x)\n",
    "\n",
    "        # Add label embedding to the image embeddings\n",
    "        #c = self.class_embeddings(label)\n",
    "        c = 0\n",
    "        x_encoded = x_encoded + c\n",
    "\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "\n",
    "        # decoded\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mu, std, z\n",
    "\n",
    "    def get_classifier_loss(self, x, labels):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.mnist_classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self.mnist_classifier(x)\n",
    "            loss = self.mnist_loss_fn(output.to(device), labels.to(device))\n",
    "        return loss.item()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, label = batch\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # randomly shuffle labels\n",
    "        if np.random.random() > 1. - self.adversarial_prob:\n",
    "            # With view\n",
    "            idx = torch.randperm(label.nelement())\n",
    "            label = label.view(-1)[idx].view(label.size())\n",
    "\n",
    "\n",
    "        # get classifier loss\n",
    "        #self.classifier_loss = self.get_classifier_loss(x, label)\n",
    "        self.classifier_loss = None\n",
    "\n",
    "        # get the x_hat\n",
    "        #print(label.get_device())\n",
    "        #print(x.get_device())\n",
    "        x_hat, mu, std, z = self(x, label)\n",
    "        #print(f\"x_hat: {x_hat.shape}\")\n",
    "        #print(f\"x: {x.shape}\")\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "\n",
    "        # kl\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (kl - recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "\n",
    "        if self.classifier_loss:\n",
    "            final_loss = 0.5*elbo + 0.5*self.classifier_loss\n",
    "        else:\n",
    "            final_loss = elbo\n",
    "\n",
    "        self.log_dict({\n",
    "            'elbo': elbo,\n",
    "            'kl': kl.mean(),\n",
    "            'recon_loss': recon_loss.mean(),\n",
    "            'reconstruction': recon_loss.mean(),\n",
    "            'kl': kl.mean(),\n",
    "        })\n",
    "\n",
    "        return final_loss\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfNn23pPG6XU"
   },
   "source": [
    "Let's use MNIST already split up and transformed.\n",
    "\n",
    "The Lightning Datamodule has 3 dataloaders, train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Eg5bOMsDHGUj"
   },
   "source": [
    "from pl_bolts.datamodules import MNISTDataModule\n",
    "\n",
    "datamodule = MNISTDataModule('.')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Inference after every 10 epochs**"
   ],
   "metadata": {
    "id": "mvpFM8-stT0_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib.pyplot import imshow, figure, show\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "\n",
    "def generate_images2(model, image, label, num_images=32):\n",
    "    predictions = []\n",
    "    figure(figsize=(8, 3), dpi=300)\n",
    "    with torch.no_grad():\n",
    "        for cnt in range(num_images):\n",
    "            this_pred,_,_,_ = model(image, label)\n",
    "            num_preds = 1\n",
    "            p = torch.distributions.Normal(torch.zeros([1, 256]), torch.ones([1,256]))\n",
    "            z = p.rsample((num_preds,))\n",
    "            # SAMPLE IMAGES\n",
    "            this_pred = model.decoder(z.to(model.device)).cpu()\n",
    "            #print(this_pred.shape)\n",
    "            # UNDO DATA NORMALIZATION\n",
    "            normalize = cifar10_normalization()\n",
    "            mean, std = np.array(normalize.mean), np.array(normalize.std)\n",
    "            this_pred = this_pred.squeeze().permute(1, 2, 0).cpu().numpy()*std + mean\n",
    "            predictions.append(this_pred.transpose())\n",
    "\n",
    "    img = make_grid(torch.tensor(predictions)).permute(1, 2, 0)\n",
    "    # PLOT IMAGES\n",
    "    imshow(img)\n",
    "    show()\n",
    "\n",
    "\n",
    "def generate_images(model, image, label, device, num_images=32):\n",
    "    predictions = []\n",
    "    figure(figsize=(8, 3), dpi=300)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cnt in range(num_images):\n",
    "            num_preds = 1\n",
    "            p = torch.distributions.Normal(torch.zeros([1, 256]), torch.ones([1,256]))\n",
    "            z = p.rsample((num_preds,))\n",
    "            this_pred = model.decoder(z.to(model.device)).cpu()\n",
    "            this_pred = this_pred.view(1, 28, 28).tile((3,1,1))\n",
    "            #print(this_pred.max())\n",
    "            #print(this_pred.min())\n",
    "            predictions.append((this_pred*255.0).type(torch.uint8))\n",
    "    img = make_grid(torch.stack(predictions)).permute(1,2,0).cpu()\n",
    "    #print(img.max())\n",
    "    #print(img.min())\n",
    "    # PLOT IMAGES\n",
    "    imshow(img, cmap='gray_r')\n",
    "    show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOviTepsuKP6",
    "outputId": "9a6835a9-8e6d-4092-becf-9345aa8f5472"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class PeriodicInference(Callback):\n",
    "    def __init__(self, data_module):\n",
    "        super().__init__()\n",
    "        self.data_module = data_module\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        print(f\"classifier loss:{trainer.model.classifier_loss}\")\n",
    "        if (trainer.current_epoch +1) % 5 == 0:\n",
    "            # plot SAMPLE IMAGES\n",
    "            test_dl = self.data_module.val_dataloader()\n",
    "            images, labels = next(iter(test_dl))\n",
    "            one_image = images[0].unsqueeze(0)\n",
    "            one_label = labels[0].unsqueeze(0)\n",
    "            generate_images(trainer.model, one_image.to(self.device), one_label.to(self.device), self.device)\n",
    "\n"
   ],
   "metadata": {
    "id": "nnu9QMhEtShG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wTKaSheHNYS"
   },
   "source": [
    "Now we train!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "86a8c1525d3c4e18b7e195e61587346f",
      "064de4c530ea42658430a76c790938af",
      "440112670da242ce951de48d4b6b84ef",
      "cf3c5bac7fc8406a98798126102a66ae",
      "d1791b4598044a9bb949f0edfb3f440e",
      "0533c642c1374c61b707d436cfddd7d3",
      "1eca1a35828d45e6a92625be2f052ba0",
      "f3670248bcaf450c8cb0a5766e98fa4f",
      "0d41c1e0d97e4f7a9c944ba632c92ee3",
      "7c033cc3a16a4dc088b029c22d51ffe8",
      "5e6a7e1063a6438ba4c63091048fb6e9"
     ]
    },
    "id": "MvBo844ZHQhF",
    "outputId": "df058365-5b1a-44bd-ed0f-4f502f85a90a"
   },
   "source": [
    "pl.seed_everything(1234)\n",
    "\n",
    "cond_vae = ConditionalVAE()\n",
    "trainer = pl.Trainer(gpus=1,\n",
    "                     max_epochs=40,\n",
    "                     callbacks=[PeriodicInference(data_module=datamodule)])\n",
    "trainer.fit(cond_vae, datamodule)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spIp7mogliDI"
   },
   "source": [
    "## Plot an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#for _ in range(25):\n",
    "imgs, labels = next(iter(datamodule.train_dataloader()))\n",
    "#    generate_images(cond_vae, imgs, torch.arange(), num_images=32)\n",
    "this_label = labels[0]\n",
    "#print(this_label)\n",
    "one_label = this_label.unsqueeze(0)\n",
    "for cnt in range(1):\n",
    "    one_image = imgs[cnt].unsqueeze(0)\n",
    "    one_label = torch.tensor([cnt]).unsqueeze(0)\n",
    "    generate_images(cond_vae, one_image, one_label, cond_vae.device, num_images=32)\n"
   ],
   "metadata": {
    "id": "3f9xRmQbzImb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "66062e41-f235-450d-8ddc-48776fd75d87"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cc =  np.array(imgs[0,0].cpu()).squeeze()\n",
    "print(cc.max())\n",
    "print(cc.min())\n",
    "imshow(cc, cmap='gray_r')\n",
    "show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
