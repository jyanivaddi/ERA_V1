{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pytorch-lightning\n",
    "! pip install pytorch-lightning-bolts==0.2.5rc1\n",
    "! pip install --quiet \"torchinfo\" \"lightning-bolts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define VAE class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim, num_labels=10, label_enc_dim=28):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # label embedding\n",
    "        self.label_enc_dim = label_enc_dim\n",
    "        self.num_labels = num_labels\n",
    "        self.class_embeddings = nn.Embedding(self.num_labels, self.label_enc_dim)\n",
    "\n",
    "        # encoder part\n",
    "        self.enc_inp_dim = x_dim+(self.num_labels*self.label_enc_dim)\n",
    "        self.fc1 = nn.Linear(self.enc_inp_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.dec_inp_dim = z_dim + (self.num_labels*self.label_enc_dim)\n",
    "        self.fc4 = nn.Linear(self.dec_inp_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "\n",
    "\n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h)  # mu, log_var\n",
    "\n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)  # return z sample\n",
    "\n",
    "    def decoder(self, z, label):\n",
    "        label_enc = self.get_label_embedding(label)\n",
    "        z = torch.cat([z, label_enc], dim=1)\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h))\n",
    "\n",
    "    def get_label_embedding(self, label):\n",
    "        label_one_hot = torch.nn.functional.one_hot(label, num_classes=10)\n",
    "        label_enc = self.class_embeddings(label_one_hot)\n",
    "        label_enc = torch.flatten(label_enc, start_dim=1)\n",
    "        return label_enc\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        x = x.view(-1, 784)\n",
    "        label_enc = self.get_label_embedding(label)\n",
    "        x = torch.cat([x, label_enc], dim=1)\n",
    "        mu, log_var = self.encoder(x)\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z, label), mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the Loss Function (Reconstruction Loss + KL Divergence Loss)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Train and Test methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch, mu, log_var = vae(data, labels)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    vae.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data = data.cuda()\n",
    "            labels = labels.cuda()\n",
    "            recon, mu, log_var = vae(data, labels)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "            if epoch % 10 == 0:\n",
    "                z = torch.randn(64, 2).cuda()\n",
    "                this_label = 5 * torch.ones(64, dtype=torch.int64).cuda()\n",
    "                sample = vae.decoder(z, this_label).cuda()\n",
    "                save_image(sample.view(64, 1, 28, 28), f\"./samples/sample_{epoch}.png\")\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_tensor):\n",
    "    np_op_img = np.asarray(img_tensor.cpu()).squeeze()\n",
    "    pl.figure()\n",
    "    pl.imshow(np_op_img, cmap='gray')\n",
    "    pl.colorbar()\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the logic to generate conditional images. Here, we generate two images, one based on the input image and label and the other based on Input label. Finally, interpolate between the two samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_generation(vae, test_loader, num_images=32, interp_weight=0.1):\n",
    "    data, label = next(iter(test_loader))\n",
    "    gen_images = []\n",
    "    for cnt in range(num_images):\n",
    "        x = data[cnt].view(-1, 784)\n",
    "        l_e = vae.get_label_embedding(label[cnt])\n",
    "        x_l = torch.cat([x, l_e], dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # get mean and std of given image and label\n",
    "            mu0, log_var0 = vae.encoder(x_l)\n",
    "            z0 = vae.sampling(mu0, log_var0)\n",
    "\n",
    "            # draw a random value of mean and std from standard gaussian\n",
    "            shuffled_label_val = np.random.choice(np.arange(10, dtype=int))\n",
    "            shuffled_label = torch.tensor(shuffled_label_val, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "            z1 = torch.randn(1, 2).cuda()\n",
    "\n",
    "            z_interp = torch.lerp(z0, z1, weight=interp_weight)\n",
    "            img_tensor = vae.decoder(z_interp, shuffled_label_val).view(1, 28, 28)\n",
    "            gen_images.append(img_tensor)\n",
    "        final_output = torch.vstack(gen_images).unsqueeze(1)\n",
    "        show_image(final_output)\n",
    "        #save_image(final_output, f'./samples/final_output_{weight*100}p.png')\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "num_epochs=30\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1=512, h_dim2=256, z_dim=2)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(vae.parameters())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = conditional_generation(vae, test_loader, num_images=32, interp_weight=0.5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
