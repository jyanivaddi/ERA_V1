{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_18/s18_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMv-YR2zikee"
      },
      "source": [
        "Download our code repository and install python dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8J1MOmbqmgC",
        "outputId": "ec36dce5-de39-41a0-b21d-8c35fc4b27bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ERA_V1'...\n",
            "remote: Enumerating objects: 1505, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 1505 (delta 36), reused 32 (delta 5), pack-reused 1407\u001b[K\n",
            "Receiving objects: 100% (1505/1505), 201.95 MiB | 26.51 MiB/s, done.\n",
            "Resolving deltas: 100% (728/728), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n",
        "!git pull\n",
        "!pip install torchinfo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"ERA_V1/session_18\")\n"
      ],
      "metadata": {
        "id": "jBbACfNkwYD9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW3WHIzUqmgF"
      },
      "source": [
        "Add all the imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zQ5ZSVQJqmgI"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "import albumentations.augmentations as AA\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from unet_model import UNet\n",
        "from data_loader import load_oxford_pet_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4AHY0CsqmgL"
      },
      "source": [
        "Allocate GPU and print model summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ContractingBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ContractingBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        skip = x  # store the output for the skip connection\n",
        "        x = self.maxpool(x)\n",
        "        return x, skip\n",
        "\n",
        "\n",
        "class ExpandingBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ExpandingBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.upsample = nn.ConvTranspose2d(out_channels, out_channels // 2, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        #print(\"x: \", x.shape)\n",
        "        #print(\"skip: \", skip.shape)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "\n",
        "        # concatenate the skip connection\n",
        "        x = torch.cat((x, skip), dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.contract1 = ContractingBlock(in_channels, 64)\n",
        "        self.contract2 = ContractingBlock(64, 128)\n",
        "        self.contract3 = ContractingBlock(128, 256)\n",
        "        self.contract4 = ContractingBlock(256, 512)\n",
        "        self.bottle_neck = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
        "\n",
        "        self.upsample = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.expand1 = ExpandingBlock(1024, 512)\n",
        "        self.expand2 = ExpandingBlock(512, 256)\n",
        "        self.expand3 = ExpandingBlock(256, 128)\n",
        "\n",
        "        self.final_dim_reduction = nn.Sequential(*[nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "                                          nn.ReLU(inplace=True),\n",
        "                                          nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "                                          nn.ReLU(inplace=True),\n",
        "                                          nn.Conv2d(64,2, kernel_size=3, padding=1),\n",
        "                                          nn.ReLU(inplace=True)])\n",
        "        self.final_block = nn.Conv2d(2, 1, kernel_size=1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Contracting path\n",
        "        x, skip1 = self.contract1(x)\n",
        "        #print(\"first contract block:\", x.shape, skip1.shape)\n",
        "        x, skip2 = self.contract2(x)\n",
        "        #print(\"second contract block:\", x.shape, skip2.shape)\n",
        "        x, skip3 = self.contract3(x)\n",
        "        #print(\"third contract block:\", x.shape, skip3.shape)\n",
        "        x, skip4 = self.contract4(x)\n",
        "        #print(\"fourth contract block:\", x.shape, skip4.shape)\n",
        "        x = self.bottle_neck(x)\n",
        "        #print(\"bottle neck:\", x.shape)\n",
        "        x = self.upsample(x)\n",
        "        #print(\"upsample:\", x.shape)\n",
        "        x = torch.cat((x, skip4), dim=1)\n",
        "        #print(\"cat:\", x.shape)\n",
        "\n",
        "        # Expanding path\n",
        "        #print(\"-------------\")\n",
        "        #print(\"starting expand block:\", x.shape)\n",
        "        x3 = self.expand1(x, skip3)\n",
        "        #print(\"after first expand block:\", x3.shape)\n",
        "        x2 = self.expand2(x3, skip2)\n",
        "        #print(\"after second expand block:\", x2.shape)\n",
        "        x1 = self.expand3(x2, skip1)\n",
        "        #print(\"after third expand block:\", x1.shape)\n",
        "        #x1 = self.expand4(x2, skip1)\n",
        "\n",
        "        x  = self.final_dim_reduction(x1)\n",
        "        #print(\"after final dim reduction:\", x.shape)\n",
        "        x_out = self.final_block(x)\n",
        "        #print(\"after 1 x 1:\", x_out.shape)\n",
        "        return x_out\n"
      ],
      "metadata": {
        "id": "Da-JzFXz9gz5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_summary(model, input_size):\n",
        "    summary(model, input_size = input_size)"
      ],
      "metadata": {
        "id": "hzhSfiUE6D4V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xmgYQudqmgM",
        "outputId": "deceb7ac-d079-4fb9-c79c-b8e1c6a2e797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 48, 48]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
            "              ReLU-3           [-1, 64, 48, 48]               0\n",
            "            Conv2d-4           [-1, 64, 48, 48]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 48, 48]             128\n",
            "              ReLU-6           [-1, 64, 48, 48]               0\n",
            "         MaxPool2d-7           [-1, 64, 24, 24]               0\n",
            "  ContractingBlock-8  [[-1, 64, 24, 24], [-1, 64, 48, 48]]               0\n",
            "            Conv2d-9          [-1, 128, 24, 24]          73,856\n",
            "      BatchNorm2d-10          [-1, 128, 24, 24]             256\n",
            "             ReLU-11          [-1, 128, 24, 24]               0\n",
            "           Conv2d-12          [-1, 128, 24, 24]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 24, 24]             256\n",
            "             ReLU-14          [-1, 128, 24, 24]               0\n",
            "        MaxPool2d-15          [-1, 128, 12, 12]               0\n",
            " ContractingBlock-16  [[-1, 128, 12, 12], [-1, 128, 24, 24]]               0\n",
            "           Conv2d-17          [-1, 256, 12, 12]         295,168\n",
            "      BatchNorm2d-18          [-1, 256, 12, 12]             512\n",
            "             ReLU-19          [-1, 256, 12, 12]               0\n",
            "           Conv2d-20          [-1, 256, 12, 12]         590,080\n",
            "      BatchNorm2d-21          [-1, 256, 12, 12]             512\n",
            "             ReLU-22          [-1, 256, 12, 12]               0\n",
            "        MaxPool2d-23            [-1, 256, 6, 6]               0\n",
            " ContractingBlock-24  [[-1, 256, 6, 6], [-1, 256, 12, 12]]               0\n",
            "           Conv2d-25            [-1, 512, 6, 6]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 6, 6]           1,024\n",
            "             ReLU-27            [-1, 512, 6, 6]               0\n",
            "           Conv2d-28            [-1, 512, 6, 6]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 6, 6]           1,024\n",
            "             ReLU-30            [-1, 512, 6, 6]               0\n",
            "        MaxPool2d-31            [-1, 512, 3, 3]               0\n",
            " ContractingBlock-32  [[-1, 512, 3, 3], [-1, 512, 6, 6]]               0\n",
            "           Conv2d-33           [-1, 1024, 3, 3]       4,719,616\n",
            "  ConvTranspose2d-34            [-1, 512, 6, 6]       2,097,664\n",
            "           Conv2d-35            [-1, 512, 6, 6]       4,719,104\n",
            "      BatchNorm2d-36            [-1, 512, 6, 6]           1,024\n",
            "             ReLU-37            [-1, 512, 6, 6]               0\n",
            "           Conv2d-38            [-1, 512, 6, 6]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 6, 6]           1,024\n",
            "             ReLU-40            [-1, 512, 6, 6]               0\n",
            "  ConvTranspose2d-41          [-1, 256, 12, 12]         524,544\n",
            "   ExpandingBlock-42          [-1, 512, 12, 12]               0\n",
            "           Conv2d-43          [-1, 256, 12, 12]       1,179,904\n",
            "      BatchNorm2d-44          [-1, 256, 12, 12]             512\n",
            "             ReLU-45          [-1, 256, 12, 12]               0\n",
            "           Conv2d-46          [-1, 256, 12, 12]         590,080\n",
            "      BatchNorm2d-47          [-1, 256, 12, 12]             512\n",
            "             ReLU-48          [-1, 256, 12, 12]               0\n",
            "  ConvTranspose2d-49          [-1, 128, 24, 24]         131,200\n",
            "   ExpandingBlock-50          [-1, 256, 24, 24]               0\n",
            "           Conv2d-51          [-1, 128, 24, 24]         295,040\n",
            "      BatchNorm2d-52          [-1, 128, 24, 24]             256\n",
            "             ReLU-53          [-1, 128, 24, 24]               0\n",
            "           Conv2d-54          [-1, 128, 24, 24]         147,584\n",
            "      BatchNorm2d-55          [-1, 128, 24, 24]             256\n",
            "             ReLU-56          [-1, 128, 24, 24]               0\n",
            "  ConvTranspose2d-57           [-1, 64, 48, 48]          32,832\n",
            "   ExpandingBlock-58          [-1, 128, 48, 48]               0\n",
            "           Conv2d-59           [-1, 64, 48, 48]          73,792\n",
            "             ReLU-60           [-1, 64, 48, 48]               0\n",
            "           Conv2d-61           [-1, 64, 48, 48]          36,928\n",
            "             ReLU-62           [-1, 64, 48, 48]               0\n",
            "           Conv2d-63            [-1, 2, 48, 48]           1,154\n",
            "             ReLU-64            [-1, 2, 48, 48]               0\n",
            "           Conv2d-65            [-1, 1, 48, 48]               3\n",
            "================================================================\n",
            "Total params: 21,602,053\n",
            "Trainable params: 21,602,053\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 55050.21\n",
            "Params size (MB): 82.41\n",
            "Estimated Total Size (MB): 55132.64\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "unet_model = UNet(in_channels=3,out_channels=1).to(device)\n",
        "model_summary(unet_model, input_size=(3,48,48))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF0JlvTsqmgP"
      },
      "source": [
        "Define Albumentations image augmentations. We use RandomResizedCrop, HorizontalFlip, and cutout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pI6EVt-jmGp6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import Any\n",
        "from torchvision import datasets, transforms\n",
        "import albumentations as A\n",
        "import albumentations.augmentations as AA\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def oxford_transforms(image, mask):\n",
        "    # Resize\n",
        "    resize = transforms.Resize(size=(48, 48))\n",
        "    image = resize(image)\n",
        "    mask = resize(mask)\n",
        "\n",
        "    # Transform to tensor\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    image = to_tensor(image)\n",
        "    mask = to_tensor(mask)\n",
        "    return image, mask\n",
        "\n",
        "class OxfordPetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.dataset = dataset\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index) -> Any:\n",
        "        image, label = self.dataset[index]\n",
        "        image = np.array(image)\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "        return (image, label)\n",
        "\n",
        "\n",
        "def load_oxford_pet_data(train_transforms, test_transforms, batch_size, **kwargs):\n",
        "    train_data = datasets.OxfordIIITPet('../data', split='trainval', transforms = train_transforms, target_transform = None, target_types='segmentation', download=True)\n",
        "    test_data = datasets.OxfordIIITPet('../data', split='test', transforms = test_transforms, target_transform = None, target_types='segmentation', download=True)\n",
        "\n",
        "    train_loader = DataLoader(train_data,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True,\n",
        "                              **kwargs)\n",
        "    test_loader = DataLoader(test_data,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=True,\n",
        "                             **kwargs)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6f-Ko64qmgU"
      },
      "source": [
        "Define batch size, train and test loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z8mQv0iUqmgV",
        "outputId": "fc6ae7f5-5727-4702-f049-2f5585a5ec97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to ../data/oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 791918971/791918971 [00:38<00:00, 20765775.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/oxford-iiit-pet/images.tar.gz to ../data/oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to ../data/oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19173078/19173078 [00:01<00:00, 11485164.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/oxford-iiit-pet/annotations.tar.gz to ../data/oxford-iiit-pet\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 32\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader, test_loader = load_oxford_pet_data(train_transforms=oxford_transforms, test_transforms=oxford_transforms, batch_size=batch_size, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b = next(iter(train_loader))\n",
        "print(a.shape)\n",
        "print(b.shape)"
      ],
      "metadata": {
        "id": "XVlZ9lf1yL8w",
        "outputId": "bbc1ce36-7be1-4b4f-d881-3bdc9c01373d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 48, 48])\n",
            "torch.Size([32, 1, 48, 48])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=10\n",
        "c = np.asarray(b[idx]).transpose()\n",
        "a1 = np.asarray(a[idx]).squeeze().transpose()\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(c.squeeze())\n",
        "plt.show()\n",
        "plt.figure()\n",
        "\n",
        "print(a1.shape)\n",
        "plt.imshow(a1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gd6m-KrW4i2I",
        "outputId": "a278cca5-6cec-47f2-d990-dfed15cd69b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48, 48, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGeCAYAAADSRtWEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1KUlEQVR4nO3df3Bd9Xnn8c+59+peydYP/wBLOLYSt2GAlEIaJxg1nZYaJ16aZaG4O3Q2s6Up00yoYADPbItnGzLNtGMm3QFCayDTUpjulDpDdiFLOoGyThCb1naMwIWQxpsfDhZrJIeCJFuW7r265+wfttUI9H0eS8fu99q8X5k7E/Tc7znf+70/Hl3r+5wnybIsEwAA/8YKsScAAHh3IgEBAKIgAQEAoiABAQCiIAEBAKIgAQEAoiABAQCiIAEBAKIgAQEAoijFnsDbpWmqgwcPqqOjQ0mSxJ4OAGCesizT4cOHtXLlShUKxvec7DT58z//8+y9731vVqlUsssuuyzbvXv3SY0bGhrKJHHjxo0btzP8NjQ0ZH7en5ZvQF/+8pe1efNmPfjgg1q3bp3uvfdebdy4Ufv27dOKFSvMsR0dHZKkRR+4QUmxPOd96hMTwfFZbdo8/n/6tZ834791/UfMeKEw95wkqTZtn/up//OsGZ+eToOx6htD5thf+sUNZry9vSMYc79oOpcL9L+p5vkm653bGGkP9c/sHCDLws+XPzbvmpqD7bizLpl1B2feaWq/BxqN8JqljYY51n9c4WN7Bl/ca8b/8uH/bsZ7fq47GOu9+D32yRP7LyH/8Vd/Mxj7+Z/5OXNsY9pe0zfGR834/xz8h2Ds2l/4xWDs6NGj+s+/cf3M53nIaUlAd999t373d39Xn/rUpyRJDz74oP7u7/5Of/VXf6U77rjDHHvijZcUy8EElBTr4QNYX/cklcutZnzx4sVmvFisBGPVujEvSZVW+9xF48WSlcOJT5IWLVpkxhcvDsdPfwLK86fG05mA8iWJLCUBvV3jDE1AlUr4fX3s1Pa5i6ViMFYq2x+ziZOA2oz3dnt7uznWS0CTDfszq2x8ZnmflZK/bqd8E0KtVtPg4KA2bPjX38gLhYI2bNignTt3vuP+1WpV4+Pjs24AgLPfKU9Ab7zxhhqNhrq7Z38l7e7u1vDw8Dvuv3XrVnV1dc3cVq9efaqnBABoQtG3YW/ZskVjY2Mzt6Eh+28dAICzwyn/G9A555yjYrGokZGRWT8fGRlRT0/PO+5fqVTcf38FAJx9TnkCKpfLWrt2rXbs2KFrr71W0rHanh07dujmm28+6eNkSUlKWuaMtWjunx8bZ//Rq9JiJ7tSKXxsSSoWw3FjE5skqVAI/6Hy2LnDcy+V7KfKm7c33mL+UVpS4uxys/4Q6f0x3pNrf53zR2t3Zsbzmab2H3+9cydm7YQ51F3T1DlAwfijuPt8pc4/qiTh8YWiN9Z5ttNwvOE8Hy/ufcmMTxubJyTpyBvhnbneH+KdPQiarE4ax7YHF4v2uRdV2sy49XlaM9ak7qzXCadlF9zmzZt1ww036MMf/rAuu+wy3XvvvZqYmJjZFQcAwGlJQNdff71+8pOf6M4779Tw8LA++MEP6qmnnnrHxgQAwLvXabsUz8033zyvf3IDALy7RN8FBwB4dyIBAQCiIAEBAKJounYMJ2RJq5TMvWW6Rcb1i5xtiRXnmmotLXa8aFyMdNrZoVpssZe72AgfoF60x7a02NuwC8b4xLsmmrsN25YYv+dk7nXonGOb473rsdnb4t3rtRnHbxhbgiV/m7Y52tvW68RTbyu1dX094/p3klTIFr4NW95YR5aE5/bmW2+aY/d9/wdm3HuPmNeC80ogrDWR/ZlULDqvYefYbRX7+pTW5+WRWjUYO1qrmcc9gW9AAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIAomrcOqFCWAjU3BaMdg5dRW/K2YyiE4yWnvqLk1PKkCtcxePv9/XYNVty9vr8dd1j1NIWcNS0Wr9amUHCOnaftQY55Hzt4+LXgXYI/cdp+JE4rCIu9olLReY0XjDYTeVtzWC0uak5dSrUarmmR5NYXWmtuttaQX2dnfSZ5LV68Y5edusgl7YuDsTeOHgnGJiePmsc9gW9AAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIAomrYOqJC0KEnm3qOeGbU4SY7eGpJUcvrqFBOrDsiur/DqgKazcJWF1W9E8usvima9QL46oDzVG16dj1cbYtU5eLVTHrcsxapvcrskeb2Kwr8bWrU0ktwapCz1zh2OubVsRk8eSUqN94jXa8h7XFZNWaXV7nvjvX+812ntaLhHWaPh9FAq2ccenRgz5uXVJzl9jJwU0LtsRTC279BIMFadnDSPewLfgAAAUZCAAABRkIAAAFGQgAAAUZCAAABRkIAAAFGQgAAAUTRtHZCSlmO3OTRy1AEVnX4/paIdLyThJSs6/Wfcehmj1qBYcOp8vDogoyYmM/oQSX4tjrPkdg1FvnIZsw4oyVWhJKVeIZARd9fM+d0vNWpH8rYa8nrbWIvurWih6NSlZOHJZ15/JkfivpiMsTnPbdUBTVftz4W2il2b+JPR4WDMe50VnOfae9g/u+K8YOzZH3wnGKtPOf2VTpz/pO4FAMApRgICAERBAgIAREECAgBEQQICAERBAgIARNG027DTpKykMPf2xIIx7cy5/LjbbsHZzlxIwtuZi418l3QvlYzxzrxbWpx5W9uwja2xx+9ghnPtpHYGe9uVzT3gOVo5HDu0M95oa9BoTNtj3e3lC+dtrfVbYBhbpZ2Je1vX7bYg9nPtPV/mea33lvw2E96pp2vWNmy7zCEx10R668hbwVi1ET6vJLU6jytzWsisaO8Kxt7ftTQ8r/KUedwT+AYEAIiCBAQAiIIEBACIggQEAIiCBAQAiIIEBACIggQEAIiieeuACiUlgbYLqdGaIHVqIPw6IHtPvlUH5F2KvuDuyQ/HzBoh+W0mrPqLLH9PhIVzalK8y8mb7Ri8mhX3cdnxRhKuoWh4rTm8x10wHrdXx2NGpYIz3mpN4LaZsMtKzLkn3nPt1mWFT/6tf9hljn3zrVEz7q15Yzr8fB9+Y8Ic27681Yy/OXYoGBt+43Vz7HuWrTDj1rwlaboebqtwxc9cHIxNTEzov5lHPoZvQACAKEhAAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKJq4DijcD6gR+LkkOa013DuY9ReSikYNUrFo94BpaQnPW5JSo47B6wfk9TOx+gHJ6weUm1W/kaPfj6SCWcOUs9+PWx8Vfr4z5/nwe/KEXwuJMy+vXsZ7jdtL6tVGLfy1lLMaTa//JFwv89y3/tEc27DeezqJt4jRG+qtA+Pm0I5z2sx4rS1ci/PVZ/+nObbvZy8z4077NL355r8EY6+++mowVq2G5zzr/Cd1LwAATjESEAAgChIQACAKEhAAIAoSEAAgChIQACCKpt2GrWLLsVsoFpAa2yEluZdV97bHWltYC84Wb6+lQmpscU2cLdxuu4Yc27C9bb2nl/N8WZtz3cv7e+e2t+YWkvCaWy0NJCmxd+wry4y2H87j8rauu4yF8dpMFNzfaY25ee0znPf2rt3fDsbe+JfwdmJJ6mxfbMYrFe/9F36+Kt5H0iH7Di1d4dfSwTd/aI59+nvhremS1L5okRmvlMOtIiqVcKzgteU4cb+TuxsAAKcWCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABBF09YB/cLPLFGpPPce9XItXAe0qGjvqb/gZ88146WS3fbAqsEoOpe5L3iX6DcuCV906oCKzrGLRo2S13bArQNyy06sWh3n3M5l8hOvJsYca8czr52DsW6J91pwa5RyrJnRyiFvPHHqO8y6rOP3CJ7XGevNe01vbzD2X//L7ebYZcuWmfElS5eY8Xo93H5gqlYzx1r1ZJLUtsiqUXJabyRObaJRUylJRePzcPLokWDs6NGj0p89YB5bWsA3oOeee05XX321Vq5cqSRJ9MQTT8yKZ1mmO++8U+edd57a2tq0YcMGff/735/vaQAAZ7l5J6CJiQldeuml2rZt25zxL3zhC7rvvvv04IMPavfu3Vq8eLE2btyoqamp3JMFAJw95v1PcFdddZWuuuqqOWNZlunee+/VH/7hH+qaa66RJP31X/+1uru79cQTT+g3f/M3880WAHDWOKWbEPbv36/h4WFt2LBh5mddXV1at26ddu7cOeeYarWq8fHxWTcAwNnvlCag4eFhSVJ3d/esn3d3d8/E3m7r1q3q6uqaua1evfpUTgkA0KSib8PesmWLxsbGZm5DQ0OxpwQA+DdwShNQT0+PJGlkZGTWz0dGRmZib1epVNTZ2TnrBgA4+53SOqA1a9aop6dHO3bs0Ac/+EFJ0vj4uHbv3q2bbrppXsd66A/WqaOjY85Y0SiDKBbtnNrS4u2L93Ky1Q/IHmvV4khSatSGlMoV+9hWvx95vYq8uhIz7NeVGLUKVi2NJGVOXx1zuDMvn72mVs2LW0Nk9I+RTqZXkTXWqTGS3dMna1hvMO/sdqOjhlHX5T1m7/116fHPnLl4NV+eNqdvTsF6nTp1PkeO2H/3LhXD7/2i0wdsetprPGUvzPR03YiFdza3TJ9capl3Ajpy5Ih+8IMfzPz3/v37tXfvXi1btky9vb267bbb9Md//Mc6//zztWbNGn32s5/VypUrde211873VACAs9i8E9Dzzz+vX/3VX535782bN0uSbrjhBj3yyCP6/d//fU1MTOjTn/60RkdH9Uu/9Et66qmn1Noa7p4HAHj3mXcCuuKKK8zLhCRJos9//vP6/Oc/n2tiAICzW/RdcACAdycSEAAgChIQACCKpm3HUCwlKpYCWwSN7ZoNZ+ttvepsQXX2gjaM+FQtfEl2yd+aWzS25rZ4bSLcbdjh3zXcC+g7a+Jt+7XO4G29Tdz9s8axnZYH3hZwlzHcayPhtx4w4m53DOfYTjw1ei4kzrb4xNrCfezkRmzh7S8kyXq63e3+3rb5HK07EuczqeS8d6Xw+JKzDdsrz2g0nHYnxvPd2tq24OOewDcgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAUTVsHtOef92nR4sVzxvJVbzg1EG4NhRFz6hg6O5ba526EL31ezuwaI6+WILHqgLxCILc1QJ6alhx9B2TXX6RO/YVfB+RWSIUjRfut5bawsOLOJfSz1L4Ef+qMT4yCmiSx16TgtDMpWs+X+8b22oYYc3OOXchzbElmNwaniMhrIdNoWNfeNIe6LSy8uVnxxe1G7zanBu8EvgEBAKIgAQEAoiABAQCiIAEBAKIgAQEAoiABAQCiIAEBAKJo2jqglV2dWtzePmesYOwxL3r72p1+JgUnbpUL+P1KnHxv1H6UZPcxKjn9gqy6kizn7yGZ0a/kGGvRvIZATtgq/fDqZdwaJK8JTI4+R86ZzSVzXuOp83wW8tR1eXUnTv1Hnr5U3snT6XD9k9cnzKvLSrxeXsXw+69QsD9mGw07bn1sNKZr5thyZZEZz1XrZsSKzmM+gW9AAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIAomrYOqHvJUnV0dMwZ8+ogLO5QtwwofAen7OQkus8YfT9ydkFSEu4XlKV2jZHXV8crJbBqddxje8w6Iqcu6yQqTyzmaPdx5ahB8l5nTi1bki38987EadqTFZx6GuMN6NVOufVmpfBr3Ju31XNH8j83ypXW8Fjn9/xpo35Jkkot5WBsauqoOTZt2McuOn2rrLmbdUBOf7IT+AYEAIiCBAQAiIIEBACIggQEAIiCBAQAiIIEBACIomm3YRcKid8aYQ5+S4Sce6XNy5N7nK2e1rFzbD0/dmbj3E6biMTdUWw/Lnt7eT5WKwlvyXI2Y3CO4Fz+3zl6wXhc7rydB+5tZ7ZbJnhb9p3HZbYFsWWp/TrNkvCW48xp++G3kbC3FZfLlWCsVrNbJritVNLw3BcvmrtU5YR6vW7GvTeJ/Rkcfi5P9rObb0AAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIAoSEAAgCiatg5ISRLco27VObjdFpyaF1euwpW8VS8LP3LmXeveOrZ7+X+7RiJNc7ZcsBiPy2+94Vwy3jlAw7qMvjPWm1rRWFOzpktS5vUFkf24rbqThldD5LVrsNqCOI/La92R552des+XUyc0XQ/X+ljPpSSlRftx16rVYKxcCdcfSVLZmXfDeK4lKTPeu9aaeOt1At+AAABRkIAAAFGQgAAAUZCAAABRkIAAAFGQgAAAUZCAAABRNG0dUHL8f6FYcJzbh8LrXWMrGOdeeKXNSRzB67njFr1YPXncQh/nyE6vFau/jFOz4tUvmWVdXu2TW+DkzK1g9LbxHpdby7Ow+gvJfw94z3dq9vyxPzJSGbVRktJG+NhZavca8uJWnZD3OvJfCvYdSi1lY6xdB1Q3aogk+7Xg8ebtfVxa9VGJ0SgscfovzZz/pO4FAMApRgICAERBAgIAREECAgBEQQICAERBAgIARNG027CVyLhmfXiLn9t1wO9bYIatDZH5NoCf3D0Wem5/YXKM9baImy0TvMvgL7yFhbfV2dsq6l3+39zu7Oyc9R+Vtf3V2zNsh71tveaqeFvT3deZ8d512zHkeZ3Zs/JKDQpOS4VyS2sw5nQ8cB+Xde56PdyqQZJaSna7htPXXubkDsw3IABAFCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFM1bB5RlwfoSq/VA4tXSeFfo9+ZltmNw6k6cI+dp5+Cd2z577kVxhi/8AF79hjVzf729tgUOq3bEaNVwckc34l49jFN4kqtWJ3VqiNySMauGL++8jbHOelttViT59U9GrNGo2+f2XuRFow6oOmUPLdgf8V5rj4IRz4w6upOt35vXN6CtW7fqIx/5iDo6OrRixQpde+212rdv36z7TE1Nqb+/X8uXL1d7e7s2bdqkkZGR+ZwGAPAuMK8ENDAwoP7+fu3atUvPPPOM6vW6Pv7xj2tiYmLmPrfffruefPJJPfbYYxoYGNDBgwd13XXXnfKJAwDObPP6J7innnpq1n8/8sgjWrFihQYHB/XLv/zLGhsb00MPPaRHH31U69evlyQ9/PDDuuiii7Rr1y5dfvnlp27mAIAzWq5NCGNjY5KkZcuWSZIGBwdVr9e1YcOGmftceOGF6u3t1c6dO+c8RrVa1fj4+KwbAODst+AElKapbrvtNn30ox/VxRdfLEkaHh5WuVzWkiVLZt23u7tbw8PDcx5n69at6urqmrmtXr16oVMCAJxBFpyA+vv79Z3vfEfbt2/PNYEtW7ZobGxs5jY0NJTreACAM8OCtmHffPPN+trXvqbnnntOq1atmvl5T0+ParWaRkdHZ30LGhkZUU9Pz5zHqlQqqlScS4YDAM4680pAWZbplltu0eOPP65nn31Wa9asmRVfu3atWlpatGPHDm3atEmStG/fPh04cEB9fX3zmlim8N76XNUbXi1Bjv4zbm8bd25GjYX7sBZe2+HLWy+TZ3SOmpU8D1lSvsdt/+NC5jUMMk+cozjq2AHs4cbCuT15nDObx3ZrjHLU+LlLZh+7Vq2Z8el6OF43YpJUMnoJSdJ0ze75Y/HWrOD9G5gRt9ppnezH6LwSUH9/vx599FF99atfVUdHx8zfdbq6utTW1qauri7deOON2rx5s5YtW6bOzk7dcsst6uvrYwccAGCWeSWgBx54QJJ0xRVXzPr5ww8/rN/+7d+WJN1zzz0qFAratGmTqtWqNm7cqPvvv/+UTBYAcPaY9z/BeVpbW7Vt2zZt27ZtwZMCAJz9uBgpACAKEhAAIAoSEAAgChIQACCKM7IfkFlvk7POx+2rYxzfqwNyj52jZY/HLJHwWqFk3h3mPZ0ZeUt1rLm99toBc+xLL/2TGa9P231cigWjL1Vi17S0t3eY8UWLFofnVXf6yzjFHS2lcH8ZSaoaPWaSov2RUSnbReUt5fC5vTogtw+SESsWFv6YJelHP/6xGd/4734tGFvUZtf5uJ28jOezYPQKkvzXQr66SWvsaegHBADAqUICAgBEQQICAERBAgIAREECAgBEQQICAERxRm7Dtq5J514G3N3z6MStQ6c5tlk73KG5eg9426zztZmwtp/7S+Kc2wi/Z1WvOfbVA/Y27a985ctmvJFOB2OtTo+rH/3o/5rxw0Zrem9rbVenvcW7q8OOp43w43r1tdftsc7rsKurMxg777yV5tgOZ95dnV3B2NK3dWl+u7KzfbyjMzxvyX6Vlitt5tipyUkzbh09SezXQqFgf8RnVgsYSakRr9XCW9et2E/jGxAAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIIqmrQNqpA01Go05Y0Wj1iBzaiTcOiG3HYN18HyHPonJhQ/ttqFY8KHdWgHv4HmWzGNegt+5VH1v7/vM+DnLzjXjB/7fj42o/cjq9XCtjSQdPjIRjHn1ZtPTc79vTiiWWuy48R4qOr+yHh4/YsYvuujngrHrr/9P5livs0B1KlxPM3U0vJ6SNDVpz3vJsiVm3GqLkDntTLw6oXq9GoxNOy1D/M8k73VaC8aOThwOxiad9T6Bb0AAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIAoSEAAgCiatg4ozbJwbxGrH1Bq10B4/TMSpxbH6m3j1fl4x/YLhayROeqXcvUSOplZG3VbOWqIJLvMwauR+OEP7Z48mez6p5+76APB2OLFi8yxq1d2m/E9394VjCUFu76ptVJ24nbvm6lquPaj4NQQLV26xIy3tYbHT0yEeyBJ0vjom2Z87K03grGpKbsuZbru9K9xasoa0+G6rmr1qDm2VLKfr8T4nlBwXgtezZj3udGoh99D1ryLJac+6Ti+AQEAoiABAQCiIAEBAKIgAQEAoiABAQCiIAEBAKJo2m3YiYwttlY7Bvf64/laC5yuod4BvO2SXjuGJMex8/aZsI7vHTnPtnhvTS699BfM+GWXXW7G7XYP9rkP/r8DZvyIseV45I3wdmNJGj8Svky+JDWm7FKFkvG4li9bao6t1sJbuCVp6LWhYOyJJ/6HOba9zd6uXC6HP87KLfZ25ULBfp1NToZbPUhSoxH+XJk4MmaOrVQWm/FypTUYK7XY2+K9EossdT4PjfdfpTVcalCf9j5nj+EbEAAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIAoSEAAgiqatA8qUhi+Hn1l79p3KEqcdg9uawDq8Oa+TYbV6yNsywajFcabt1wm5Jw+HktNX31Qs2i/vrq4u59xm2FyX1GkLcu6K88z45b/4y8HYjv/9dXPs4SNHzPjkVNWMTxlxp1zGbQVRKoTrVg6PjZpjjx6xa3mKJaMOqGzXyyxqbTPjP/rRj834M8/872Dsyg3rzbH1uv18WLVwpRZ7vb33j/d52WrU+kwbtU9em4iZ+53UvQAAOMVIQACAKEhAAIAoSEAAgChIQACAKEhAAIAoSEAAgCiatg4obaTBHhvWvnivf4ybcZ1Chyy16mni5XN3v78R99bMi3vMOiK3bYhTJ2TMLc+a+Gd2ju8MtmpWJOmyX/yVYOzNt/7FHDs+sMOMT1bt3jaJVd9k1H5I0uiY3YuoPh2uj/J602RObVWlHK6JWbJ0iTl2arHdk6dj6blmfNny5cGY1V9JktoWhWttJCm11iVnfaB5bEmTE+Hns1qdCsYmJiZO6vx8AwIAREECAgBEQQICAERBAgIAREECAgBEQQICAERBAgIARNG8dUBpFtyjXrDqbZz+Mg2nQKOQOTnZKInJMntPvVtPY8w9cX5XCPZO+tc7GCGn507OdkCnlVEH4T0ut1OKW0YUXnO/D4uttS1cG7L+Y//eHPvm6KgZ37nrW2a8WAh/LNSnp+2xLfbjbi+Fa2K8mpS6UXciSRNHwrUnQ0MHzbHFFvuj8KKfX2vG+/rWBWPTdXveVq2NJFVa242oU7fofCbVnJqwWi0894LRb8uKzbrfSd0LAIBTjAQEAIiCBAQAiIIEBACIggQEAIiCBAQAiKKJt2GnwW2ZmbE/tuBtdc6cbYsFZ0uyeXyvrYEZtsd6vyq4rQWsLd7OmjinzsNbknzbmfPN3B1t3sHbw+0dO3yHxe3Wtlzp3/+H3zDjb42+Zcb3//AHwdjRKXtLcbVaM+OpsY27WLJf5MXWVjNebmkJxmp1e/v40iVLzHhnu90yoV6vBmNtrfbYyaNHzbj1weGWGjjvn4azrb5UDq95w2it4b+zj5nXN6AHHnhAl1xyiTo7O9XZ2am+vj59/etfn4lPTU2pv79fy5cvV3t7uzZt2qSRkZH5nAIA8C4xrwS0atUq3XXXXRocHNTzzz+v9evX65prrtErr7wiSbr99tv15JNP6rHHHtPAwIAOHjyo66677rRMHABwZpvXP8FdffXVs/77T/7kT/TAAw9o165dWrVqlR566CE9+uijWr9+vSTp4Ycf1kUXXaRdu3bp8ssvP3WzBgCc8Ra8CaHRaGj79u2amJhQX1+fBgcHVa/XtWHDhpn7XHjhhert7dXOnTuDx6lWqxofH591AwCc/eadgF5++WW1t7erUqnoM5/5jB5//HF94AMf0PDwsMrlspa87Y953d3dGh4eDh5v69at6urqmrmtXr163g8CAHDmmXcCuuCCC7R3717t3r1bN910k2644QZ997vfXfAEtmzZorGxsZnb0NDQgo8FADhzzHsbdrlc1vvf/35J0tq1a7Vnzx598Ytf1PXXX69arabR0dFZ34JGRkbU09MTPF6lUlGlUpn/zAEAZ7TcdUBpmqparWrt2rVqaWnRjh07tGnTJknSvn37dODAAfX19c37uI1GQ43G3PvMk4K1L96pxSk4X/qcOiGrDshrt+CWKFljc17e3zx13nLkHAUzznLnKuXxaiRO5ghm1HpO3DIgp32G1ZrDWbMlXUvM+Mc+dpUZ/4v924Ix7/L+BaeHRbESrtVZvMiu81m+bIkZbzNaWCxaZNdOtTnx3t5e59wdwZj3C3ajYa/p5ET47+ItlTZzbKEQbn8hSY3UquWRSi3h58SqX6rVwnVRs45/Uvc6bsuWLbrqqqvU29urw4cP69FHH9Wzzz6rp59+Wl1dXbrxxhu1efNmLVu2TJ2dnbrlllvU19fHDjgAwDvMKwEdOnRIv/Vbv6XXX39dXV1duuSSS/T000/rYx/7mCTpnnvuUaFQ0KZNm1StVrVx40bdf//9p2XiAIAz27wS0EMPPWTGW1tbtW3bNm3bFv4KDwCAxMVIAQCRkIAAAFGQgAAAUZCAAABRNG0/ILMOKA0XQqRGjZAkFZw6Bq/IwqwDcs6d+E19FjzWq0Eyz5rmrJc5rb2IFj43v8QoX88ea7x/bGfNjJep1+Nlerpuxl955Z/MeK0a7vlz0QXnm2PX/IwdP+fc7mCsXLZrViplu56mtXVxeKxRI3Ts3GUz3tnZZcZbjF5EnorTL6hYDM+tkdr9fLzXitXvR5Iyo0YpNWqIrNhP4xsQACAKEhAAIAoSEAAgChIQACAKEhAAIAoSEAAgiubdhp2Gt2EXjO3OztXglXnbrJ12DeZ2aOfcSWJvAbdbPdgH91tBGHF33nbc33Ecftxe+4w8/RhSr4VF3sfltVQwpF45gNGnYnra3nr7wuBuM/4P33rOjF904QXB2K9d/Rvm2BXd4d5fkv3e9bbupk7bAmvLsVci4b0YKq3OdmXj3O7jSp3HZUadMgbnPVAs2ClgYjLcCqJYCm8PL5bsUoAT+AYEAIiCBAQAiIIEBACIggQEAIiCBAQAiIIEBACIggQEAIiiaeuAUqMdg1Uj4SkU7Uu+y6ntSKy4W2PkxK2Y144hRzFPwal9Or2ctgROHYNZ3uTVAbn1SwtvqeC1Y/BqlKYmwy0Rdv6DXcfz1FP/y4z3rl5pxq9YvzEYW/me1eZY/7UUfv80Gt77w65/ahj1NH6dXL52J1YtT56xkl1HlzqtVNwaJKceraUl3AIjUbjWp1Q8udTCNyAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBTNWweUpsYediNvOiVCmb0tXkmOGiPv3IVs4fne6yXkjw9PzqozOD56wcc+foYFH9uqtZHskjCvjidz6i/qTt+d6Xq4DmJi4rA59sf7f2TG93x7ZzB26CfD5th169aZ8V/40EfMeHfPe8y4yVnzhlGXkq8vTj7eSzhzPjiCNYuSik7tofc6tdbFe+9a8zoWt8dXq+F6tMnJyWBsYmLCPO4JfAMCAERBAgIAREECAgBEQQICAERBAgIAREECAgBE0bTbsBtpGry8empc0t3bTpk6OdfbKu1vOQ5zWwtYMaeVg6dgzDv1tkL7R3fiObZhO+0xzJHOpeoPvLrfjH/3lZfN+Ojom8HY2Nhb5tgss7d4r1y5Khi7Yv2V9tj3hMdKUktL2YzbLRW8bb92PDW2M3vPl7sl39yS7LVEsI/t7Mg32x7kbccwbZx8auqoObZeC5cKSFKxaL8WatVaMFYyXkelFvu8J/ANCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQRdPWAdVrVdVb5p6eVadg1zBIctoaFAr2pdMTqxOEs98/ccocEqNWwW/l4FzS3ZhawQqeDGtRJJlz86+Dv+Bje0N7es4z40uXLTfj9VrVmJX3OrPXrFJuDcaKRe817rXPsIdbtTpy6mXcWh7j+fLHOkc2n3Bv3vaxSy0tZtx673t1PnWjrYckHR4fXfDYSqXNjGfOuhRL4cddMNpMlIxxs45xUvcCAOAUIwEBAKIgAQEAoiABAQCiIAEBAKIgAQEAoiABAQCiaN46oOlp1etz98EoGL1xikX7IXl1PllqN/6w6ju8chi3xsioz0hSp0+RfWrzDm79kntwr4eSVQfkLJpXGmId2xlr1TFIUltbuBbnWDxcY2H3pvHj1hPm9ZWSc2y/3MaqrXKO7dS8WFPPsyaSXdOSuL2E7DN7j8uKe8eemBg345NTU8GYVS8mSQXn89Dr32R9ZoU+n73YrOOf1L0AADjFSEAAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIAomrYOKE1TNYJ7641+QInRy0RSw6sHcIpHrGjBafhTLNrxxOgRY9bSKGcdkFFXdWyoF/caHS28T4vbLsiqWXEKXvxWRHn603h1J26B04LH+vU03mvJOLfbVydPvUy+fkD2uyDf+75er5lxq5bHe1jTTs2M1VvHW7PqVLhnlSQlTh1etRquQToycSQYO3r0qHncE/gGBACIggQEAIiCBAQAiIIEBACIggQEAIiCBAQAiKJpt2FnWRrcTpoa22un3W29zjZRo93CsfHGFlVnX6+3ybTgbp8Nc1sqWDFj+/exsc5+ZXcPuDHUeT78U+doW+DyxlttC5yRXrsGK+j2U8i35dhcdOeBpW4bCmvN8s47zHuJeueedso7JifD244LidMSwXk+rZ3tmVOeIefzrFazt2kfHg9vL7daOVSn6va0jsv1Deiuu+5SkiS67bbbZn42NTWl/v5+LV++XO3t7dq0aZNGRkbynAYAcBZacALas2ePvvSlL+mSSy6Z9fPbb79dTz75pB577DENDAzo4MGDuu6663JPFABwdllQAjpy5Ig++clP6i/+4i+0dOnSmZ+PjY3poYce0t13363169dr7dq1evjhh/WP//iP2rVr1ymbNADgzLegBNTf369PfOIT2rBhw6yfDw4Oql6vz/r5hRdeqN7eXu3cuXPOY1WrVY2Pj8+6AQDOfvPehLB9+3a98MIL2rNnzztiw8PDKpfLWrJkyayfd3d3a3h4eM7jbd26VX/0R38032kAAM5w8/oGNDQ0pFtvvVV/8zd/o9bW1lMygS1btmhsbGzmNjQ0dEqOCwBobvNKQIODgzp06JA+9KEPqVQqqVQqaWBgQPfdd59KpZK6u7tVq9U0Ojo6a9zIyIh6enrmPGalUlFnZ+esGwDg7Devf4K78sor9fLLL8/62ac+9SldeOGF+oM/+AOtXr1aLS0t2rFjhzZt2iRJ2rdvnw4cOKC+vr55TazRSNVozL333qu3sXj1Ml4dgzncqwNyL6NvHtwc6y9J+NyFzKkDyrHePu/c9mjzAvynsa7EP36+dgz2a2HhtTbH75FjvPca9+qbjGO7z9fC5V2TYqloxtNGeHxasGuIiqWKGc+mrXqbcLsESao7rR5qVbsOqFYzxhtvTq+26YR5JaCOjg5dfPHFs362ePFiLV++fObnN954ozZv3qxly5aps7NTt9xyi/r6+nT55ZfP51QAgLPcKb8Swj333KNCoaBNmzapWq1q48aNuv/++0/1aQAAZ7jcCejZZ5+d9d+tra3atm2btm3blvfQAICzGBcjBQBEQQICAERBAgIAREECAgBE0bT9gNJGQ2mgDii1evKcrgkdVyzm6JXi1l+EY149TJ7WN4XE+T3E6zXklgmFj+/2A3L7Oxkjc9XaSF69TWodP2c/IKfCacEjpXw9ezzuWOu9m3NemdU4x2Ufu1Cw64BKpfBHaX2qZo49OmFf/9IqqWlM2zVGXh3Q5NFwHyNJqtbCc0+MNZmcnDSPewLfgAAAUZCAAABRkIAAAFGQgAAAUZCAAABRkIAAAFE07Tbs6TTVdGhbpbEtMfW2Yjp7VN0tyVbO9loHODtUC8YW1aTgzCvH9tfgOh9XcCbuzs0YnzitIJTZ20wza6u0t33c+/3LWVL7teZtH/deZwvfCm1uD5f/HrHi7vsrz7ydY+dqn+EOtc9dq9fN+ORkuK3B+LjdMuHll/7JjP/ghz8IxurOvBrT9jbsRYsWmfGjxjbtUls5GJt2znsC34AAAFGQgAAAUZCAAABRkIAAAFGQgAAAUZCAAABRkIAAAFE0bR1QozGtRmPuveSJUXDj1UB4Col92fXMqFvx2hK4LRWK4aej4D0uL2y2PXDqQuxD+3OzCqQyu17Ar+sKn9u7hL6cVhCZdR18Oe0BnCfbra3K0WYiTe3aKS9u1XB4Y/Pw2zEs/Nijo2+Z8aeffsaMH3x9xIwfPhKuAypqsTn2x69914zXauFje7VRJeMzRZLWvO+9Zvy83pXB2GsTh4KxRqCVztvxDQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEEXT1gGljYbSwF7ypGAWSdgHzryGQE59hlUHVMyXz1OjJsaqfZKkPO1lvPoLT+bNzSyX8foY2WGr7itJnF5CzuP26rasRfeer9QtCgs/Lq8cJvS+OaHh1PJYPWSmA7V5/ypPHV6OejJvpPMG2f/jA2b8e/833JNHkiotbcFY+6Jl5th6PVzn4/J6VjmvBe/jcNl7zg3GRl4bDcYKdfoBAQCaGAkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQRfPWAWWZ0kA/Frt0ZOF9ViQpbTg9YKz+Mzl7EUnhPfsFp8bIaW1j9pDxaiS8vjjumhv1G15vG+fJduL2k+2f2x5fLBqPy1kTb03TLPxayJweSdMNO27V+Uh2Lxe3rsTpHmU+W856e1VA1rFbSvZH3fnn/6wZf+V7+8y4VVs1Pe3Vo5nhXKVV3tBiR8W+Q4v1Gl9Y7KfxDQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABBF827DbqRqONtJ51KwWjVIStyNiQvf85gUcvREkL3NNGnk21JsRQvOvN3tsc413c22B9683ZYI4VDBmXfqtmOw1yVUJnBsrDnUfZk1pmvhmNdOwSklqNfqZtxsueBuXbfDdjmAPdh7ndrtNexjv+e8lWa8Ui6b8WmjpUKjYa+391qwtrZ7T0ep0mLGi1324/rJW/8SjE0bLRcaztbzE/gGBACIggQEAIiCBAQAiIIEBACIggQEAIiCBAQAiKLptmGf2KY5OTm5oPGJuw3bncGCziv523ZzbcN2tqiyDfudTvc2bGvb/Wndhu3M27uiO9uw36laDW+jPnZs53VqxFPn6uX+ezcc954O79gNYyu1JE3Xw68Va6v1iZh3/iRzr0n/b+u1117T6tWrY08DAJDT0NCQVq1aFYw3XQJK01QHDx5UR0eHkiTR+Pi4Vq9eraGhIXV2dsae3hmBNZs/1mz+WLP5e7esWZZlOnz4sFauXGl+c226f4IrFApzZszOzs6z+gk7HViz+WPN5o81m793w5p1dXW592ETAgAgChIQACCKpk9AlUpFn/vc51SpOL3LMYM1mz/WbP5Ys/ljzWZruk0IAIB3h6b/BgQAODuRgAAAUZCAAABRkIAAAFGQgAAAUTR9Atq2bZve9773qbW1VevWrdO3v/3t2FNqGs8995yuvvpqrVy5UkmS6IknnpgVz7JMd955p8477zy1tbVpw4YN+v73vx9nsk1g69at+shHPqKOjg6tWLFC1157rfbt2zfrPlNTU+rv79fy5cvV3t6uTZs2aWRkJNKMm8MDDzygSy65ZKZ6v6+vT1//+tdn4qyZ7a677lKSJLrttttmfsaaHdPUCejLX/6yNm/erM997nN64YUXdOmll2rjxo06dOhQ7Kk1hYmJCV166aXatm3bnPEvfOELuu+++/Tggw9q9+7dWrx4sTZu3Kipqal/45k2h4GBAfX392vXrl165plnVK/X9fGPf1wTExMz97n99tv15JNP6rHHHtPAwIAOHjyo6667LuKs41u1apXuuusuDQ4O6vnnn9f69et1zTXX6JVXXpHEmln27NmjL33pS7rkkktm/Zw1Oy5rYpdddlnW398/89+NRiNbuXJltnXr1oizak6Ssscff3zmv9M0zXp6erI//dM/nfnZ6OhoVqlUsr/927+NMMPmc+jQoUxSNjAwkGXZsfVpaWnJHnvssZn7/PM//3MmKdu5c2esaTalpUuXZn/5l3/JmhkOHz6cnX/++dkzzzyT/cqv/Ep26623ZlnG6+ynNe03oFqtpsHBQW3YsGHmZ4VCQRs2bNDOnTsjzuzMsH//fg0PD89av66uLq1bt471O25sbEyStGzZMknS4OCg6vX6rDW78MIL1dvby5od12g0tH37dk1MTKivr481M/T39+sTn/jErLWReJ39tKa7GvYJb7zxhhqNhrq7u2f9vLu7W9/73vcizerMMTw8LElzrt+J2LtZmqa67bbb9NGPflQXX3yxpGNrVi6XtWTJkln3Zc2kl19+WX19fZqamlJ7e7sef/xxfeADH9DevXtZszls375dL7zwgvbs2fOOGK+zf9W0CQg4nfr7+/Wd73xH3/rWt2JP5YxwwQUXaO/evRobG9NXvvIV3XDDDRoYGIg9raY0NDSkW2+9Vc8884xaW1tjT6epNe0/wZ1zzjkqFovv2BkyMjKinp6eSLM6c5xYI9bvnW6++WZ97Wtf0ze/+c1Zvad6enpUq9U0Ojo66/6smVQul/X+979fa9eu1datW3XppZfqi1/8Ims2h8HBQR06dEgf+tCHVCqVVCqVNDAwoPvuu0+lUknd3d2s2XFNm4DK5bLWrl2rHTt2zPwsTVPt2LFDfX19EWd2ZlizZo16enpmrd/4+Lh27979rl2/LMt088036/HHH9c3vvENrVmzZlZ87dq1amlpmbVm+/bt04EDB961axaSpqmq1SprNocrr7xSL7/8svbu3Ttz+/CHP6xPfvKTM/+fNTsu9i4Iy/bt27NKpZI98sgj2Xe/+93s05/+dLZkyZJseHg49tSawuHDh7MXX3wxe/HFFzNJ2d133529+OKL2auvvpplWZbddddd2ZIlS7KvfvWr2UsvvZRdc8012Zo1a7LJycnIM4/jpptuyrq6urJnn302e/3112duR48enbnPZz7zmay3tzf7xje+kT3//PNZX19f1tfXF3HW8d1xxx3ZwMBAtn///uyll17K7rjjjixJkuzv//7vsyxjzU7GT++CyzLW7ISmTkBZlmV/9md/lvX29mblcjm77LLLsl27dsWeUtP45je/mUl6x+2GG27IsuzYVuzPfvazWXd3d1apVLIrr7wy27dvX9xJRzTXWknKHn744Zn7TE5OZr/3e7+XLV26NFu0aFH267/+69nrr78eb9JN4Hd+53ey9773vVm5XM7OPffc7Morr5xJPlnGmp2Mtycg1uwY+gEBAKJo2r8BAQDObiQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAU/x+Dl1Yp/pcVNAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCSVRbYZmmOG"
      },
      "source": [
        "Train model using Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def model_train(model, device, train_loader, optimizer, criterion, train_acc, train_losses):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        print(loss)\n",
        "        train_loss+=loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct+= output.argmax(dim=1).eq(target).sum().item()\n",
        "        processed+= len(data)\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx} Accuracy = {100*correct/processed:0.2f}')\n",
        "\n",
        "    train_acc.append(100*correct/processed)\n",
        "    train_losses.append(train_loss/len(train_loader))\n",
        "    return  loss.item()\n"
      ],
      "metadata": {
        "id": "cB49PmvsdebC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ysHqVyhGZJ27",
        "outputId": "dc5bf526-f6f9-4f72-ed55-6257cd9b151d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6533d243d6dd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "num_epochs=24\n",
        "unet_model = UNet(in_channels=3,out_channels=1).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(unet_model.parameters())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "I8RlOADSBX4y",
        "outputId": "68d7923c-8d78-4eae-894c-95aa96003358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.48013442754745483 batch_id=2 Accuracy = 0.00:   3%|▎         | 3/115 [00:01<01:11,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-712fc622cb78>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mthis_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#this_loss = model_test(resnet_model, device, test_loader, criterion, test_acc, test_losses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#optim_obj.scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e684aba8dc33>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(model, device, train_loader, optimizer, criterion, train_acc, train_losses)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "lr_values = []\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    this_train_loss = model_train(unet_model, device, train_loader, optimizer, criterion, train_acc, train_losses)\n",
        "    #this_loss = model_test(resnet_model, device, test_loader, criterion, test_acc, test_losses)\n",
        "    #optim_obj.scheduler.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7zJvrQjP8nR"
      },
      "source": [
        "Plot LR values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTncfVknP7wM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_lr_values2(lr_list):\n",
        "    num_epochs = len(lr_list)\n",
        "    plt.figure()\n",
        "    plt.plot(range(1,num_epochs+1),lr_list)\n",
        "    plt.xlabel('Epoch #')\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    #plt.yscale('log')\n",
        "    plt.show()\n",
        "\n",
        "def plot_lr_values(scheduler, num_epochs, num_batches):\n",
        "    lrs = []\n",
        "    steps = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in range(num_batches):\n",
        "            scheduler.step()\n",
        "            lrs.append(scheduler.get_last_lr()[0])\n",
        "            steps.append(epoch * num_batches + batch)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.legend()\n",
        "    plt.plot(steps, lrs, label='OneCycle')\n",
        "    plt.show()\n",
        "\n",
        "def plot_losses(train_losses, test_losses):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "    epochs = range(1,len(train_losses)+1)\n",
        "    axs[0].plot(epochs, train_losses)\n",
        "    axs[0].set_title(\"Train\")\n",
        "    axs[1].plot(epochs, test_losses)\n",
        "    axs[1].set_title(\"Test\")\n",
        "\n",
        "def plot_accuracy(train_acc, test_acc, target_test_acc = 90.):\n",
        "    epochs = range(1,len(train_acc)+1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_acc, epochs, test_acc)\n",
        "    plt.axhline(target_test_acc, color='r')\n",
        "    plt.legend(('Train','Test'),loc='best')\n",
        "    plt.title(\"Accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWzELTZYazCZ"
      },
      "source": [
        "Plot results for Batch Norm experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEU2V5lxayQJ"
      },
      "outputs": [],
      "source": [
        "this_scheduler = OneCycleLR(\n",
        "        optim_obj.optimizer,\n",
        "        max_lr = max_lr,\n",
        "        steps_per_epoch=len(optim_obj.train_loader),\n",
        "        epochs = num_epochs,\n",
        "        pct_start = 5./num_epochs,\n",
        "        div_factor=200,\n",
        "        three_phase=False,\n",
        "        #final_div_factor=1000,\n",
        "        anneal_strategy='linear',\n",
        "        verbose=False\n",
        "        )\n",
        "plot_lr_values(this_scheduler, num_epochs, len(train_loader))\n",
        "plot_losses(train_losses, test_losses)\n",
        "plot_accuracy(train_acc, test_acc, target_test_acc=90.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Uz2jryV3u1"
      },
      "source": [
        "Print Training Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ew5n7bbgW1OK"
      },
      "outputs": [],
      "source": [
        "print_train_log(train_acc, test_acc, train_losses, test_losses)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}