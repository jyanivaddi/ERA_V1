{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_18/s18_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMv-YR2zikee"
      },
      "source": [
        "Download our code repository and install python dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8J1MOmbqmgC",
        "outputId": "2be8956c-622c-408e-b6d5-13b4906ff11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ERA_V1'...\n",
            "remote: Enumerating objects: 1497, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 1497 (delta 31), reused 34 (delta 5), pack-reused 1407\u001b[K\n",
            "Receiving objects: 100% (1497/1497), 201.92 MiB | 26.57 MiB/s, done.\n",
            "Resolving deltas: 100% (723/723), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n",
        "!git pull\n",
        "!pip install torchinfo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"ERA_V1/session_18\")\n"
      ],
      "metadata": {
        "id": "jBbACfNkwYD9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW3WHIzUqmgF"
      },
      "source": [
        "Add all the imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "zQ5ZSVQJqmgI"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "import albumentations.augmentations as AA\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from unet_model import UNet\n",
        "from data_loader import load_oxford_pet_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4AHY0CsqmgL"
      },
      "source": [
        "Allocate GPU and print model summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_summary(model, input_size):\n",
        "    summary(model, input_size = input_size)"
      ],
      "metadata": {
        "id": "hzhSfiUE6D4V"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "3xmgYQudqmgM",
        "outputId": "50a34815-cd07-428a-da18-e56136e1c256"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-c7c6d9949a05>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0munet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-44fe6805c845>\u001b[0m in \u001b[0;36mmodel_summary\u001b[0;34m(model, input_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ERA_V1/session_18/unet_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Expanding path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             for hook_id, hook in (\n",
            "\u001b[0;32m/content/ERA_V1/session_18/unet_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, skip)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# concatenate the skip connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 6 but got size 12 for tensor number 1 in the list."
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "unet_model = UNet(in_channels=3,out_channels=1).to(device)\n",
        "model_summary(unet_model, input_size=(3,48,48))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF0JlvTsqmgP"
      },
      "source": [
        "Define Albumentations image augmentations. We use RandomResizedCrop, HorizontalFlip, and cutout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(48),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(48),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "target_transform = transforms.Compose([transforms.Resize(48)])"
      ],
      "metadata": {
        "id": "3hLwMa6Ky3Ff"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "pI6EVt-jmGp6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import Any\n",
        "from torchvision import datasets, transforms\n",
        "import albumentations as A\n",
        "import albumentations.augmentations as AA\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def oxford_transforms(image, mask):\n",
        "    # Resize\n",
        "    resize = transforms.Resize(size=(48, 48))\n",
        "    image = resize(image)\n",
        "    mask = resize(mask)\n",
        "\n",
        "    # Transform to tensor\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    image = to_tensor(image)\n",
        "    mask = to_tensor(mask)\n",
        "    return image, mask\n",
        "\n",
        "class OxfordPetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.dataset = dataset\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index) -> Any:\n",
        "        image, label = self.dataset[index]\n",
        "        image = np.array(image)\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "        return (image, label)\n",
        "\n",
        "\n",
        "def load_oxford_pet_data(train_transforms, test_transforms, batch_size, **kwargs):\n",
        "    train_data = datasets.OxfordIIITPet('../data', split='trainval', transforms = train_transforms, target_transform = None, target_types='segmentation', download=True)\n",
        "    test_data = datasets.OxfordIIITPet('../data', split='test', transforms = test_transforms, target_transform = None, target_types='segmentation', download=True)\n",
        "\n",
        "    train_loader = DataLoader(train_data,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True,\n",
        "                              **kwargs)\n",
        "    test_loader = DataLoader(test_data,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=True,\n",
        "                             **kwargs)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6f-Ko64qmgU"
      },
      "source": [
        "Define batch size, train and test loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Z8mQv0iUqmgV"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 32\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader, test_loader = load_oxford_pet_data(train_transforms=oxford_transforms, test_transforms=oxford_transforms, batch_size=batch_size, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b = next(iter(train_loader))\n"
      ],
      "metadata": {
        "id": "XVlZ9lf1yL8w"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.asarray(b[0])\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(c.squeeze())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gd6m-KrW4i2I",
        "outputId": "8a3a9dc0-e596-49ff-8520-f47bf3890377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BJ_T8ExsnE_"
      },
      "source": [
        "Preview Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQB2RLRxtSlv"
      },
      "source": [
        "Show sample Images from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjjB363XqmgW"
      },
      "outputs": [],
      "source": [
        "preview_images(train_loader,class_names, num_rows = 5, num_cols = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCSVRbYZmmOG"
      },
      "source": [
        "Train model using Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysHqVyhGZJ27"
      },
      "outputs": [],
      "source": [
        "drop_out = 0.02\n",
        "num_epochs=24\n",
        "resnet_model = CustomResnet(base_channels=3, num_classes=10,drop_out_probability=drop_out).to(device)\n",
        "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "optim_obj = Optimization(resnet_model, device, train_loader, criterion, num_epochs)\n",
        "lr_history = find_best_lr(resnet_model, train_loader, optim_obj.optimizer, criterion, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8RlOADSBX4y"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "lr_values = []\n",
        "max_lr = 4.65e-2\n",
        "# Define scheduler\n",
        "optim_obj.define_scheduler(max_lr)\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    lr_values.append(optim_obj.scheduler.get_lr())\n",
        "    print(f\"epoch: {epoch}\\t learning rate: {optim_obj.scheduler.get_last_lr()[0]}\")\n",
        "    this_train_loss = training_loop(resnet_model, device, train_loader, optim_obj.optimizer, optim_obj.scheduler, criterion, train_acc, train_losses)\n",
        "    this_loss = model_test(resnet_model, device, test_loader, criterion, test_acc, test_losses)\n",
        "    #optim_obj.scheduler.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7zJvrQjP8nR"
      },
      "source": [
        "Plot LR values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTncfVknP7wM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_lr_values2(lr_list):\n",
        "    num_epochs = len(lr_list)\n",
        "    plt.figure()\n",
        "    plt.plot(range(1,num_epochs+1),lr_list)\n",
        "    plt.xlabel('Epoch #')\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    #plt.yscale('log')\n",
        "    plt.show()\n",
        "\n",
        "def plot_lr_values(scheduler, num_epochs, num_batches):\n",
        "    lrs = []\n",
        "    steps = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in range(num_batches):\n",
        "            scheduler.step()\n",
        "            lrs.append(scheduler.get_last_lr()[0])\n",
        "            steps.append(epoch * num_batches + batch)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.legend()\n",
        "    plt.plot(steps, lrs, label='OneCycle')\n",
        "    plt.show()\n",
        "\n",
        "def plot_losses(train_losses, test_losses):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "    epochs = range(1,len(train_losses)+1)\n",
        "    axs[0].plot(epochs, train_losses)\n",
        "    axs[0].set_title(\"Train\")\n",
        "    axs[1].plot(epochs, test_losses)\n",
        "    axs[1].set_title(\"Test\")\n",
        "\n",
        "def plot_accuracy(train_acc, test_acc, target_test_acc = 90.):\n",
        "    epochs = range(1,len(train_acc)+1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_acc, epochs, test_acc)\n",
        "    plt.axhline(target_test_acc, color='r')\n",
        "    plt.legend(('Train','Test'),loc='best')\n",
        "    plt.title(\"Accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWzELTZYazCZ"
      },
      "source": [
        "Plot results for Batch Norm experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEU2V5lxayQJ"
      },
      "outputs": [],
      "source": [
        "this_scheduler = OneCycleLR(\n",
        "        optim_obj.optimizer,\n",
        "        max_lr = max_lr,\n",
        "        steps_per_epoch=len(optim_obj.train_loader),\n",
        "        epochs = num_epochs,\n",
        "        pct_start = 5./num_epochs,\n",
        "        div_factor=200,\n",
        "        three_phase=False,\n",
        "        #final_div_factor=1000,\n",
        "        anneal_strategy='linear',\n",
        "        verbose=False\n",
        "        )\n",
        "plot_lr_values(this_scheduler, num_epochs, len(train_loader))\n",
        "plot_losses(train_losses, test_losses)\n",
        "plot_accuracy(train_acc, test_acc, target_test_acc=90.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Uz2jryV3u1"
      },
      "source": [
        "Print Training Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ew5n7bbgW1OK"
      },
      "outputs": [],
      "source": [
        "print_train_log(train_acc, test_acc, train_losses, test_losses)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}