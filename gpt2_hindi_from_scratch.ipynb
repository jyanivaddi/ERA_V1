{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKT6FaNWzGUbRhcd7V+T9I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/gpt2_hindi_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARkRHQ2v7KSD",
        "outputId": "93d2f3d0-071e-4cd9-e1bd-a331b73b954f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/jyanivaddi/dl_hub.git\"\n",
        "!git -C dl_hub pull\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICgTNwcQUD8L",
        "outputId": "0ebb9567-085a-4d8c-8bc0-f4438b815c3f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dl_hub'...\n",
            "remote: Enumerating objects: 581, done.\u001b[K\n",
            "remote: Counting objects: 100% (333/333), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 581 (delta 215), reused 291 (delta 183), pack-reused 248\u001b[K\n",
            "Receiving objects: 100% (581/581), 161.26 KiB | 1.60 MiB/s, done.\n",
            "Resolving deltas: 100% (359/359), done.\n",
            "Already up to date.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fte3KS2c68Pr",
        "outputId": "f6068d39-820d-4e1a-f883-b21ebc9dea00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet \"torchtext\" \"datasets\" \"tokenizers\" \"transformers\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the train and val datasets"
      ],
      "metadata": {
        "id": "JW0kCFY8ALdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = '/content/gdrive/MyDrive/Datasets/Hindi_Aesthetics/hindi_train.txt'\n",
        "val_dataset_path = '/content/gdrive/MyDrive/Datasets/Hindi_Aesthetics/hindi_val.txt'\n",
        "all_data_path = '/content/gdrive/MyDrive/Datasets/Hindi_Aesthetics/hindi_asthetics_corpus.txt'"
      ],
      "metadata": {
        "id": "VIeI2nM4AKIK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First lets build our vocabulary by tokenizing the data using word level encoding from class"
      ],
      "metadata": {
        "id": "JHD8-uKF2bfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers import Tokenizer\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def build_word_level_tokenizer(data_iterator, tokenizer_path = None):\n",
        "    if tokenizer_path is None:\n",
        "        # code inspired from huggingface tokenizers\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"],\n",
        "                                    min_frequency=2)\n",
        "        tokenizer.train_from_iterator(data_iterator, trainer=trainer)\n",
        "        #tokenizer.train(files=[all_data_path], vocab_size=52_000, min_frequency=2, special_tokens=[\"<s>\",\"<pad>\",\"</s>\",\"<unk>\",\"<mask>\"])\n",
        "        tokenizer.save('./hindi_aesthetics_word_level.json')\n",
        "    else:\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "cG6FIv4R2ejr"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(all_data_path,'r',encoding='UTF-8') as fh:\n",
        "    all_data = fh.readlines()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIgX_sYs4mbE",
        "outputId": "d8dbbd1e-3498-44c8-e757-a88a8eb2698c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "649481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_path = '/content/gdrive/MyDrive/Datasets/Hindi_Aesthetics/hindi_aesthetics_word_level.json'\n",
        "tokenizer = build_word_level_tokenizer(all_data, tokenizer_path)"
      ],
      "metadata": {
        "id": "u5voqahg43lU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets build our dataloader"
      ],
      "metadata": {
        "id": "jRHHKreN7-z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class HindiAestheticsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, ds_path, tokenizer, seq_len=64):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.ds_path = ds_path\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.sos_token = torch.tensor([tokenizer.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
        "        self.eos_token = torch.tensor([tokenizer.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
        "        self.pad_token = torch.tensor([tokenizer.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "        with open(ds_path, 'r', encoding='UTF-8') as fh:\n",
        "            self.ds = fh.readlines()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get a src, target pair\n",
        "        input_text = self.ds[idx]\n",
        "\n",
        "        # transform the text into tokens\n",
        "        input_tokens = self.tokenizer.encode(input_text).ids\n",
        "        num_input_tokens = len(input_tokens)\n",
        "\n",
        "        #print(\"inside get item and I am returning the dict list!\")\n",
        "        return {\n",
        "            \"input_tokens\": input_tokens,\n",
        "            \"token_len\": num_input_tokens,\n",
        "            \"input_sentence\": input_text,\n",
        "        }\n",
        "\n",
        "    def collate_samples(self, batch):\n",
        "        \"\"\"\n",
        "        Perform dynamic batching on the sequences.\n",
        "        For each batch, we get the length of the longest sentence and pad the remaining sentences according to that.\n",
        "        \"\"\"\n",
        "\n",
        "        #print(\"inside collate function\")\n",
        "        # max encoder str length\n",
        "        max_len = max(x[\"token_len\"] for x in batch)\n",
        "        #print(f\"longest encoder input in this batch: {encoder_input_max}\")\n",
        "\n",
        "        x_list = []\n",
        "        y_list = []\n",
        "        input_sentences = []\n",
        "\n",
        "        for cnt, x in enumerate(batch):\n",
        "            # Add sos, eos and padding to each sentence\n",
        "            num_padding_tokens_input = max(0, max_len - len(x[\"input_tokens\"]))  # we will add <s> and </s>\n",
        "            # we will only add only the <s> token to the decoder\n",
        "            num_padding_tokens_output = num_padding_tokens_input+1\n",
        "\n",
        "            # Add <s> and </s> token\n",
        "            batch_x = torch.cat(\n",
        "                [\n",
        "                    self.sos_token,\n",
        "                    torch.tensor(x[\"input_tokens\"], dtype=torch.int64),\n",
        "                    self.eos_token,\n",
        "                    torch.tensor([self.pad_token] * num_padding_tokens_input, dtype=torch.int64),\n",
        "                ],\n",
        "                dim=0,\n",
        "            )\n",
        "\n",
        "            # Add only the <s>\n",
        "            batch_y = torch.cat(\n",
        "                [\n",
        "                    torch.tensor(x[\"input_tokens\"], dtype=torch.int64),\n",
        "                    torch.tensor([self.pad_token] * num_padding_tokens_output, dtype=torch.int64),\n",
        "                ],\n",
        "                dim=0,\n",
        "            )\n",
        "            x_list.append(batch_x)\n",
        "            y_list.append(batch_y)\n",
        "            input_sentences.append(x[\"input_sentence\"])\n",
        "\n",
        "        #print(\"inside get item and I am returning the dict list!\")\n",
        "        return {\n",
        "            \"x\": torch.vstack(x_list),\n",
        "            \"y\": torch.vstack(y_list),\n",
        "            \"input_sentences\": input_sentences,\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "OZeAL2Hs9oN2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_ds = HindiAestheticsDataset(train_dataset_path, tokenizer)\n",
        "val_ds = HindiAestheticsDataset(val_dataset_path, tokenizer)\n",
        "train_dataloader = DataLoader(dataset = train_ds,\n",
        "                              batch_size = BATCH_SIZE,\n",
        "                              num_workers = 1,\n",
        "                              collate_fn = train_ds.collate_samples)\n",
        "val_dataloader = DataLoader(dataset = val_ds,\n",
        "                            batch_size = 1,\n",
        "                            num_workers = 1,\n",
        "                            collate_fn = val_ds.collate_samples)"
      ],
      "metadata": {
        "id": "hVqp45lcMJyB"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vals = next(iter(train_dataloader))\n"
      ],
      "metadata": {
        "id": "jR_05yxVNA3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vals['x'][2])\n",
        "print(vals['y'][2])\n",
        "print(vals['input_sentences'][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHm7JstcOWGq",
        "outputId": "228dab11-7c06-4682-dd25-9a60d46ed259"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    2,     6,   425,  3189,   855,    62,   184,   725,  1970,   208,\n",
            "           68,   190,     5,  7429,     6,    46,    57,     7,     0,   411,\n",
            "           11,  1363,    26,   122,  1220,    35,  1363,   607, 14573,     0,\n",
            "           22,  8771,  2236,     6,     3])\n",
            "tensor([    6,   425,  3189,   855,    62,   184,   725,  1970,   208,    68,\n",
            "          190,     5,  7429,     6,    46,    57,     7,     0,   411,    11,\n",
            "         1363,    26,   122,  1220,    35,  1363,   607, 14573,     0,    22,\n",
            "         8771,  2236,     6,     1])\n",
            "में इसकी धार सीधे  बहुत बड़े वर्ग समुदाय समाज या देश के संदर्भों में  उस तरह की बृहत सोच को दिशा न दे पाई  जो दिशा सर रिचर्ड एटनबरो ने सिनेमाई अंदाज में\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dl_hub.transformer_models.transformer_models import GPT\n"
      ],
      "metadata": {
        "id": "Bt2IkQdgUMB2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train a new model\n",
        "vocab_size = tokenizer.get_vocab_size()\n",
        "NUM_HEAD = 6\n",
        "NUM_EMBED = NUM_HEAD*128\n",
        "NUM_LAYER = 6\n",
        "DROPOUT = 0.2\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BLOCK_SIZE = 64\n",
        "model = GPT(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=NUM_EMBED,\n",
        "    block_size=BLOCK_SIZE,\n",
        "    num_heads=NUM_HEAD,\n",
        "    num_layers=NUM_LAYER,\n",
        "    dropout=DROPOUT,\n",
        "    device = DEVICE\n",
        ")\n",
        "# load model to GPU if available\n",
        "m = model.to(DEVICE)\n",
        "# print the number of parameters in the model\n",
        "print(\n",
        "    \"Model with {:.2f}M parameters\".format(sum(p.numel() for p in m.parameters()) / 1e6)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POR_b7FEVjsd",
        "outputId": "c0ed56b6-59fc-4c43-da27-318767723b33"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with 88.65M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data_loader):\n",
        "    vals = next(iter(train_dataloader))\n",
        "    x = vals[\"x\"]\n",
        "    y = vals[\"y\"]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(\n",
        "    data_loader,\n",
        "    model: torch.nn.Module,\n",
        "    block_size: int,\n",
        "    batch_size: int,\n",
        "    eval_iters:int = 200):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "        X, Y = get_batch(data_loader)\n",
        "        logits, loss = model.forward(X, Y)\n",
        "        losses[k] = loss.item()\n",
        "    out = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "eMz3QwJoWbas"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer takes the model's parameters and the learning rate as input,\n",
        "# and updates the parameters during the training process in order to\n",
        "# minimize the loss function.\n",
        "LEARNING_RATE = 3e-4\n",
        "EVAL_INTER = 500\n",
        "\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=LEARNING_RATE)\n",
        "MAX_ITER = 500\n",
        "for step in range(MAX_ITER):\n",
        "\n",
        "    # every EVAL_INTER evaluate the loss on train and val sets\n",
        "    if step % EVAL_INTER == 0 or step == MAX_ITER - 1:\n",
        "        loss_train = estimate_loss(\n",
        "            data=train_dataloader, model=m, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE\n",
        "        )\n",
        "        loss_val = estimate_loss(\n",
        "            data=val_dataloader, model=m, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE\n",
        "        )\n",
        "        print(\"step {:10} | train loss {:6.4f} | val loss {:6.4f}\".format(step, loss_train, loss_val))\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch(data=train_dataloader)\n",
        "    logits, loss = m.forward(xb, yb)\n",
        "    # zero_grad() method sets the gradients of all parameters in the optimizer to zero\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    # backward() method on the loss variable calculates the gradients\n",
        "    # of the loss with respect to the model's parameters.\n",
        "    loss.backward()\n",
        "    # step() method on the optimizer updates the model's parameters\n",
        "    # using the calculated gradients, in order to minimize the loss.\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "bFchAl3rXZrD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}