{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdEc36yhBcg4y1e4nT6qYK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/gpt2_hindi_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARkRHQ2v7KSD",
        "outputId": "93d2f3d0-071e-4cd9-e1bd-a331b73b954f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fte3KS2c68Pr",
        "outputId": "f6068d39-820d-4e1a-f883-b21ebc9dea00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet \"torchtext\" \"datasets\" \"tokenizers\" \"transformers\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the train and val datasets"
      ],
      "metadata": {
        "id": "JW0kCFY8ALdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = '/content/gdrive/MyDrive/Datasets/Hindi_Aesthetics/hindi_train.txt'\n",
        "val_dataset_path = '/content/gdrive/MyDrive/Datasets/Hindi_Aesthetics/hindi_val.txt'\n",
        "all_data_path = '/content/gdrive/MyDrive/Datasets/Hindi_Aesthetics/hindi_asthetics_corpus.txt'"
      ],
      "metadata": {
        "id": "VIeI2nM4AKIK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First lets build our vocabulary by tokenizing the data using word level encoding from class"
      ],
      "metadata": {
        "id": "JHD8-uKF2bfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers import Tokenizer\n",
        "\n",
        "\n",
        "def build_word_level_tokenizer(data_iterator):\n",
        "    # code inspired from huggingface tokenizers\n",
        "    tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "    tokenizer.pre_tokenizer = Whitespace()\n",
        "    trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"],\n",
        "                                min_frequency=2)\n",
        "    tokenizer.train_from_iterator(data_iterator, trainer=trainer)\n",
        "    #tokenizer.train(files=[all_data_path], vocab_size=52_000, min_frequency=2, special_tokens=[\"<s>\",\"<pad>\",\"</s>\",\"<unk>\",\"<mask>\"])\n",
        "    tokenizer.save('./hindi_aesthetics_word_level.json')\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "cG6FIv4R2ejr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(all_data_path,'r',encoding='UTF-8') as fh:\n",
        "    all_data = fh.readlines()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIgX_sYs4mbE",
        "outputId": "d8dbbd1e-3498-44c8-e757-a88a8eb2698c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "649481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = build_word_level_tokenizer(all_data)"
      ],
      "metadata": {
        "id": "u5voqahg43lU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets build our dataloader"
      ],
      "metadata": {
        "id": "jRHHKreN7-z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class HindiAestheticsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, ds_path, tokenizer, seq_len=64):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.ds_path = ds_path\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.sos_token = torch.tensor([tokenizer.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
        "        self.eos_token = torch.tensor([tokenizer.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
        "        self.pad_token = torch.tensor([tokenizer.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "        with open(ds_path, 'r', encoding='UTF-8') as fh:\n",
        "            self.ds = fh.readlines()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get a src, target pair\n",
        "        input_text = self.ds[idx]\n",
        "\n",
        "        # transform the text into tokens\n",
        "        input_tokens = self.tokenizer.encode(input_text).ids\n",
        "        num_input_tokens = len(input_tokens)\n",
        "\n",
        "        #print(\"inside get item and I am returning the dict list!\")\n",
        "        return {\n",
        "            \"input_tokens\": input_tokens,\n",
        "            \"token_len\": num_input_tokens,\n",
        "            \"input_sentence\": input_text,\n",
        "        }\n",
        "\n",
        "    def collate_samples(self, batch):\n",
        "        \"\"\"\n",
        "        Perform dynamic batching on the sequences.\n",
        "        For each batch, we get the length of the longest sentence and pad the remaining sentences according to that.\n",
        "        \"\"\"\n",
        "\n",
        "        #print(\"inside collate function\")\n",
        "        # max encoder str length\n",
        "        max_len = max(x[\"token_len\"] for x in batch)\n",
        "        #print(f\"longest encoder input in this batch: {encoder_input_max}\")\n",
        "\n",
        "        x_list = []\n",
        "        y_list = []\n",
        "        input_sentences = []\n",
        "\n",
        "        for cnt, x in enumerate(batch):\n",
        "            # Add sos, eos and padding to each sentence\n",
        "            num_padding_tokens_input = max(0, max_len - len(x[\"input_tokens\"]))  # we will add <s> and </s>\n",
        "            # we will only add only the <s> token to the decoder\n",
        "            num_padding_tokens_output = num_padding_tokens_input+1\n",
        "\n",
        "            # Add <s> and </s> token\n",
        "            batch_x = torch.cat(\n",
        "                [\n",
        "                    self.sos_token,\n",
        "                    torch.tensor(x[\"input_tokens\"], dtype=torch.int64),\n",
        "                    self.eos_token,\n",
        "                    torch.tensor([self.pad_token] * num_padding_tokens_input, dtype=torch.int64),\n",
        "                ],\n",
        "                dim=0,\n",
        "            )\n",
        "\n",
        "            # Add only the <s>\n",
        "            batch_y = torch.cat(\n",
        "                [\n",
        "                    torch.tensor(x[\"input_tokens\"], dtype=torch.int64),\n",
        "                    torch.tensor([self.pad_token] * num_padding_tokens_output, dtype=torch.int64),\n",
        "                ],\n",
        "                dim=0,\n",
        "            )\n",
        "            x_list.append(batch_x)\n",
        "            y_list.append(batch_y)\n",
        "            input_sentences.append(x[\"input_sentence\"])\n",
        "\n",
        "        #print(\"inside get item and I am returning the dict list!\")\n",
        "        return {\n",
        "            \"x\": torch.vstack(x_list),\n",
        "            \"y\": torch.vstack(y_list),\n",
        "            \"input_sentences\": input_sentences,\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "OZeAL2Hs9oN2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = HindiAestheticsDataset(train_dataset_path, tokenizer)\n",
        "val_ds = HindiAestheticsDataset(val_dataset_path, tokenizer)\n",
        "train_dataloader = DataLoader(dataset = train_ds,\n",
        "                              batch_size = 8,\n",
        "                              num_workers = 1,\n",
        "                              collate_fn = train_ds.collate_samples)\n",
        "val_dataloader = DataLoader(dataset = val_ds,\n",
        "                            batch_size = 1,\n",
        "                            num_workers = 1,\n",
        "                            collate_fn = val_ds.collate_samples)"
      ],
      "metadata": {
        "id": "hVqp45lcMJyB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vals = next(iter(train_dataloader))\n"
      ],
      "metadata": {
        "id": "jR_05yxVNA3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vals['x'][0])\n",
        "print(vals['y'][0])\n",
        "print(vals['input_sentences'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHm7JstcOWGq",
        "outputId": "317a3778-d137-4e1b-d1dc-749dfc69f333"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    2,    25,  5476,    13, 25517,     9,    14,   281,   989,     4,\n",
            "            3,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1])\n",
            "tensor([   25,  5476,    13, 25517,     9,    14,   281,   989,     4,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1])\n",
            " यह चुटकी तो पहलेवाली से भी ज्यादा गहरी है\n",
            "\n"
          ]
        }
      ]
    }
  ]
}