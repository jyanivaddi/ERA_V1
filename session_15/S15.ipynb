{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_15/S15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZ4DqRTb9Ym8"
   },
   "source": [
    "First Connect Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDhBByBZ8qi9",
    "outputId": "f84d600d-7735-4f6b-e826-05041631fa8e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgHQxuQMAJ5o"
   },
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-15T11:24:45.241258Z",
     "iopub.status.busy": "2023-08-15T11:24:45.240841Z",
     "iopub.status.idle": "2023-08-15T11:25:50.896569Z",
     "shell.execute_reply": "2023-08-15T11:25:50.895113Z",
     "shell.execute_reply.started": "2023-08-15T11:24:45.241226Z"
    },
    "id": "VAOiUa_mAJVQ",
    "outputId": "b0f2ab9c-d179-441d-fdca-284c01631b13",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n",
    "!git -C ERA_V1 pull\n",
    "#!cd ../\n",
    "!git clone \"https://github.com/jyanivaddi/dl_hub.git\"\n",
    "!git -C dl_hub pull\n",
    "!git pull\n",
    "#!cd ../\n",
    "\n",
    "!pip install --quiet \"torchinfo\" \"seaborn\" \"pytorch-lightning\" \"torchmetrics\" \"lightning-bolts\", \"torchtext\", \"datasets\", \"tokenizers\"\n",
    "!pip install --quiet \"prettytable\"\n",
    "!pip install --quiet \"torchsummary\"\n",
    "!pip install --quiet \"torch_lr_finder\"\n",
    "!pip install --quiet \"grad-cam\"\n",
    "!pip install --quiet \"gradio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T11:26:21.699043Z",
     "iopub.status.busy": "2023-08-15T11:26:21.698652Z",
     "iopub.status.idle": "2023-08-15T11:26:21.704208Z",
     "shell.execute_reply": "2023-08-15T11:26:21.703030Z",
     "shell.execute_reply.started": "2023-08-15T11:26:21.699011Z"
    },
    "id": "ivBzl8YFPvJ0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"ERA_V1/session_15\")\n",
    "sys.path.append(\"dl_hub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-15T11:31:55.436556Z",
     "iopub.status.busy": "2023-08-15T11:31:55.435500Z",
     "iopub.status.idle": "2023-08-15T11:31:56.839658Z",
     "shell.execute_reply": "2023-08-15T11:31:56.838219Z",
     "shell.execute_reply.started": "2023-08-15T11:31:55.436518Z"
    },
    "id": "n41Pe-b1J3mC",
    "outputId": "a8cbac66-45be-4bab-9e28-2db0da2b7505",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git -C dl_hub pull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "execution": {
     "iopub.execute_input": "2023-08-15T11:32:10.059219Z",
     "iopub.status.busy": "2023-08-15T11:32:10.058548Z",
     "iopub.status.idle": "2023-08-15T11:32:10.065799Z",
     "shell.execute_reply": "2023-08-15T11:32:10.064511Z",
     "shell.execute_reply.started": "2023-08-15T11:32:10.059186Z"
    },
    "id": "x8WpKATx75Hu",
    "outputId": "53c19e59-1a97-4dc0-a2d7-2d31e3809f2f",
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-09-01T07:15:51.432816174Z",
     "start_time": "2023-09-01T07:15:47.902649597Z"
    }
   },
   "outputs": [],
   "source": [
    "#from dl_hub.Transformer.config import get_config\n",
    "from config import get_config\n",
    "cfg = get_config()\n",
    "cfg['batch_size'] = 16\n",
    "cfg['d_model'] = 512\n",
    "cfg['preload'] = None\n",
    "cfg['num_epochs'] = 10\n",
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T07:28:40.083925948Z",
     "start_time": "2023-09-01T07:15:54.564046752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing epoch 00: 100%|██████████| 1819/1819 [11:43<00:00,  2.58it/s, loss=5.649]\n",
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Yes, I think this will be the only quite correctly planned hospital in Russia,' said Sviyazhsky.\n",
      "    TARGET: — Sì, io penso che sarà in Russia l’unico ospedale attrezzato in modo pienamente adeguato — disse Svijazskij.\n",
      " PREDICTED: — Non ho detto , — disse — disse Levin .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Better let him be that than be like Madame Stahl, or like what I wanted to be when I was abroad.\n",
      "    TARGET: Meglio che sia sempre così, invece d’essere come la signora Stahl o come volevo essere io allora, all’estero.\n",
      " PREDICTED: Non era fatto che non mi , ma non mi , ma non mi .\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e183534/ERA_V1/venv/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `CharErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `CharErrorRate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n",
      "/home/e183534/ERA_V1/venv/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `WordErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `WordErrorRate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n",
      "/home/e183534/ERA_V1/venv/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:61: FutureWarning: Importing `BLEUScore` from `torchmetrics` was deprecated and will be removed in 2.0. Import `BLEUScore` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n",
      "processing epoch 01:   6%|▋         | 117/1819 [00:49<11:59,  2.37it/s, loss=5.855]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ERA_V1/session_15/train.py:247\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(config)\u001B[0m\n\u001B[1;32m    244\u001B[0m writer\u001B[38;5;241m.\u001B[39mflush()\n\u001B[1;32m    246\u001B[0m \u001B[38;5;66;03m# Back propagate the loss\u001B[39;00m\n\u001B[0;32m--> 247\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# Update weights\u001B[39;00m\n\u001B[1;32m    250\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/ERA_V1/venv/lib/python3.8/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ERA_V1/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
