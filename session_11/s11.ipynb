{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_11/s11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMv-YR2zikee"
      },
      "source": [
        "Download our code repository and install python dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8J1MOmbqmgC",
        "outputId": "0e00712d-2723-4204-de02-578423dd9362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ERA_V1' already exists and is not an empty directory.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: destination path 'dl_hub' already exists and is not an empty directory.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: torch_lr_finder in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (1.22.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->torch_lr_finder) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->torch_lr_finder) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->torch_lr_finder) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->torch_lr_finder) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->torch_lr_finder) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n",
        "!git pull\n",
        "!git clone \"https://github.com/jyanivaddi/dl_hub.git\"\n",
        "!git pull\n",
        "!pip install torchinfo\n",
        "!pip install prettytable\n",
        "!pip install torch_lr_finder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW3WHIzUqmgF"
      },
      "source": [
        "Add all the imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ5ZSVQJqmgI",
        "outputId": "79035765-5a8e-4da2-92d1-c73783486b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_lr_finder/lr_finder.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "sys.path.append(\"ERA_V1/session_11\")\n",
        "sys.path.append(\"dl_hub\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "import albumentations.augmentations as AA\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from dl_hub.main import setup_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF0JlvTsqmgP"
      },
      "source": [
        "Define Albumentations image augmentations. We use RandomResizedCrop, HorizontalFlip, and cutout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pI6EVt-jmGp6"
      },
      "outputs": [],
      "source": [
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        AA.crops.transforms.RandomResizedCrop(height = 32,width = 32,p=0.2),\n",
        "        A.HorizontalFlip(p=0.2),\n",
        "        AA.dropout.coarse_dropout.CoarseDropout(max_holes = 1, max_height=8,\n",
        "                                                max_width=8, min_holes = 1,\n",
        "                                                min_height=8, min_width=8,\n",
        "                                                fill_value=(0.491, 0.482, 0.447),\n",
        "                                                mask_fill_value = None),\n",
        "\n",
        "        A.Normalize(mean=(0.491,0.482,0.447),std=(0.247,0.244,0.262)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "test_transforms = A.Compose([\n",
        "\n",
        "    A.Normalize(mean=(0.491,0.482,0.447),std=(0.247,0.244,0.262)),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lnEwxxIcDg8V"
      },
      "outputs": [],
      "source": [
        "optimizer_type = 'SGD'\n",
        "optimizer_params = {\n",
        "    'weight_decay': 5e-4,\n",
        "    'lr': 0.03,\n",
        "    'momentum': 0.99\n",
        "}\n",
        "scheduler_type = 'ReduceLrOnPlateau'\n",
        "scheduler_params = {\n",
        "    'mode': 'min',\n",
        "    'factor': 0.1,\n",
        "    'patience': 4,\n",
        "    'threshold': 0.1\n",
        "}\n",
        "loss_func = F.nll_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBfwjcgkDg8Y"
      },
      "source": [
        "Define Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TTfFFfqtDg8Z"
      },
      "outputs": [],
      "source": [
        "params = {}\n",
        "params['model_type'] = 'RESNET18'\n",
        "params['dataset_name'] = 'CIFAR10'\n",
        "params['batch_size'] = 512\n",
        "params['train_transforms'] = train_transforms\n",
        "params['test_transforms'] = test_transforms\n",
        "params['num_workers'] = 2\n",
        "params['num_epochs'] = 20\n",
        "params['optimizer_type'] = optimizer_type\n",
        "params['optimizer_params'] = optimizer_params\n",
        "params['scheduler_type'] = scheduler_type\n",
        "params['scheduler_params'] = scheduler_params\n",
        "params['loss_func'] = loss_func"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up Model"
      ],
      "metadata": {
        "id": "8Z-wTdsRJWek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device, train_loader, test_loader, class_names, model, optimizer, scheduler = setup_model(params)"
      ],
      "metadata": {
        "id": "iiBkzw_5JYFE",
        "outputId": "24eebefc-ec35-4e1e-c549-e3c8dc12afc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6e685d270302>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/dl_hub/main.py\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dl_hub/main.py\u001b[0m in \u001b[0;36mdefine_scheduler\u001b[0;34m(params, optimizer)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0manneal_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anneal_strategy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             verbose=True)\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'REDUCELRONPLATEAU'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n\u001b[1;32m    109\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'scheduler' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BJ_T8ExsnE_"
      },
      "source": [
        "Preview Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm_7N56ksma4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def un_normalize_image(img):\n",
        "    un_norm_transform = transforms.Compose([transforms.Normalize((0.,0.,0.,),(1./0.247,1./0.244,1./0.262)),\n",
        "                                                 transforms.Normalize((-0.491,-0.482,-0.447),(1.0,1.0,1.0))])\n",
        "    return un_norm_transform(img)\n",
        "\n",
        "def preview_augmentations(train_loader, image_transform):\n",
        "    batch_data, batch_label = next(iter(train_loader))\n",
        "    preview_img = np.asarray(un_normalize_image(batch_data[0].squeeze()))\n",
        "    preview_img = (preview_img*255./np.max(preview_img)).astype('uint8')\n",
        "    preview_label = batch_label[0]\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    un_normalized_img = un_normalize_image(batch_data[0].squeeze())\n",
        "    un_normalized_img = np.asarray(un_normalized_img)\n",
        "    transformed_numpy_img = image_transform(image = un_normalized_img.transpose(1,2,0))[\"image\"]\n",
        "    axs[0].imshow(preview_img.transpose((1,2,0)))\n",
        "    axs[0].set_xticks([])\n",
        "    axs[0].set_yticks([])\n",
        "    axs[1].imshow(transformed_numpy_img)\n",
        "    axs[1].set_xticks([])\n",
        "    axs[1].set_yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Reload train and test loader to preview augmentations\n",
        "torch.manual_seed(1)\n",
        "batch_size = 512\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
        "eg_train_loader, eg_test_loader, eg_class_names = load_cifar10_data(train_transforms= A.Compose([A.Normalize(mean=(0.491,0.482,0.447),std=(0.247,0.244,0.262)),ToTensorV2()]), test_transforms=A.Compose([A.Normalize(mean=(0.491,0.482,0.447),std=(0.247,0.244,0.262)),ToTensorV2()]), batch_size=32, **kwargs)\n",
        "\n",
        "# Random Resized Crop\n",
        "img_transforms = A.Compose([AA.crops.transforms.RandomResizedCrop(height= 32,width = 32,p=0.2)])\n",
        "preview_augmentations(eg_train_loader, img_transforms)\n",
        "\n",
        "# Horizontal Flip\n",
        "img_transforms = A.Compose([A.HorizontalFlip(always_apply=True)])\n",
        "preview_augmentations(eg_train_loader, img_transforms)\n",
        "\n",
        "# Cut out\n",
        "img_transforms = A.Compose([AA.dropout.coarse_dropout.CoarseDropout(max_holes = 1, max_height=8,\n",
        "                                                max_width=8, min_holes = 1,\n",
        "                                                min_height=8, min_width=8,\n",
        "                                                fill_value=(0.491, 0.482, 0.447),\n",
        "                                                mask_fill_value = None, always_apply=True)])\n",
        "preview_augmentations(eg_train_loader, img_transforms)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQB2RLRxtSlv"
      },
      "source": [
        "Show sample Images from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjjB363XqmgW"
      },
      "outputs": [],
      "source": [
        "preview_images(train_loader,class_names, num_rows = 5, num_cols = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCSVRbYZmmOG"
      },
      "source": [
        "Train model using Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysHqVyhGZJ27"
      },
      "outputs": [],
      "source": [
        "drop_out = 0.02\n",
        "num_epochs=24\n",
        "resnet_model = CustomResnet(base_channels=3, num_classes=10,drop_out_probability=drop_out).to(device)\n",
        "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "optim_obj = Optimization(resnet_model, device, train_loader, criterion, num_epochs)\n",
        "lr_history = find_best_lr(resnet_model, train_loader, optim_obj.optimizer, criterion, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8RlOADSBX4y"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "#optim_obj.define_scheduler(max_lr=4.93E-2)\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "lr_values = []\n",
        "def define_scheduler(max_lr):\n",
        "    scheduler = OneCycleLR(\n",
        "        optim_obj.optimizer,\n",
        "        max_lr = max_lr,\n",
        "        steps_per_epoch=len(optim_obj.train_loader),\n",
        "        epochs = num_epochs,\n",
        "        pct_start = 5./num_epochs,\n",
        "        div_factor=2000,\n",
        "        three_phase=False,\n",
        "        final_div_factor= 100,\n",
        "        anneal_strategy='linear',\n",
        "        verbose=False\n",
        "        )\n",
        "    return scheduler\n",
        "\n",
        "max_lr = 4.65e-2\n",
        "optim_obj.scheduler = define_scheduler(max_lr)\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    lr_values.append(optim_obj.scheduler.get_lr())\n",
        "    print(f\"epoch: {epoch}\\t learning rate: {optim_obj.scheduler.get_last_lr()[0]}\")\n",
        "    this_train_loss = training_loop(resnet_model, device, train_loader, optim_obj.optimizer, optim_obj.scheduler, criterion, train_acc, train_losses)\n",
        "    this_loss = model_test(resnet_model, device, test_loader, criterion, test_acc, test_losses)\n",
        "    #optim_obj.scheduler.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7zJvrQjP8nR"
      },
      "source": [
        "Plot LR values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTncfVknP7wM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_lr_values2(lr_list):\n",
        "    num_epochs = len(lr_list)\n",
        "    plt.figure()\n",
        "    plt.plot(range(1,num_epochs+1),lr_list)\n",
        "    plt.xlabel('Epoch #')\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    #plt.yscale('log')\n",
        "    plt.show()\n",
        "\n",
        "def plot_lr_values(scheduler, num_epochs, num_batches):\n",
        "    lrs = []\n",
        "    steps = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in range(num_batches):\n",
        "            scheduler.step()\n",
        "            lrs.append(scheduler.get_last_lr()[0])\n",
        "            steps.append(epoch * num_batches + batch)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.legend()\n",
        "    plt.plot(steps, lrs, label='OneCycle')\n",
        "    plt.show()\n",
        "\n",
        "def plot_losses(train_losses, test_losses):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "    epochs = range(1,len(train_losses)+1)\n",
        "    axs[0].plot(epochs, train_losses)\n",
        "    axs[0].set_title(\"Train\")\n",
        "    axs[1].plot(epochs, test_losses)\n",
        "    axs[1].set_title(\"Test\")\n",
        "\n",
        "def plot_accuracy(train_acc, test_acc, target_test_acc = 90.):\n",
        "    epochs = range(1,len(train_acc)+1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_acc, epochs, test_acc)\n",
        "    plt.axhline(target_test_acc, color='r')\n",
        "    plt.legend(('Train','Test'),loc='best')\n",
        "    plt.title(\"Accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWzELTZYazCZ"
      },
      "source": [
        "Plot results for Batch Norm experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEU2V5lxayQJ"
      },
      "outputs": [],
      "source": [
        "this_scheduler = OneCycleLR(\n",
        "        optim_obj.optimizer,\n",
        "        max_lr = max_lr,\n",
        "        steps_per_epoch=len(optim_obj.train_loader),\n",
        "        epochs = num_epochs,\n",
        "        pct_start = 5./num_epochs,\n",
        "        div_factor=200,\n",
        "        three_phase=False,\n",
        "        #final_div_factor=1000,\n",
        "        anneal_strategy='linear',\n",
        "        verbose=False\n",
        "        )\n",
        "plot_lr_values(this_scheduler, num_epochs, len(train_loader))\n",
        "plot_losses(train_losses, test_losses)\n",
        "plot_accuracy(train_acc, test_acc, target_test_acc=90.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Uz2jryV3u1"
      },
      "source": [
        "Print Training Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ew5n7bbgW1OK"
      },
      "outputs": [],
      "source": [
        "print_train_log(train_acc, test_acc, train_losses, test_losses)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}