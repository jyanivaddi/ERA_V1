{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyanivaddi/ERA_V1/blob/master/session_11/s11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMv-YR2zikee"
      },
      "source": [
        "Download our code repository and install python dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8J1MOmbqmgC",
        "outputId": "56f6c4ca-b11c-4f7b-d952-dca6ca222b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ERA_V1'...\n",
            "remote: Enumerating objects: 893, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 893 (delta 32), reused 20 (delta 5), pack-reused 821\u001b[K\n",
            "Receiving objects: 100% (893/893), 14.39 MiB | 24.60 MiB/s, done.\n",
            "Resolving deltas: 100% (477/477), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Cloning into 'dl_hub'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 43 (delta 12), reused 32 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (43/43), 11.86 KiB | 11.86 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Collecting torch_lr_finder\n",
            "  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (1.22.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->torch_lr_finder) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->torch_lr_finder) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->torch_lr_finder) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->torch_lr_finder) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->torch_lr_finder) (1.3.0)\n",
            "Installing collected packages: torch_lr_finder\n",
            "Successfully installed torch_lr_finder-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n",
        "!git pull\n",
        "!git clone \"https://github.com/jyanivaddi/dl_hub.git\"\n",
        "!git pull\n",
        "!pip install torchinfo\n",
        "!pip install prettytable\n",
        "!pip install torch_lr_finder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW3WHIzUqmgF"
      },
      "source": [
        "Add all the imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zQ5ZSVQJqmgI"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "sys.path.append(\"ERA_V1/session_11\")\n",
        "sys.path.append(\"dl_hub\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "import albumentations.augmentations as AA\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from dl_hub.main import setup_model,build_model\n",
        "from dl_hub.utils.utils import model_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF0JlvTsqmgP"
      },
      "source": [
        "Define Albumentations image augmentations. We use RandomResizedCrop, HorizontalFlip, and cutout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pI6EVt-jmGp6"
      },
      "outputs": [],
      "source": [
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        AA.crops.transforms.RandomResizedCrop(height = 32,width = 32,p=0.2),\n",
        "        A.HorizontalFlip(p=0.2),\n",
        "        AA.dropout.coarse_dropout.CoarseDropout(max_holes = 1, max_height=8,\n",
        "                                                max_width=8, min_holes = 1,\n",
        "                                                min_height=8, min_width=8,\n",
        "                                                fill_value=(0.491, 0.482, 0.447),\n",
        "                                                mask_fill_value = None),\n",
        "\n",
        "        A.Normalize(mean=(0.491,0.482,0.447),std=(0.247,0.244,0.262)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "test_transforms = A.Compose([\n",
        "\n",
        "    A.Normalize(mean=(0.491,0.482,0.447),std=(0.247,0.244,0.262)),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lnEwxxIcDg8V"
      },
      "outputs": [],
      "source": [
        "optimizer_type = 'SGD'\n",
        "optimizer_params = {\n",
        "    'weight_decay': 5e-4,\n",
        "    'lr': 0.03,\n",
        "    'momentum': 0.99\n",
        "}\n",
        "scheduler_type = 'ReduceLrOnPlateau'\n",
        "scheduler_params = {\n",
        "    'mode': 'min',\n",
        "    'factor': 0.1,\n",
        "    'patience': 4,\n",
        "    'threshold': 0.1\n",
        "}\n",
        "loss_func = F.nll_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBfwjcgkDg8Y"
      },
      "source": [
        "Define Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TTfFFfqtDg8Z"
      },
      "outputs": [],
      "source": [
        "params = {}\n",
        "params['model_type'] = 'RESNET18'\n",
        "params['dataset_name'] = 'CIFAR10'\n",
        "params['batch_size'] = 512\n",
        "params['train_transforms'] = train_transforms\n",
        "params['test_transforms'] = test_transforms\n",
        "params['num_workers'] = 2\n",
        "params['num_epochs'] = 20\n",
        "params['optimizer_type'] = optimizer_type\n",
        "params['optimizer_params'] = optimizer_params\n",
        "params['scheduler_type'] = scheduler_type\n",
        "params['scheduler_params'] = scheduler_params\n",
        "params['loss_func'] = loss_func"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up Model"
      ],
      "metadata": {
        "id": "8Z-wTdsRJWek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device, train_loader, test_loader, class_names, model, optimizer, scheduler = setup_model(params)"
      ],
      "metadata": {
        "id": "iiBkzw_5JYFE",
        "outputId": "bdfeac8c-5a1d-4d11-b62c-0ebf8952619d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29527243.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Summary"
      ],
      "metadata": {
        "id": "ER7fBDCpQJw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_summary(model, input_size = (3,32,32))"
      ],
      "metadata": {
        "id": "ohOonfrPQTBJ",
        "outputId": "50b08014-fc6b-4696-a2c2-11a5e0f3c4ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================================================================================================================================================================\n",
            "Layer (type:depth-idx)                   Kernel Shape              Input Shape               Output Shape              Param #                   Mult-Adds\n",
            "=====================================================================================================================================================================\n",
            "ResNet                                   --                        [1, 3, 32, 32]            [1, 10]                   --                        --\n",
            "├─Conv2d: 1-1                            [3, 3]                    [1, 3, 32, 32]            [1, 64, 32, 32]           1,728                     1,769,472\n",
            "├─BatchNorm2d: 1-2                       --                        [1, 64, 32, 32]           [1, 64, 32, 32]           128                       128\n",
            "├─Sequential: 1-3                        --                        [1, 64, 32, 32]           [1, 64, 32, 32]           --                        --\n",
            "│    └─BasicBlock: 2-1                   --                        [1, 64, 32, 32]           [1, 64, 32, 32]           --                        --\n",
            "│    │    └─Conv2d: 3-1                  [3, 3]                    [1, 64, 32, 32]           [1, 64, 32, 32]           36,864                    37,748,736\n",
            "│    │    └─BatchNorm2d: 3-2             --                        [1, 64, 32, 32]           [1, 64, 32, 32]           128                       128\n",
            "│    │    └─Conv2d: 3-3                  [3, 3]                    [1, 64, 32, 32]           [1, 64, 32, 32]           36,864                    37,748,736\n",
            "│    │    └─BatchNorm2d: 3-4             --                        [1, 64, 32, 32]           [1, 64, 32, 32]           128                       128\n",
            "│    │    └─Sequential: 3-5              --                        [1, 64, 32, 32]           [1, 64, 32, 32]           --                        --\n",
            "│    └─BasicBlock: 2-2                   --                        [1, 64, 32, 32]           [1, 64, 32, 32]           --                        --\n",
            "│    │    └─Conv2d: 3-6                  [3, 3]                    [1, 64, 32, 32]           [1, 64, 32, 32]           36,864                    37,748,736\n",
            "│    │    └─BatchNorm2d: 3-7             --                        [1, 64, 32, 32]           [1, 64, 32, 32]           128                       128\n",
            "│    │    └─Conv2d: 3-8                  [3, 3]                    [1, 64, 32, 32]           [1, 64, 32, 32]           36,864                    37,748,736\n",
            "│    │    └─BatchNorm2d: 3-9             --                        [1, 64, 32, 32]           [1, 64, 32, 32]           128                       128\n",
            "│    │    └─Sequential: 3-10             --                        [1, 64, 32, 32]           [1, 64, 32, 32]           --                        --\n",
            "├─Sequential: 1-4                        --                        [1, 64, 32, 32]           [1, 128, 16, 16]          --                        --\n",
            "│    └─BasicBlock: 2-3                   --                        [1, 64, 32, 32]           [1, 128, 16, 16]          --                        --\n",
            "│    │    └─Conv2d: 3-11                 [3, 3]                    [1, 64, 32, 32]           [1, 128, 16, 16]          73,728                    18,874,368\n",
            "│    │    └─BatchNorm2d: 3-12            --                        [1, 128, 16, 16]          [1, 128, 16, 16]          256                       256\n",
            "│    │    └─Conv2d: 3-13                 [3, 3]                    [1, 128, 16, 16]          [1, 128, 16, 16]          147,456                   37,748,736\n",
            "│    │    └─BatchNorm2d: 3-14            --                        [1, 128, 16, 16]          [1, 128, 16, 16]          256                       256\n",
            "│    │    └─Sequential: 3-15             --                        [1, 64, 32, 32]           [1, 128, 16, 16]          8,448                     2,097,408\n",
            "│    └─BasicBlock: 2-4                   --                        [1, 128, 16, 16]          [1, 128, 16, 16]          --                        --\n",
            "│    │    └─Conv2d: 3-16                 [3, 3]                    [1, 128, 16, 16]          [1, 128, 16, 16]          147,456                   37,748,736\n",
            "│    │    └─BatchNorm2d: 3-17            --                        [1, 128, 16, 16]          [1, 128, 16, 16]          256                       256\n",
            "│    │    └─Conv2d: 3-18                 [3, 3]                    [1, 128, 16, 16]          [1, 128, 16, 16]          147,456                   37,748,736\n",
            "│    │    └─BatchNorm2d: 3-19            --                        [1, 128, 16, 16]          [1, 128, 16, 16]          256                       256\n",
            "│    │    └─Sequential: 3-20             --                        [1, 128, 16, 16]          [1, 128, 16, 16]          --                        --\n",
            "├─Sequential: 1-5                        --                        [1, 128, 16, 16]          [1, 256, 8, 8]            --                        --\n",
            "│    └─BasicBlock: 2-5                   --                        [1, 128, 16, 16]          [1, 256, 8, 8]            --                        --\n",
            "│    │    └─Conv2d: 3-21                 [3, 3]                    [1, 128, 16, 16]          [1, 256, 8, 8]            294,912                   18,874,368\n",
            "│    │    └─BatchNorm2d: 3-22            --                        [1, 256, 8, 8]            [1, 256, 8, 8]            512                       512\n",
            "│    │    └─Conv2d: 3-23                 [3, 3]                    [1, 256, 8, 8]            [1, 256, 8, 8]            589,824                   37,748,736\n",
            "│    │    └─BatchNorm2d: 3-24            --                        [1, 256, 8, 8]            [1, 256, 8, 8]            512                       512\n",
            "│    │    └─Sequential: 3-25             --                        [1, 128, 16, 16]          [1, 256, 8, 8]            33,280                    2,097,664\n",
            "│    └─BasicBlock: 2-6                   --                        [1, 256, 8, 8]            [1, 256, 8, 8]            --                        --\n",
            "│    │    └─Conv2d: 3-26                 [3, 3]                    [1, 256, 8, 8]            [1, 256, 8, 8]            589,824                   37,748,736\n",
            "│    │    └─BatchNorm2d: 3-27            --                        [1, 256, 8, 8]            [1, 256, 8, 8]            512                       512\n",
            "│    │    └─Conv2d: 3-28                 [3, 3]                    [1, 256, 8, 8]            [1, 256, 8, 8]            589,824                   37,748,736\n",
            "│    │    └─BatchNorm2d: 3-29            --                        [1, 256, 8, 8]            [1, 256, 8, 8]            512                       512\n",
            "│    │    └─Sequential: 3-30             --                        [1, 256, 8, 8]            [1, 256, 8, 8]            --                        --\n",
            "├─Sequential: 1-6                        --                        [1, 256, 8, 8]            [1, 512, 4, 4]            --                        --\n",
            "│    └─BasicBlock: 2-7                   --                        [1, 256, 8, 8]            [1, 512, 4, 4]            --                        --\n",
            "│    │    └─Conv2d: 3-31                 [3, 3]                    [1, 256, 8, 8]            [1, 512, 4, 4]            1,179,648                 18,874,368\n",
            "│    │    └─BatchNorm2d: 3-32            --                        [1, 512, 4, 4]            [1, 512, 4, 4]            1,024                     1,024\n",
            "│    │    └─Conv2d: 3-33                 [3, 3]                    [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296                 37,748,736\n",
            "│    │    └─BatchNorm2d: 3-34            --                        [1, 512, 4, 4]            [1, 512, 4, 4]            1,024                     1,024\n",
            "│    │    └─Sequential: 3-35             --                        [1, 256, 8, 8]            [1, 512, 4, 4]            132,096                   2,098,176\n",
            "│    └─BasicBlock: 2-8                   --                        [1, 512, 4, 4]            [1, 512, 4, 4]            --                        --\n",
            "│    │    └─Conv2d: 3-36                 [3, 3]                    [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296                 37,748,736\n",
            "│    │    └─BatchNorm2d: 3-37            --                        [1, 512, 4, 4]            [1, 512, 4, 4]            1,024                     1,024\n",
            "│    │    └─Conv2d: 3-38                 [3, 3]                    [1, 512, 4, 4]            [1, 512, 4, 4]            2,359,296                 37,748,736\n",
            "│    │    └─BatchNorm2d: 3-39            --                        [1, 512, 4, 4]            [1, 512, 4, 4]            1,024                     1,024\n",
            "│    │    └─Sequential: 3-40             --                        [1, 512, 4, 4]            [1, 512, 4, 4]            --                        --\n",
            "├─Linear: 1-7                            --                        [1, 512]                  [1, 10]                   5,130                     5,130\n",
            "=====================================================================================================================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 555.43\n",
            "=====================================================================================================================================================================\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.83\n",
            "Params size (MB): 44.70\n",
            "Estimated Total Size (MB): 54.54\n",
            "=====================================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Model"
      ],
      "metadata": {
        "id": "LPIsd6WGPqBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, test_losses, train_acc, test_acc = build_model(model, device, train_loader, test_loader, optimizer, scheduler, params)"
      ],
      "metadata": {
        "id": "lJk6ChzOPr1d",
        "outputId": "31d7aa1b-f7fc-4620-9f9a-273685e16de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-717eaa624a0e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/dl_hub/main.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(model, device, train_loader, test_loader, optimizer, scheduler, params)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mlr_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch: {epoch}\\t learning rate: {scheduler.get_last_lr()[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mtrain_the_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ReduceLROnPlateau' object has no attribute 'get_lr'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BJ_T8ExsnE_"
      },
      "source": [
        "Preview Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm_7N56ksma4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def un_normalize_image(img):\n",
        "    un_norm_transform = transforms.Compose([transforms.Normalize((0.,0.,0.,),(1./0.247,1./0.244,1./0.262)),\n",
        "                                                 transforms.Normalize((-0.491,-0.482,-0.447),(1.0,1.0,1.0))])\n",
        "    return un_norm_transform(img)\n",
        "\n",
        "def preview_augmentations(train_loader, image_transform):\n",
        "    batch_data, batch_label = next(iter(train_loader))\n",
        "    preview_img = np.asarray(un_normalize_image(batch_data[0].squeeze()))\n",
        "    preview_img = (preview_img*255./np.max(preview_img)).astype('uint8')\n",
        "    preview_label = batch_label[0]\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    un_normalized_img = un_normalize_image(batch_data[0].squeeze())\n",
        "    un_normalized_img = np.asarray(un_normalized_img)\n",
        "    transformed_numpy_img = image_transform(image = un_normalized_img.transpose(1,2,0))[\"image\"]\n",
        "    axs[0].imshow(preview_img.transpose((1,2,0)))\n",
        "    axs[0].set_xticks([])\n",
        "    axs[0].set_yticks([])\n",
        "    axs[1].imshow(transformed_numpy_img)\n",
        "    axs[1].set_xticks([])\n",
        "    axs[1].set_yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Reload train and test loader to preview augmentations\n",
        "torch.manual_seed(1)\n",
        "batch_size = 512\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
        "eg_train_loader, eg_test_loader, eg_class_names = load_cifar10_data(train_transforms= A.Compose([A.Normalize(mean=(0.491,0.482,0.447),std=(0.247,0.244,0.262)),ToTensorV2()]), test_transforms=A.Compose([A.Normalize(mean=(0.491,0.482,0.447),std=(0.247,0.244,0.262)),ToTensorV2()]), batch_size=32, **kwargs)\n",
        "\n",
        "# Random Resized Crop\n",
        "img_transforms = A.Compose([AA.crops.transforms.RandomResizedCrop(height= 32,width = 32,p=0.2)])\n",
        "preview_augmentations(eg_train_loader, img_transforms)\n",
        "\n",
        "# Horizontal Flip\n",
        "img_transforms = A.Compose([A.HorizontalFlip(always_apply=True)])\n",
        "preview_augmentations(eg_train_loader, img_transforms)\n",
        "\n",
        "# Cut out\n",
        "img_transforms = A.Compose([AA.dropout.coarse_dropout.CoarseDropout(max_holes = 1, max_height=8,\n",
        "                                                max_width=8, min_holes = 1,\n",
        "                                                min_height=8, min_width=8,\n",
        "                                                fill_value=(0.491, 0.482, 0.447),\n",
        "                                                mask_fill_value = None, always_apply=True)])\n",
        "preview_augmentations(eg_train_loader, img_transforms)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQB2RLRxtSlv"
      },
      "source": [
        "Show sample Images from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjjB363XqmgW"
      },
      "outputs": [],
      "source": [
        "preview_images(train_loader,class_names, num_rows = 5, num_cols = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCSVRbYZmmOG"
      },
      "source": [
        "Train model using Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysHqVyhGZJ27"
      },
      "outputs": [],
      "source": [
        "drop_out = 0.02\n",
        "num_epochs=24\n",
        "resnet_model = CustomResnet(base_channels=3, num_classes=10,drop_out_probability=drop_out).to(device)\n",
        "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "optim_obj = Optimization(resnet_model, device, train_loader, criterion, num_epochs)\n",
        "lr_history = find_best_lr(resnet_model, train_loader, optim_obj.optimizer, criterion, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8RlOADSBX4y"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "#optim_obj.define_scheduler(max_lr=4.93E-2)\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "lr_values = []\n",
        "def define_scheduler(max_lr):\n",
        "    scheduler = OneCycleLR(\n",
        "        optim_obj.optimizer,\n",
        "        max_lr = max_lr,\n",
        "        steps_per_epoch=len(optim_obj.train_loader),\n",
        "        epochs = num_epochs,\n",
        "        pct_start = 5./num_epochs,\n",
        "        div_factor=2000,\n",
        "        three_phase=False,\n",
        "        final_div_factor= 100,\n",
        "        anneal_strategy='linear',\n",
        "        verbose=False\n",
        "        )\n",
        "    return scheduler\n",
        "\n",
        "max_lr = 4.65e-2\n",
        "optim_obj.scheduler = define_scheduler(max_lr)\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    lr_values.append(optim_obj.scheduler.get_lr())\n",
        "    print(f\"epoch: {epoch}\\t learning rate: {optim_obj.scheduler.get_last_lr()[0]}\")\n",
        "    this_train_loss = training_loop(resnet_model, device, train_loader, optim_obj.optimizer, optim_obj.scheduler, criterion, train_acc, train_losses)\n",
        "    this_loss = model_test(resnet_model, device, test_loader, criterion, test_acc, test_losses)\n",
        "    #optim_obj.scheduler.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7zJvrQjP8nR"
      },
      "source": [
        "Plot LR values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTncfVknP7wM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_lr_values2(lr_list):\n",
        "    num_epochs = len(lr_list)\n",
        "    plt.figure()\n",
        "    plt.plot(range(1,num_epochs+1),lr_list)\n",
        "    plt.xlabel('Epoch #')\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    #plt.yscale('log')\n",
        "    plt.show()\n",
        "\n",
        "def plot_lr_values(scheduler, num_epochs, num_batches):\n",
        "    lrs = []\n",
        "    steps = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in range(num_batches):\n",
        "            scheduler.step()\n",
        "            lrs.append(scheduler.get_last_lr()[0])\n",
        "            steps.append(epoch * num_batches + batch)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.legend()\n",
        "    plt.plot(steps, lrs, label='OneCycle')\n",
        "    plt.show()\n",
        "\n",
        "def plot_losses(train_losses, test_losses):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "    epochs = range(1,len(train_losses)+1)\n",
        "    axs[0].plot(epochs, train_losses)\n",
        "    axs[0].set_title(\"Train\")\n",
        "    axs[1].plot(epochs, test_losses)\n",
        "    axs[1].set_title(\"Test\")\n",
        "\n",
        "def plot_accuracy(train_acc, test_acc, target_test_acc = 90.):\n",
        "    epochs = range(1,len(train_acc)+1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_acc, epochs, test_acc)\n",
        "    plt.axhline(target_test_acc, color='r')\n",
        "    plt.legend(('Train','Test'),loc='best')\n",
        "    plt.title(\"Accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWzELTZYazCZ"
      },
      "source": [
        "Plot results for Batch Norm experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEU2V5lxayQJ"
      },
      "outputs": [],
      "source": [
        "this_scheduler = OneCycleLR(\n",
        "        optim_obj.optimizer,\n",
        "        max_lr = max_lr,\n",
        "        steps_per_epoch=len(optim_obj.train_loader),\n",
        "        epochs = num_epochs,\n",
        "        pct_start = 5./num_epochs,\n",
        "        div_factor=200,\n",
        "        three_phase=False,\n",
        "        #final_div_factor=1000,\n",
        "        anneal_strategy='linear',\n",
        "        verbose=False\n",
        "        )\n",
        "plot_lr_values(this_scheduler, num_epochs, len(train_loader))\n",
        "plot_losses(train_losses, test_losses)\n",
        "plot_accuracy(train_acc, test_acc, target_test_acc=90.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Uz2jryV3u1"
      },
      "source": [
        "Print Training Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ew5n7bbgW1OK"
      },
      "outputs": [],
      "source": [
        "print_train_log(train_acc, test_acc, train_losses, test_losses)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}