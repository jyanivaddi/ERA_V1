{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8J1MOmbqmgC",
        "outputId": "d5e067e8-6a99-4c4e-d1a4-c9d9ca138506"
      },
      "outputs": [],
      "source": [
        "#!git clone \"https://github.com/jyanivaddi/ERA_V1.git\"\n",
        "#!git pull"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lW3WHIzUqmgF"
      },
      "source": [
        "Add all the imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zQ5ZSVQJqmgI"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "sys.path.append(\"ERA_V1/session_7\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from s8_utils import load_cifar10_data, preview_batch_images, plot_statistics\n",
        "from s8_model import Model_Net, model_summary, model_train, model_test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n4AHY0CsqmgL"
      },
      "source": [
        "Allocate GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xmgYQudqmgM",
        "outputId": "34a69653-0c49-4f65-ffd2-693c6dc291fb"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 1, 3, 32, 32]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_cuda \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m cifar_10_model \u001b[39m=\u001b[39m Model_Net()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m model_summary(cifar_10_model, input_size\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m32\u001b[39;49m,\u001b[39m32\u001b[39;49m))\n",
            "File \u001b[0;32m~/ERA_V1/session_8/s8_model.py:9\u001b[0m, in \u001b[0;36mmodel_summary\u001b[0;34m(model, input_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_summary\u001b[39m(model, input_size):\n\u001b[0;32m----> 9\u001b[0m     summary(model, input_size \u001b[39m=\u001b[39;49m input_size)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
            "File \u001b[0;32m~/ERA_V1/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/ERA_V1/session_8/s8_model.py:125\u001b[0m, in \u001b[0;36mModel_Net.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 125\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_block_1_1(x)\n\u001b[1;32m    126\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_block_1_2(x)\n\u001b[1;32m    127\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_block_1(x)\n",
            "File \u001b[0;32m~/ERA_V1/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/ERA_V1/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/ERA_V1/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
            "File \u001b[0;32m~/ERA_V1/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m~/ERA_V1/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 1, 3, 32, 32]"
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "cifar_10_model = Model_Net().to(device)\n",
        "model_summary(cifar_10_model, input_size=(3,32,32))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eF0JlvTsqmgP"
      },
      "source": [
        "Define Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzPjTF_ZqmgQ"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.244, 0.262))\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.491, 0.482, 0.447), (0.247, 0.244, 0.262))\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UvBUHxXlqmgR"
      },
      "source": [
        "Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZPaylEkqmgS"
      },
      "outputs": [],
      "source": [
        "train_data, test_data, class_names = load_cifar10_data(train_transforms, test_transforms)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D6f-Ko64qmgU"
      },
      "source": [
        "Define train and test loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8mQv0iUqmgV"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle = True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = True, **kwargs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q6gJu4mQqmgV"
      },
      "source": [
        "Calculate Mean and Std of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "mean_r = 0\n",
        "mean_g = 0\n",
        "mean_b = 0\n",
        "\n",
        "std_r = 0\n",
        "std_g = 0\n",
        "std_b = 0\n",
        "for img,_ in tqdm(train_loader):\n",
        "    img = np.asarray(img)\n",
        "    #print(img[:,0,:,:].shape)\n",
        "    num_elem = np.prod(img[:,0,:,:].shape)\n",
        "    mean_r += np.mean(img[:,0,:,:])\n",
        "    mean_g += np.mean(img[:,1,:,:])\n",
        "    mean_b += np.mean(img[:,2,:,:])\n",
        "    std_r += np.var(img[:,0,:,:])\n",
        "    std_g += np.var(img[:,1,:,:])\n",
        "    std_b += np.var(img[:,2,:,:])\n",
        "mean_r = mean_r / len(train_loader)\n",
        "mean_g = mean_g / len(train_loader)\n",
        "mean_b = mean_b / len(train_loader)\n",
        "std_r = np.sqrt(((1./(len(train_loader)-1))*std_r))\n",
        "std_g = np.sqrt(((1./(len(train_loader)-1))*std_g))\n",
        "std_b = np.sqrt(((1./(len(train_loader)-1))*std_b))\n",
        "print(f\"dataset mean: {mean_r:0.3f}, {mean_g:0.3f}, {mean_b:0.3f}\")\n",
        "print(f\"dataset std: {std_r:0.3f}, {std_g:0.3f}, {std_b:0.3f}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "DjjB363XqmgW",
        "outputId": "facf47b2-2b42-4865-c170-c93ccbb3527f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def preview_images(train_loader, num_rows = 5, num_cols = 5):\n",
        "    batch_data, batch_label = next(iter(train_loader))\n",
        "    num_images_to_preview = num_rows*num_cols\n",
        "    fig = plt.figure()\n",
        "    for cnt in range(num_images_to_preview):\n",
        "        plt.subplot(num_rows,num_cols,cnt+1)\n",
        "        plt.tight_layout()\n",
        "        this_img = np.asarray(batch_data[cnt])\n",
        "        plt.imshow(this_img.transpose((1,2,0)))\n",
        "        plt.title(class_names[str(batch_label[cnt].item())])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    plt.show()\n",
        "\n",
        "preview_images(train_loader,num_rows = 5, num_cols = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WmzCEZZqmgW",
        "outputId": "e6a2cded-baf8-4c70-9453-431e749e0b0f"
      },
      "outputs": [],
      "source": [
        "model = Model_Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1, verbose=True)\n",
        "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True)\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "for epoch in range(1,20):\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    this_train_loss = model_train(model, device, train_loader, optimizer, train_acc, train_losses)\n",
        "    this_loss = model_test(model, device, test_loader, test_acc, test_losses)\n",
        "    #scheduler.step()\n",
        "    #print(optimizer.)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UvisCz-fqmgX"
      },
      "source": [
        "Plot Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "d-K0apFoqmgX",
        "outputId": "bbd0fc3c-09da-47f6-b127-7a99e2a8ba09"
      },
      "outputs": [],
      "source": [
        "plot_statistics(train_losses, train_acc, test_losses, test_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
